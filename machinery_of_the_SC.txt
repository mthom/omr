DISCLAIMER: This is a very rough set of notes on the implementation of
the shared cache class. Our ambition is to transform it into a
detailed, technically well-founded white paper on the shared cache
class, which (presumably) will be released for the benefit of the
general public (if not, at least internally to IBM and CASA). For now,
this document must remain INTERNAL TO CASA.

--

First, it's instructive to look at the J9PORT_SHR_CACHE_TYPE
enum. It's not an enum..  they are defined separately as individual
constants/macros, defined as 1-5. Their names are:

*_PERSISTENT
*_NONPERSISTENT
*_VMEM
*_CROSSGUEST
*_SNAPSHOT

I don't know what distinguishes the last of these two. Or _VMEM.
J9_SHR_CACHELET_SUPPORT is linked to OsCachevm.hpp, so I suppose
cachelets are connected to whatever the VMEM cache type handles.

Starting with the data and functionality of OSCache.hpp and sattelite
modules.

The inheritance diagram for the OSCache*.[c|h]pp files is:

			OSCache             <----
			    |                    \
			OSCacheFile               \
			 /     \                  |
			/       \                 |
	OSCachemmap		OSCachevmem  OSCachesysv

These are all preceded by the characters "SH_" within C++, BTW.

Certain crucial methods in OSCacheFile (like the very instructive
createCacheFile method) are non-virtual. Indicating that OSCachemmap
and OSCachevmem instantiate their parent objects with different mode
creation settings, the mechanics of which are otherwise the same.

Note that SH_OSCacheInitializer is provided for use by consumers of
the OSCache family. They tell the OSCache* class how to initialize
data in the class. Or, the class itself. I suppose! I don't really
know the direct purpose of it. To initialize the class at key moments,
yes? I don't think OSCache presumes much about the client.

OSCACHE.HPP MEMBER VARIABLES:

As the header comment says.. the purpose of the class is to abstract
over the shared memory region that the class will be mapped into, and
it also contains mutexes for read/write access.

We run down the list.

	char* _cacheName; // the name of the cache. command line argument.
	/* Align the U_64 so we don't have too many platform specific structure padding
	 * issues in the debug extensions. Note C++ adds a pointer variable at the start
	 * of the structure so putting it second should align it.
	 */
	U_64 _runtimeFlags; // not sure what values these might assume.
	U_32 _cacheSize; // size of the cache in bytes.
	void* _headerStart; // where does the cache header start?
	void* _dataStart; // and its data?
	U_32 _dataLength; // how large is the data segment?
	char* _cacheNameWithVGen; // cache name with version and generation included.
	char* _cachePathName; // its filesystem path.
	UDATA _activeGeneration; // which is the currently active generation?
	UDATA _createFlags; // configures the creation of a cache (?)
	UDATA _verboseFlags; // verbosity options.
	IDATA _errorCode; // the active error code? possibly an OK code?
	const J9SharedClassPreinitConfig* _config; //
	I_32 _openMode; // passed to j9file_open or j9file_blocking_async_open
			// (platform dependent)
	bool _runningReadOnly; // cannot write? wouldn't it be handled by _openMode?
	J9PortLibrary* _portLibrary; // the port library. platform dependent.
	char* _cacheDirName; // The parent directory of the cache.
	bool _startupCompleted; // was startup completed???
	bool _doCheckBuildID; // dunno.
	IDATA _corruptionCode; // did some sort of corruption take place?
	UDATA _corruptValue; // Which value is known to be corrupt?
	bool _isUserSpecifiedCacheDir; // used the default cache dir?

Surely you notice the lack of mutexes. The member functions SH_OSCache
contains that have to do with acquiring locks are pure virtual
functions. ACKSHAULLY.. these methods..  acquiring and releasing locks
and so forth.. are defined in OSCacheFile, which is at the root of
both OSCachevmem and OSCachemmap.

Interesting comment from Hang Shao (dated Jun 19 of this year):

"OSCachevmem.hpp/OSCachevmem.cpp is not being used now. They are only
active under J9SHR_CACHELET_SUPPORT, which is not defined.

We could either remove these two files together with all the code
inside J9SHR_CACHELET_SUPPORT, or simply add vm parameter and put
#include "OSCachevmem.hpp" inside ifdef J9SHR_CACHELET_SUPPORT here."

Fun!! So it isn't necessary at all. I don't understand what cachelets
are.

OSCACHE.HPP MEMBER FUNCTIONS:

There is a 'newInstance' method, so it is a singleton class... well,
no, OSCache is not a singleton class. That's what I initially
thought. Instead, it's a static helper method that creates a
SH_OSCache according to the versionData->cacheType attribute. If it's
of _VMEM type, then we construct a vmem object, etc. Interestingly,
_VMEM object construction is supported only if J9SHR_CACHELET_SUPPORT
is on, which per the earlier comment is never defined! So I don't
think we have to worry about it at all, really. _SYSV is the version
used if a nonpersistent cache is chosen, BTW.. doesn't appear
particular to the system architecture used at all!! Contra our earlier
impressions.

One thing to note is that OSCachevmem uses j9file_read and
j9file_blocking_async_read, while OSCachemmap does not. My impression
is that 'cachelets' are smaller versions of the cache that are copied
into main memory, though from a file (and hence they are
persistent!). Does that mean they're written back to file?

Despite the annotation, j9file_read is a macro defined in
runtime/oti/j9port_generated.  It expands to a call to the port
library to call whatever file reading routine the host platform
provides. A great many other system calls are wrapped in macros and
named similarly within the file.

See runtime/port/sysvipc for a collection of wrappers around System V
style ipc primitives.  Mostly for shared memory and semaphores,
although there is j9sharedwrapper.[h|c], which provides some helper
routines for dealing with the shared class cache. You see, strewn
throughout, references to a 'control file', for shared memory..

This is what the whole ctrlDir convention has been about!! Setting up
the control file directory. From the OpenJ9 manual:

"Nonpersistent caches are stored in shared memory and have control
files that describe the location of the memory. Control files are
stored in a javasharedresources subdirectory of the cacheDir
specified. Do not move or delete control files in this directory. The
listAllCaches utility, the destroyAll utility, and the expire
suboption work only in the scope of a given cacheDir."

Nonpersistent caches are still shared!! You must keep this in mind.

Going back to OSCache, though, it appears to be mostly used for
extracting the Java version and cache generation info from cache
filenames / control files, depending on which is used (ie. is the
cache persistent or nonpersistent?).  The only really non-trivial
parts are those dealing with initialization and startup.

'commonStartup', as the name suggests, deals with the initializing the
portions OSCache manages that are common to all its variants: vmem,
Sysv, and mmap. Many of the utilities are statically
initialized. commonStartup, again, is mostly concerned with
initializing everything properly.. the cache names, their version and
generation flags, various runtime and verbosity flags.. administrivia!

'commonInit' sets the OsCache data to 0 or NULL.  Or FALSE, if the
values are boolean.  This exhaustively describes what it does. See for
yourself.

'commonCleanup' is similar.. it mostly calls j9mem_free_memory on the
string data that were allocated in commonStartup, and it emits some
trace messages as it does so.  Nothing interesting or spectacular.

'initOSCache' does exactly that. It writes the _dataLength and
_dataStart attributes into the header, along with the version,
generation and build ID (a SHA hash) to the header.  Notice that
OSCache does nothing at all with _dataStart and _dataLength, beyond
initializing them and writing them to the cache header. These belong
to the subclasses!

'checkOSCacheHeader' simply verifies that several important invariants
hold.. ie.  the size of the cache is equal to the size of the cache
header + _dataLength.

Then there's some functions for specifying the corruption
context. Which is just a code, and the value that points to the
corrupted thing or provides some helpful data, usually.  It's all in
the comments, no need to reiterate that here.

Moving onto OSCacheFile.hpp !

It's another abstract class. It doesn't initialize the 'initialize'
virtual function or anything. It wraps a single file handle as its
lone data member.

It also defines some OSCache_mmap_header structs, which contain (among
other things) locks for the header and data
sections. OSCache_mmap_header_1 and *_2 contain many of the same
members but are slightly different. *_1 appears to contain some
'unused' padding that's probably used to make them the same
size. Hmmm.. yeah, I dunno.  Actually appears to have more to do with
OSCache_header1 versus OSCache_header2.  The mmap_header_*'s wrap one
of each. Going by the #define's in OSCache.hpp, they appear to
correspond to different cache generations.

OSCACHEFILE member variables:

	IDATA _fileHandle;

And that's it!! That's all the class wraps. It's a handle for a
file. That is it.

OSCACHEFILE member functions:

'acquireHeaderWriteLock' reaches into the header, and grabs the header
write lock, calling out to the j9file_lock/j9_file_async_blocking_lock
primitives to acquire it.  With traces and error handling, as always.

'getmmapHeaderFieldOffsetForGen' finds the byte offset of a given
field (second argument) with the OSCache header, depending on the
generation passed to it (first argument).

'releaseHeaderWriteLock'.. similar, analogous thing. Clear the lock.

'tryAcquireAttachWriteLock' does.. pretty much the same as
'acquireHeaderWriteLock', only it gets the attach write lock.. to
write to the attach region of the cache.  I don't know what the
'attach region' is, exactly. I suppose we'll find out!  But the logic
is basically the same. I don't why the function name begins with 'try'
and not 'acquire'.. there's nothing exceptional about it. No, I see
the difference now. One of the flags has a NOWAIT stipulation. If the
lock is held, it will immediately return to the caller.

'checkCacheHeaderValid' checks that the cache header is well formed
and forms a corruption context if it's not, and yadda yadda. Most of
this stuff is straightforward and uninteresting!! Mostly has to do
with acquiring and releasing locks. It assumes the cache is
persistent, since, y'know, a cache formed at runtime must be valid,
yes??  There's no chance it was violated by openj9. I expect this to
be the assumption.

`openCacheFile' opens the cache attached to the file header. Nothing
interesting about it. Uses the _openMode flags and such. Blah.

'findfirst', 'findnext', and 'findclose' iterate through cache files
in the cacheDir (a parameter for all three functions). There's a
helper predicate that determines whether the files found are valid
cache name files, and if they are, it returns the file handle of those
files.

And then we have two other functions checking cache access permissions
attached to the file handle. These are static functions of
OSCacheFile.

And we're done! Easy.

OSCACHESYSV

Ok, in OSCachesysv.hpp, we have a few different header types
corresponding to the various cache generations. Again, they are
similar to the mmap headers we saw last time (defined in
OSCacheFile.hpp, confusingly). This time, they contain things like
semaphore IDS (but never shared memory segment IDs).

REMEMBER, OSCachesysv is NOT inherited from OSCacheFile!! It's a
shared memory region after all, not a cache.

OSCachesysv member variables:

	j9shmem_handle* _shmhandle;
	j9shsem_handle* _semhandle;

	IDATA _attach_count; // # of processes attached to the region.
	UDATA _totalNumSems; // total number of semaphores active.
	UDATA _userSemCntr;  // the number of semaphores requested by users.
	U_32 _actualCacheSize; // the actual size of the cache in bytes.

	char* _shmFileName; // initialized as 'cacheNameWithVGen' in startup
	char* _semFileName; // not sure!
	bool _openSharedMemory; // did we fail at attempting to open an existing shared memory??

	UDATA _storageKeyTesting;

	const J9SharedClassPreinitConfig* config;

	SH_OSCache::SH_OSCacheInitializer* _initializer;
	UDATA _groupPerm; // group permissions.

	I_32 _semid; // ID of the seamphore.

	SH_SysvSemAccess _semAccess;
	SH_SysvShmAccess _shmAccess;

	J9ControlFileStatus _controlFileStatus; // the status of the shared memory control file.

Clearly, these are much more elaborate than the other ones.

OSCACHESYSV MEMBER FUNCTIONS:

`startup` is a few hundred lines long, and mostly deals with the myriad cases involved
in trying to create a new shared memory, or attach to an existing one.

`openCache` is called if the caller holds the mutex... but it says as much. First,
a few helper functions!!

`OpenSysVMemoryHelper` does the thing of calling out to j9shmem_open and related
functions. It even calls out to 'Deprecated' versions of j9shmem_open if the generation
is less than current. So that is good.

'shmemOpenWrapper' calls to OpenSysVMemoryHelper, and tries to open again if the previous
read failed if an option was set to attempting a read-only open upon initial failure.

'openCache'.. calls shmemOpenWrapper and branches on the result code. the *_FAILED cases
consist mostly of printing an error message somewhere and promptly returning. For the
opening (of an existing) shared cache case: check that there is a user specified
cacheDir, and also get the shared memory access settings by calling
'checkSharedMemoryAccess'. If all checks out, do nothing. If we created the cache by
opening it, call 'initializeHeader'. Otherwise, usually.. an error happened, and
we simply print it out.

`verifyCacheHeader`.. checks the validity of the cache header and assorted nonsense. Yeah.
Sets the corruption context and/or prints error messages where applicable.

'detachRegion' detaches from the _shmHandle memory region, and files error info if
that doesn't succeed.

'cleanup' calls 'detachRegion', and closes _shmHandle, using j9shmem_close. Similarly
for _semhandle.. if they are both non-NULL. 'commonCleanup' is called.

'detach' ... detaches the region. But adds some trace messages on top of calling
'detachRegion'.

'initializeHeader' checks that the cacheSize and other features are set up appropriately,
before attaching to the region by calling j9shmem_attach. If this doesn't succeed,
ErrorInfo is recorded and we return. Otherwise, _headerStart, _dataStart and _dataLength
are all written to (dataLength was determined previously in the function). We copy
the shared memory eyecatcher into the header, call 'initOSCacheHeader', and importantly,
we call the _initializer's init virtual function, if _initializer is non-NULL. Then
we toggle _cacheInitComplete as true.

'attach' similarly attaches to an existing region if one exists at _shmHandle.
From there, it calls 'verifyCacheHeader', and if the cache header is found to be invalid
or corrupt, it returns with an error after detaching _shmHandle. Otherwise, it initializes
_dataStart and _dataLength as 'initializeHeader' does, and increments the _attachCount.
Curiously, it doesn't seem to bother with mutexes.. I suppose because a header, once
initialized, is a read-only structure. I don't think _attachCount is atomic either..
yeah, it's not. It's just an old fashioned integer.

'destroy' starts by calling 'DestroySysVShmHelper', which extracts the version and generation
from the cacheName, and uses them to decide which j9shmem_destroy[Deprecated]? routine
to call. Very much in parallel with OpenSysVHelper. Before this, it detaches from the
shared memory region, and checks that the cache isn't active (ie. the number of processes
attached isn't greater than 0). Then we call 'DestroySysVSemHelper' and so forth.

'getNewWriteLockID' returns a new, unoccupied ID, from its store of unused write lock IDs.
If there are none left, it returns -1.

'acquireWriteID' awaits on a passed write lock id, and returns it when j9shmem_wait_deprecated
returns, if successful. Otherwise it prints an error message and returns.

'enterHeaderMutex' and 'exitHeaderMutex' acquire the specially designated SEM_HEADERLOCK
as the previous two functions do, not much difference in how they work.

'isCacheActive' retrieves the status of the shared memory region using j9shmem_stat,
and checks that the number of processes attached is > 0. If so, return true; otherwise,
false.

'printErrorMessage' translates J9PORT_ERROR_SYSV_IPC_* values to trace messages.

'cleanupSysVResources' tries to detach and destroy both _shmHandle and _semHandle.
If 'isCacheActive' returns true, it simply detaches and closes the handles. There's
extensive error handling and platform specific code laden throughout.

'errorHandler' prints the passed error message and calls 'cleanupSysVResources' if
startup didn't complete, and we meant to create shared memory resources.

'setRegionPermissions' is the barest of wrappers around j9shmem_protect.

Same for 'getPermissionsRegionGranularity'.

Most of the remaining functions are quite straightforward. What I'm drawn to primarily
is 'getControlFilePerm', which gets the permissions of the control file, mostly..
interesting that the name of the control file is stored outside the OSCachesysv object.
Actually, no, the name is either 'memory' or 'semaphore'. Huh.

'restoreSnapshotFile' is a tour de force through OSCacheSysv's internal functionality,
and through SH_CacheMap's as well! I think that about sums up its methods.

OSCACHEVMEM

That's right! It's quite small, so I think we can devote a quick aside to it. Here are
its member variables:

	I_64 _actualFileLength;
	UDATA _writeLockCounter;

	omrthread_monitor_t _lockMutex[J9SH_OSCACHE_VMEM_LOCK_COUNT];

That's the list. We have mutexes and a counter for write lock. Also, OSCachevmem
inherits from OSCacheFile, so it does have a file handle. Interesting.

Yeah, pouring over this, looks to be very very much like an mmap! That's the
header format it uses.. all the rest is just logic for 'attaching' to a file, and
setting up the internals of the object.

OSCACHEMMAP

Like OSCacheVmem, it also inherits from OSCacheFile.

Member variables:
	I_64 _actualFileLength;
	J9MmapHandle *_mapFileHandle;

	UDATA _finalised;

	omrthread_monitor_t _lockMutex[J9SH_OSCACHE_MMAP_LOCK_COUNT];

	SH_CacheFileAccess _cacheFileAccess;

That's all she wrote! Notice the addition of the _mapFileHandle clause thingum.
Something OSCacheVmem didn't have. I guess the virtual memory versus was.. a lightweight
spin on this more elaborate idea? Maybe a paring down of functionality, or management
responsibility?

Looking at the startup method, I see that OSCacheSysv's startup is largely mirrored,
in terms of what is checked.. only here we fall back on the 'openCacheFile' of OSCacheFile.

It's 'internalAttach' which calls j9mmap_map_file, and passes the _fileHandle field
along to it. It returns the _mapFileHandle. Then some error checking is done, the
header is gotten at eventually, the _dataStart and _dataLength things are loaded into
it.. pretty unremarkable stuff I'd say!!

ok, moving on from the OSCACHE* files...

.. and to the CompositeCache classes.

SH_CompositeCache is a pure abstract class defining a minimal interface:

class SH_CompositeCache
{
public:
	virtual U_16 getJVMID(void) = 0;
	virtual bool isRunningReadOnly(void) = 0;
	virtual UDATA getTotalUsableCacheSize(void) = 0;
	virtual void getMinMaxBytes(U_32 *softmx, I_32 *minAOT, I_32 *maxAOT, I_32 *minJIT,
								I_32 *maxJIT) = 0;
	virtual UDATA getFreeAvailableBytes(void) = 0;
	virtual U_32 getDebugBytes(void) = 0;
	virtual void setInternCacheHeaderFields(J9SRP** sharedTail, J9SRP** sharedHead,
								U_32** totalSharedNodes, U_32** totalSharedWeight) = 0;
	virtual bool isStarted(void) = 0;
	virtual IDATA restoreFromSnapshot(J9JavaVM* vm, const char* cacheName, bool* cacheExist) = 0;
	virtual I_32 tryAdjustMinMaxSizes(J9VMThread *currentThread, bool isJCLCall = false) = 0;
};

SH_CompositeCacheImpl is much much larger. The implementation of the CompositeCacheImpl
class, which inherits from SH_CompositeCache, of course, is in CompositeCache.cpp.

Composite caches are linked lists of composite caches that represent the view of shared
class in terms of blocks of memory. Each node in the list has its own locks for reading
and writing. Cache entries grow from the back, memory segments from the front.
CompositeCache.cpp contains a helpful diagram. Top of the file, can't miss it!!

The start of the block (the node in the list managed by this object) is stored in
the member variable _theca.

A J9SharedCacheHeader contains a bunch of useful information about the layout of each
cache block.. its updateSRP, readWriteSRP, etc.. how they're all maintained in relation
to one another. Also, it has lots of statistics on how many bytes are taken up by
different types of data, like JIT and AOT code.

Importantly, each SH_CompositeCacheImpl contains an SH_OSCache *. Part of our work will
be uncovering the relationship between the two!

BTW, a cachelet is an SH_CompositeCache nested *within* an SH_CompositeCache!! Why you'd
ever want to use it (and from Hang Shao's comments, they do not!) I dunno.
'newInstanceNested' and 'newInstanceChained' are both walled off behind the
J9SHR_CACHELET_SUPPORT conditional, so we will not document them here (for now).

Back to _theca.. it's not set until way down in ::startup. Late in the file.

In 'startup', cacheMemory is argument that is non-NULL only if we are UnitTesting
the cache and want to avoid using the OSCache, per the comments. Otherwise, we are
using the OSCache to store shit in. _oscache is initialized primarily in 'initialize',
but a few other places as well. The cacheName is provided to SH_OSCache's static
'newInstance' function, which builds the subclass of SH_OSCache that applies, as we
saw earlier.

Back to 'startup'. oscache calls its 'startup' method, and we pass _runtimeFlags,
_verboseFlags, etc. along to it. Then, if we 'hasWriteMutex' (ie. the CompositeCache
object's 'startup' secured the CompositeCache's write mutex), we do something like this:

		if (cacheMemory != NULL) {
			_theca = (J9SharedCacheHeader*)cacheMemory;
		} else {
	    	_theca = (J9SharedCacheHeader*)_oscache->attach(currentThread, &versionData);

That's right, we get the _dataStart of _oscache and store it in our _theca. Yep.
Then we check if the cache hasn't already been corrupted. Presumably by a concurrently
running VM that is trying to do the same thing we are. If so, do the usual error reporting
song and dance and return; if not, do a veritable fuckton of other crap. Corruption
and error checking and reporting, and writing numbers to stats variables, mostly.

_theca is a J9SharedCacheHeader, which looks like this:

typedef struct J9SharedCacheHeader {
	U_32 totalBytes;      /* set to
	piconfig->sharedClassCacheSize. the size of the entire cache
	as a file, or a block of shared memory. */
	U_32 readWriteBytes;  /* size of the readWriteArea */
	UDATA updateSRP;      /* the 'free' part, growing leftward
	from the metadata area (the cache entries part of the cache). */
	UDATA readWriteSRP;   /* the 'written' readWrite area, its
	startpoint, growing rightward */
	UDATA segmentSRP;     /* the 'free part' of the segment entry,
	growing rightward */
	UDATA updateCount;    /* the number of updates since the last
	nextEntry() call; why is this useful? */
	J9WSRP updateCountPtr; /* initialized to the address of
	updateCount, in this very header */
	volatile UDATA readerCount; /* incremented in conjunction
	with locking the cache, for reads. */
	UDATA unused2; /* it's unused! I don't know why it's here. Ask
	Hang. */
	UDATA writeHash; /* used to record the hash value of the class
	being cached. */
	UDATA unused3;
	UDATA unused4;
	UDATA crashCntr; /* used to count the number of actors
	performing critical section updates! critical in the sense
	that if they fail, the cache will 'crash', ie. be corrupted. */
	UDATA aotBytes; // I don't know what the next two fields do.
	UDATA jitBytes;
	U_16 vmCntr; // the number of VMs using the cache.
	U_8 corruptFlag; // 0 or 1, boolean value flagging corruption.
	U_8 roundedPagesFlag; // 0 or 1, boolean value indicating roundedPages.
	I_32 minAOT; // minimum reserved space for AOT code.
	I_32 maxAOT; // maximum reserved space for AOT code.
	U_32 locked; // is the cache locked? also a boolean.. 0 or 1.
	J9WSRP lockedPtr; // the pointer to the locked field in this header.
	J9WSRP corruptFlagPtr; /* the pointer to the corruptFlag field
	in this header. */
	J9SRP sharedStringHead; /* I can't find anywhere in the ported
	shared cache this is used. Even in OpenJ9, it doesn't appear
	to be used anymore. My guess: it's vestigial.*/
	J9SRP sharedStringTail; // ditto.
	J9SRP unused1;
	U_32 totalSharedStringNodes; /* has no use anywhere in OpenJ9. */
	U_32 totalSharedStringWeight; /* same. */
	U_32 readWriteFlags; /* set to
	OMRSHR_HEADER_STRING_TABLE_INITIALIZED in CompositeCache.cpp,
	does seem to be read anywhere, not even in OpenJ9. */
	UDATA readWriteCrashCntr; /* incremented when we enter the
	string table mutex, and decremented when we have it. This
	flags a crash if the decrement isn't reached because of a VM
	crash in the midst of entering the mutex. */
	UDATA readWriteRebuildCntr; /* used to detect the need for a
	cache rebuild. Flagged if oldReadWriteCrashCntr (the value of
	_theca->readWriteRebuildCntr before the increment in
	enterReadWriteMutex) doesn't equal readWriteRebuildCntr. */
	UDATA osPageSize; /* the size of pages used to layout the
	OSCache */
	UDATA ccInitComplete; /* boolean, is the compositecache
	startup complete? */
	UDATA crcValid; /* is the CRC valid? */
	UDATA crcValue; /* the CRC value. */
	UDATA containsCachelets; /* cachelets are obsolete, and are
	never used now. */
	UDATA cacheFullFlags; /* is the cache full? which section? AOT
	section? JIT section? a bitvector. */
	UDATA readWriteVerifyCntr; /* I.. don't know what this
	does. If the resetReason in exitReadWriteAreaMutex is not
	J9SHR_STRING_POOL_OK, we use it for some reason. Otherwise it
	appears nowhere. */
	UDATA extraFlags; /* pertains to
	OMRSHR_EXTRA_FLAGS_*.. flags. Again, a bit vector. */
	UDATA debugRegionSize; /* The size of the debug region. */
	UDATA lineNumberTableNextSRP; /* There is a table for storing
	line numbers of methods! Apparent the debug area stores only
	line numbers and local variables. Free space is calculated as
	localVariableTableNextSRP - lineNumberTableNextSRP. */
	UDATA localVariableTableNextSRP; // see above.
	I_32 minJIT; // minimum reserved space for JIT.
	I_32 maxJIT; // maximum reserved space for JIT.
	IDATA sharedInternTableBytes; /* initialized as
	sharedClassReadWriteBytes. The size of the
	readWriteArea. Initialized in several places as that value,
	calculated according to the available data. */
	IDATA corruptionCode; // self-explanatory.
	UDATA corruptValue; // same.
	UDATA lastMetadataType; /* type of the last piece of the
	metadata added to the metadata area. */
	UDATA writerCount; /* increment the number of concurrent
	writers. used when entering and exiting the write mutex. */
	UDATA unused5;
	UDATA unused6;
	U_32 softMaxBytes; /* I don't know what the soft maximum is
	for. Ask Hang. */
	UDATA unused8;
	UDATA unused9;
	UDATA unused10;
} J9SharedCacheHeader;

'getRequiredConstrBytes' indicates that is an OSCache instance is to
be built with the object (ie. we are not doing any UnitTest'ing),
since the sizeof(OSCache) is included in the reqBytes value returned
by the function!! This indicates they are to be built on the same
block.

'getRequiredConstrBytesWithCommonInfo' gets the constructor size of
'getRequiredConstrBytes', plus the size of
J9ShrCompositeCacheCommonInfo, which houses data common to *all*
composite caches, as the name would suggest. It's:

typedef struct J9ShrCompositeCacheCommonInfo {
	omrthread_tls_key_t writeMutexEntryCount; /* Only used if the
	   writeMutexID has the value CC_READONLY_LOCK_VALUE, which is true
	   iff _readOnlyOSCache is true. In that case, no one ever writes to the cache.
	   This plays the role of a reader count, but.. a 'writer' count. It's used
	   to tell whether the current thread holds the write mutex, in this case, since
	   no actual write mutexes are being held. 
	*/
	struct J9VMThread* hasWriteMutexThread; /* the thread holding
	the write mutex. */
	struct J9VMThread* hasReadWriteMutexThread; // Similar.
	struct J9VMThread* hasRefreshMutexThread; // Similar.
	struct J9VMThread* hasRWMutexThreadMprotectAll; // Similar.
	U_16 vmID; // which VM is this?
	U_32 writeMutexID; /* .. is passed to
	oscache->acquireWriteLock. I'm not sure how it works. Beyond
	being a lockID. From the implementation in OSCachemmap.cpp,
	the lockID is actually more appropriately called a lock
	type. It takes values like J9SH_OSCACHE_MMAP_LOCKID_WRITELOCK,
	*_READWRITELOCK, etc. Also it determines the offset of the
	lock into the OSCachemmap_header. And then an index into the
	_lockMutex array of OSCachemmap. Then it acquires the lock to
	lock between processes and threads. */
	U_32 readWriteAreaMutexID; // same thing, I think. Yes.
	UDATA cacheIsCorrupt; // a 0-1 boolean.
	UDATA stringTableStarted; // a 0-1 boolean.
	UDATA oldWriterCount; /* the writer count before we (the
	current thread in the current VM) incremented it. */
} J9ShrCompositeCacheCommonInfo;

ShcItemHdr is this:

typedef struct ShcItemHdr {
	U_32 itemLen; 		/* lower bit set means item is stale */
} ShcItemHdr;

Why do I bring this up?? Because the composite cache can be
'scanned'.. that is, its contents can be walked.

I went down to 'nextEntry' to see how the cache is iterated over,
starting from 'findStart'. It depends on these macros, defined in
shcdatatypes.h :

#define CCITEMLEN(ih) (J9SHR_READMEM((ih)->itemLen) & 0xFFFFFFFE)
#define CCITEMSTALE(ih) (J9SHR_READMEM((ih)->itemLen) & 0x1)
#define CCSETITEMLEN(ih, len) ((ih)->itemLen = (len & 0x1) ? len+1 : len)
#define CCSETITEMSTALE(ih) ((ih)->itemLen |= 0x1)
#define CCITEM(ih) (((U_8*)(ih)) - (CCITEMLEN(ih) - sizeof(ShcItemHdr)))
#define CCITEMNEXT(ih) ((ShcItemHdr*)(CCITEM(ih) - sizeof(ShcItemHdr)))

Before examining methods, we should look to fields! Here they are.

  	OMRSharedClassConfig* _sharedClassConfig; /* the index of
	function pointers. */
	SH_OSCache* _oscache; /* The underlying OSCache object that
	provides the data and functions to manage it. */
	omrthread_monitor_t _utMutex, _headerProtectMutex,
	_runtimeFlagsProtectMutex; /* thread-level management for the
	components of the composite cache. */

	OMRPortLibrary* _portlib; /* the cross-platform library. wraps
	routines and so forth. */

	J9SharedCacheHeader* _theca; /* The header at the header of
	the cache, after the OSCache header, which is
	subclass-dependent. */
	bool _started; // is the cache started?
	const char* _cacheName; /* the name of the cache. Derived from
	the version, and generated of the cache, used. */

	SH_CompositeCacheImpl* _next;   // not used! cachelets are obsolete.
	SH_CompositeCacheImpl* _parent; // same.
	SH_CompositeCacheImpl* _ccHead; /* the head of the cache, as
	distinct from.. this one itself? Probably just equal to 'this'. */

	ShcItemHdr* _scan; // the scan pointer.
	ShcItemHdr* _prevScan;
	ShcItemHdr* _storedScan;
	ShcItemHdr* _storedPrevScan;
	BlockPtr _romClassProtectEnd; /* Has the simplest possible
	getters and setters. Used in shrtest, and no where else. */

	UDATA _oldUpdateCount; /* the update count prior to the latest
	change to the update count. */

	U_32 _storedSegmentUsedBytes; /* How many stored segment bytes
	were used in an allocation? Of those stored in the segment region,
	how many have been used? */
	U_32 _storedMetaUsedBytes; // Similar.
	U_32 _storedAOTUsedBytes;  // Similar.
	U_32 _storedJITUsedBytes;  // Similar.
	U_32 _storedReadWriteUsedBytes; // Similar.
	U_32 _softmxUnstoredBytes; // Similar.
	U_32 _maxAOTUnstoredBytes; // Similar.
	U_32 _maxJITUnstoredBytes; // Similar.
	I_32 _maxAOT; /* Separate from _theca->maxAOT. Seems to be
	work like a liaison to _theca->maxAOT. Nope, at least, not
	within CompositeCache.cpp. */
	I_32 _maxJIT; /* Same deal as with _maxAOT. */

	U_64* _runtimeFlags; /* A bitvector tracking various
	OMRSHR_RUNTIMEFLAG_* values. */
	UDATA _verboseFlags; /* A bitvector tracking various
	OMRSHR_VERBOSEFLAG_* values. */
	UDATA _cacheFullFlags; /* A bitvector tracking regions
	of the cache that are full. */

	U_32 _totalStoredBytes; /* the total bytes stored in the cache */

	UDATA _lastFailedWriteHash; /* the hash value of the last
	class that failed to be found on disk (or in shared
	memory). */
	U_32 _lastFailedWHCount; /* how many times has the
	write hash remain unchanged? which is to say failed? We don't
	care about thread safety for this field, as the exactness of
	the value isn't important, according to the comments. I don't
	know why, exactly, it's not important. The count being greater
	than FAILED_WRITEHASH_MAX_COUNT is the only place it's checked
	within CompositeCache. */

	BlockPtr _readWriteAreaStart; // the start of the read write area!
	U_32 _readWriteAreaBytes; // the size of the read write area.
	BlockPtr _readWriteAreaPageStart; /* _readWriteAreaStart
	rounded down to the next multiple of _osPageSize. */
	U_32 _readWriteAreaPageBytes; /* _readWriteAreaPageBytes
	rounded *up* to the next multiple of _osPageSize. */

	BlockPtr _cacheHeaderPageStart; /* same thing as documented
	with _readWriteAreaPageBytes, but with the cache header in
	place of the read write area. */
	U_32 _cacheHeaderPageBytes; // same thing.

	UDATA _osPageSize; /* the size of pages used as a unit of page
	size in the underlying OSCache. */

	UDATA _nestedSize; // cachelet thing! irrelevant.
	BlockPtr _nestedMemory; // same.

	UDATA _localReadWriteCrashCntr; /* appears in startup() a few
	times. I don't really know what it means when variables and
	functions in the CompositeCache are designated 'local'. I will
	ask Hang. */

	J9MemorySegment** _metadataSegmentPtr; /* points to the field
	of the same name in _sharedClassConfig. Not sure what it
	does. */
	J9MemorySegment* _currentROMSegment; /* not paid much
	attention in the CompositeCache. Mostly just defines getters
	and setters. These are used in the CacheMap, however. */

	bool _doReadWriteSync; /* do we sync updates to the
	readWriteArea? In effect only under the mandate of the
	OMRSHR_MYSNC_SUPPORT flag. */
	bool _doHeaderReadWriteProtect; /* Encoded by
	OMRSHR_RUNTIMEFLAG_ENABLE_MPROTECT_RW being flagged. */
	bool _readWriteAreaHeaderIsReadOnly; /* Set to true if we're
	protecting the header (_doHeaderProtect, one below) and if the
	_headerProtectCntr == 1. */
	bool _doHeaderProtect; /* Encoded by
	OMRSHR_RUNTIMEFLAG_ENABLE_MPROTECT_ALL. */
	bool _doSegmentProtect; /* Set if we don't contain cachelets,
	for some reason, and since cachelets are now obsolete, we
	never contain cachelets! So this is always true.. we always
	want to protect the ROM segments. The segments are where the
	ROM classes are stored. */
	bool _doMetaProtect; /* Encoded by
	OMRSHR_RUNTIMEFLAG_ENABLE_MPROTECT. */
	bool _doPartialPagesProtect; /* Encoded by
	OMRSHR_RUNTIMEFLAG_ENABLE_MPROTECT_PARTIAL_PAGES. I don't know
	what partial pages are. I'm confused by the concept. A page is
	an atom, an indivisible unit, you heathen motherfuckers. */
	bool _readOnlyOSCache; // is the underlying OSCache read-only?
#if defined (J9SHR_MSYNC_SUPPORT)
	bool _doMetaSync; /* the following three: determine whether we
	sync the metadata, header, and ROM segment areas. */
	bool _doHeaderSync;
	bool _doSegmentSync;
#endif

	IDATA _headerProtectCntr; /* A value of 1 indicates that the
	header is unprotected, according to the comments. This is
	distinguished from the later counters. */
	IDATA _readWriteProtectCntr; // 1 doesn't mean unprotected.
	IDATA _readOnlyReaderCount; // Same.
	bool _incrementedRWCrashCntr; /* counts the number of VMs
	accessing the read/write area while it is protected, so that
	we can diagnose the cause of a crash, should it occur while
	the RW area is protected. */

	bool _useWriteHash; // do we use the writeHash?

	bool _canStoreClasspaths; // can the cache store Java classpaths?

	bool _reduceStoreContentionDisabled; /* is the reduce store
	contention option enabled? Encoded by
	OMRSHR_RUNTIMEFLAG_ENABLE_REDUCE_STORE_CONTENTION. */

	/* All instances of this class share a common debug & raw class data region
	 */
  //	ClassDebugDataProvider * _debugData;

	/* All composite caches within a JVM point to the same 'J9ShrCompositeCacheCommonInfo'
	 * structure. Set *before* the shared cache is started.
	 */
	J9ShrCompositeCacheCommonInfo * _commonCCInfo;

--

Now methods.

'newInstance' is indeed static, belonging to
SH_SharedCacheHeaderInit. It's init method is virtual, and thus,
instance-based. Uses placement new to construct a
SH_CompositeCacheImpl(), and calls initializeWithCommonInfo() on it.

'getFreeBlockBytes' uses the minAOT flags in the header to determine
whether AOT and JIT space is being allocated at all! In other words,
if their values are negative, there is no reserved space for AOT or
JIT. It calculates the free block space available in the class,
without the space that's been reserved for JIT and AOT. FREEBYTES, the
macro, corresponds to exactly the region you think it would in the
all-important CompositeCache diagram.

'initializeWithCommonInfo' calls 'initCommonCCInfoHelper', then 'initialize'.

'initialize' calls 'commonInit', and 'setCurrentCacheVersion'. Guess
what the latter does!! _osPageSize is computed in terms of region
granularity!! 'j9mmap:get_region_granularity' is called for this
purpose... verily! Otherwise it's initialized to 0. This is if we are
unit testing, I think. UnitTest is just a wrapper around the enum,
with a static IDATA to contain an enum value. If UnitTest is ==
NO_TEST, no tests are performed.. the explanation I just gave applies
if UnitTest::unitTest != NO_TEST or CORRUPT_CACHE_TEST.

If startupForStats is true (meaning that we want to enable the reading
of cache statistics, and ONLY THAT.. we cannot write to or delete the
cache), _oscache is NULL. We.. do some stuff we would ordinarily do,
but without regard to previous cache generations. I take this to mean
that gather stats using startupForStats is not supported for previous
generations of the cache.

Notice that the OSCache is not initialized if we are "startupForStats"
or if some unit test is active. _oscache is only initialized in the
'else' case. The '*_CREATE_OLD_GEN' runtime flag decrements the cache
generation to *one* before the current.

'getRequiredConstrBytes' computes the required bytes needed to build
an object instance, according to the comments. An 'object instance' in
this case is necessarily an instance of SH_CompositeCache, as well as
the OSCache attached to the _oscache pointer. Notice that the criteria
to include OSCache::getRequiredConstrBytes() as a summand in the
reqBytes return value are exactly those that determine whether
_oscache is initialized or left NULL in 'initialize'! In summary, they
are the following:

1) sizeof(OSCache) (if applicable)
2) sizeof(SH_CompositeCacheImpl)
3) sizeof(SH_CompositeCacheImpl::SH_SharedCacheHeaderInit)
4) sizeof(ClassDebugDataProvider)

'getRequiredConstrBytesWithCommonInfo' calls 'getRequiredConstrBytes'
with exactly the same parameters, isNested and startupForStats. It
takes its value, and adds sizeof(J9ShrCompositeCacheCommonInfo).

'cleanup' mostly acts as a delegate to _oscache->cleanup(). It also
releases the _headerProtectMutex and _runtimeFlagsProtectMutex, frees
the writeMutexEntryCount TLS, etc.

'crashDetected' checks that *localCrashCntr != _theca->crashCntr. You
see, this object that we are currently in is local to a thread.. but
the _theca is cross-thread and possibly cross-process. So if the two
do not agree at the point 'crashDetected' was called, we are in
trouble. Something has crashed!! We return true. Otherwise, we return
false. Note that localCrashCntr was passed in as an argument, which
you can see from the formatting of the variable name. 'crashDetected'
is used from SH_CacheMap's 'checkForCrash', which keeps
_localCrashCntr as a field. More on that when we study CacheMap.

'reset' mainly resets the _stored* fields and the _oldUpdateCount (as
well as the _maxAOTUnstoredBytes and _maxJITUnstoredBytes fields) to
0. It first calls 'findStart', and bookends the resetting of the named
fields with 'doUnlockCache'. 'findStart', we recall, sets _prevScan to
_scan and _scan to the first entry in the cache entries section of
_theca.

'isCacheCorrupt' checks if _commonCCInfo->cacheIsCorrupt is true, and
is so, returns true. If not, it goes to the supercache (again, an
obsolete concept now that cachelets are obsolete) and checks its
_theca->corruptFlag. If it's not 0, guess what?!? The cache is
corrupt.

'setCorruptCache' sets _commonCCInfo->cacheIsCorrupt = 1. If the cache
has been started, it calls 'ccToUse->unprotectHeaderReadWriteArea'
(usually ccToUse == this, unless cachelets are active, which they
never are anymore!). It calls 'getCorruptionContext' to record the
corruption code and value (the corrupt value) to
_theca->corruptionCode and _theca->corruptValue. If we aren't using
UnitTest to test a corrupt cache, and statistics gathering isn't
enabled (via the J9SHR_RUNTIMEFLAG_ENABLE_STATS), we set
_theca->corruptFlag to 1. Finally, we call
ccUse->protectHeaderReadWriteArea.

'setCorruptCache' has a second, overloaded version that takes two
additional parameter: the corruptionCode and corruptValue (the corrupt
value in the cache indeed, confirmed in the preamble comments) as
parameters. It sets those values in the underlying _oscache, if it
exists. (Where are the stats stored, if not the OSCache? Which is not
initialized if we "startupForStats").

'setCacheAreaBoundaries' sets up the various boundaries of the cache.
According to the diagram that leads the source file, in fact.

As the comments say, the read/write area, for now, is home only to the
shared intern string table. "String interning" is the practice of
keeping single immutable copies of strings around in the memory for
the sake of efficiently using space. There are a few circumstances
where the size of the readWriteArea is 0: -Xitsn, the command line
argument, is how the user defines the size of the shared string intern
table. If it's 0, so goes the read/write area! Also, it may be 0 if
the user explicitly defines -Xitsn to be 0.

That's the main thing. Either of these circumstances will set
piConfig->sharedClassReadWriteBytes to -1 and finalReadWriteSize to
0. If that is true, we reset finalReadWriteSize to a portion of the
cache size, aligned by the word. J9SRPHashTable nodes correspond to
the 'buckets' of the hash table, which are filled via linear probing,
from what I can tell. The number of nodes is the number of buckets, in
other words.

Anyway, once the number of shared nodes is calculated (which is
essentially a quotient between the finalReadWriteSize and the sizeof
J9SharedInternSRPHashTableEntry, rounded up or down to the nearest
prime number), finalReadWriteSize is set to that. Keep in mind, these
calculations occur only if the finalReadWriteSize was initialized to
0, as described above.

The final segment size is computed in a single line, in consequence of
finalReadWriteSize being computed, precisely where the diagram says it
should start. There's padding added in the address to ensure it starts
at a word-aligned address.

If J9SHR_RUNTIMEFLAG_ENABLE_ROUND_TO_PAGE_SIZE, we round up to
_osPageSize, and recalculate the end of the cache to ensure it ends on
a page boundary (the cache end is rounded *down* as you might
suspect). _theca->readWriteBytes is computed to match the size of the
read/write area, and _theca->totalBytes is the total size of the cache
(which was modified if the cache size was rounded down in the previous
check).

Then we set _theca->sharedInternTableBytes. It's easy! Reflects the
same logic described above. Then we check to see that _parent is
non-NULL. I'm unsure about the role of it absent cachelets. If it
isn't NULL, ClassDebugDataProvider::HeaderInit is called.

If _theca->softMaxBytes isn't -1, we call 'getUsedBytes()' and store
it to usedBytes. If _theca->softMaxBytes < usedBytes, we call
'setSoftMaxBytes' with the current thread and usedBytes as parameters.

Lastly, if _runtimeFlags has
J9SHR_RUNTIMEFLAG_ENABLE_ROUND_TO_PAGE_SIZE is toggled, and
'isVerbosePages' returns true, we print a ton of diagnostic info to
tty, using j9tty_printf.

An SRP hashtable is also stored within its depths!! This
determines the value of finalReadWriteSize, in part, under the right
conditions. It contains "numOfSharedNodes" entries. I'm not sure what
a "shared node" is.

It goes through some trouble to determine finalReadWriteSize.  This
determines the size of the read/write area after the shared cache
header. The start of the segment area is much much easier to compute.
If the "ENABLE_ROUND_TO_PAGE_SIZE" option is enabled, then
finalSegmentStart, newCacheEnd, etc. are rounded to the size of a
page. Whatever the value of _osPageSize is.

"Currently the read write area of composite cache is only used by
shared string intern table."

Sounds as though that's the SRP hash table that determines the size of
the read/write area! Then, since we're not using cachelets (we never
use cachelets!), the ClassDebugDataProvider calls its static
'HeaderInit' method.

A debug message is printed if the composite cache size was rounded
down to a page's size, and we're done.

But verily, we are writing segmentSRP and updateSRP in this
segment. So it's all good, I think.

'isLocked'.. finds the appropriate cache using the usual ternary
expression that selects between _ccHead, _parent and _this, based upon
which of the three is not NULL.

'setLocked'.. toggles _ccToUse->_theca->locked. Any time you see
ccToUse, you should keep the aforementioned ternary expression in
mind. It appears frequently.

'notifyPagesRead' tells the cache that a series of pages are being
read. This executes only if the cache is unlocked, and if memory
protection on the cache has been enabled (see the opening condition,
it's one of the RUNTIME_FLAGS). The condition wraps the entire body of
the function. The start and end parameters, the region to protect for
reading, are rounded up or down to the nearest page boundaries,
depending on the direction (ie. if start < end or end < start). The
rounded start and end are called protectStart and protectEnd. If
they're not equal, *then* we call 'setRegionPermissions'. Then there's
some trace messages emitted if rc, the result code, is non-zero.. but
otherwise we're done.

Question for Hang: why is locking the cache a separate operation from
memory protecting regions of the cache??

A: Memory protection is to protect from access by malicious
processes. Locking the cache is done to protect the cache when it is
being read.

'notifyPagesCommitted' If J9SHR_MSYNC_SUPPORT is toggled in
_runtimeFlags, we computed the actual direction (again, based on
whether start < end or end < start), round them up or down to the
nearest page boundary, and call _oscache->syncUpdates. Sync'ing
flushes updates made to a memory-mapped file back to disk. It has similar
effects with shared memory.. the idea is to intercalate concurrent
writes so that they don't overstep each other.. anyway,
'notifyPagesCommitted' ends by calling 'notifyPagesRead'.

So, 'startup'! We begin by setting a ton of local variables (all of
these are easy to understand!! on lines 1025 - 1053). If the _parent
is NULL for some reason, we toggle the openMode local variable /
argument. These are modes which are somewhat like UNIX style open
modes, but not really. They govern the open mode of the OSCache, which
we.. really should've documented before. createFlags, same
deal. openMode later goes on to decide whether the OSCache is open in
read-only mode. 'startup' is called with the parameter isFirstStart,
which determines whether the cache has been started before. 'startup'
either connects to a running cache, or starts an entirely new one.

After we configure openMode and createFlags, we try to get
_headerProtectMutex and _runtimeFlagsProtectMutex. Then, if firstStart
== true, we set _commonCCInfo->cacheIsCorrupt = 0. If _osPageSize is
0, *_RUNTIMEFLAG_ENABLE_ROUND_TO_PAGE_SIZE is toggled off in
_runtimeFlags. If it is still enabled after this, we round up
piconfig->sharedClassCacheSize to *twice* the _osPageSize, if we
can. Otherwise, we round the sharedClassCacheSize *down* to the next
multiple of _osPageSize. So it all aligns.

Then we make sure that piconfig->sharedClassCacheSize is between
MIN_CC_SIZE and MAX_CC_SIZE.

Then we set *actualSize = 0. For we do not know the actual size yet!

There's another argument to 'startup', a BlockPtr named
cacheMemory. It's used when unit testing to ensure that _oscache is
NULL if we are unit testing, which is something we noticed
earlier. For normal use, cacheMemory is always 0. Always. If
cacheMemory isn't NULL, we check that the composite cache
initialization and startup are complete, at which point we initialize
headerInit by calling headerInit->init() (with some arguments, it's
not an empty argument list).

Next, if _parent == NULL, we know we're unit testing!! And we toggle
_readOnlyOSCache according to whether J9OSCACHE_OPEN_MODE_DO_READONLY
is true in openMode. If _readOnlyOSCache becomes true from this, we
set _commonCCInfo->writeMutexID and
_commonCCInfo->readWriteAreaMutexID to CC_READONLY_LOCK_VALUE. The
same TLS key (I believe! this is something I've yet to confirm). If
isFirstStart is true, we also allocate a TLS key for
_commonCCInfo->writeMutexEntryCount, and we try to initialize the
_utMutex (the trace/logger).

If cacheMemory is NULL, we go about the usual thing. That is, we set
the current cache version by calling setCurrentCacheVersion.. and from
there we call _oscache->startup(). We set OSCStarted =
_oscache->startup(..). The bad BUILDID test is disabled in the runtime
flags, since it only applies during testing. If OSCStarted is false,
we check if _oscache was corrupted. By comparing _oscache->getError()
to J9SH_OSCACHE_CORRUPT, because that will the error value if so. If
we disable corrupt cache dumps, we trigger it. And we set the
corruption context and value by calling 'setCorruptCache', and return
CC_STARTUP_CORRUPT.

If that was not the error, we check to see that the error is
J9SH_OSCACHE_NO_CACHE. And we return CC_STARTUP_NO_CACHE.

So, if OSCStarted == false, we return from 'startup'. Otherwise, we
keep going!

If _readOnlyOSCache is true, set the _commonCCInfo write and
readWriteArea mutex ID's to CC_READONLY_LOCK_VALUE.. again, as
before. Same thing with writeMutexEntryCount that we just went over in
the testing branch. We are repeating ourselves here, so eat your heart
out, Uncle Bob.

Otherwise, if the OS Cache isn't readonly, and isFirstStart is true,
we do... same thing. Set _commonCCInfo->writeMutexID and
_commonCCInfo->readWriteAreaMutexID via _oscache->getWriteLockID() and
_oscache->getReadWriteLockID(). If we fail to return either of these,
we return with CC_STARTUP_FAILED.

If we don't have the write mutex (ie. hasWriteMutex == false), we try
to claim the write mutex by calling 'enterWriteMutex'. Using either
this CC, or the _parent, if _parent is non-NULL. If the result was 0,
meaning we succeeded, we toggle hasWriteMutex = doReleaseWriteMutex =
true, and we continue.

Then we check to see that hasWriteMutex is true. But first, a burning
missive from Hang Shao:

yes, _parent is always NULL now that cachelets are not a thing, which
would indicate the same is true of _ccHead.

Ok, where we left off, hasWriteMutex was true. We set _oldUpdateCount
to 0. If _cacheMemory != NULL, we set _theca to be the
J9SharedCacheHeader pointed to by cacheMemory.. otherwise, we
initialize _theca by _theca =
(J9SharedCacheHeader*)_oscache->attach(..).

Either way, _theca comes out non-NULL, or rather it should. If _theca
!= NULL, we check that the CC_INIT_COMPLETE flag fails to holds in
_theca->ccInitComplete, and that !_readOnlyOSCache is true.  If this
is true, we set rc = CC_STARTUP_CORRUPT, we call 'setCorruptCode' with
the corrupt context values (*_INIT and _theca->ccInitComplete, in this
case) and we goto releaseLockCheck (the label of that name).

If that if failed to fire, is we check that isCacheInitComplete() ==
true. If so, and also, _theca->osPageSize != _osPageSize, we goto
releaseLockCheck again, setting rc = CC_STARTUP_RESET. Then there's a
section dedicated exclusively to WIN32 and its weird handling of
virtual memory, but I think we can safely ignore that for
now. Skipping down to line 1314.

If !isCacheCorrupt() is true, and !checkCacheCRC(), then the CRC is
deemed invalid.. and the cache is indeed corrupt, with crcValue being
the corrupt value, and CACHE_CRC_INVALID the corruption code. If
!isCacheCorrupt() is false, we force a cache dump if _runtimeFlags is
configured appropriately.

If it remains true that !isCacheCorrupt(), we continue on (at line
1329). We set retryCntr = 0 (a local variable). If !_readOnlyOSCache,
we set _theca->crcValid = 0. Otherwise, If isCacheInitComplete() ==
false, and retryCntr < J9SH_OSCACHE_READONLY_RETRY_COUNT, we sleep a
*_SLEEP_MILLIS count of milliseconds before incrementing retryCntr. If
isCacheInitComplete() == false, we set rc = CC_STARTUP_FAILED and goto
releaseLockCheck.

So! Suppose isCacheInitComplete() returns false. We check to see that
_ccHead != NULL. If it isn't, we set _theca->updateCountPtr,
_theca->corruptFlagPtr, and _theca->lockedPtr with the values of each
of their counterparts in _ccHead->_theca.

Then, regardless of what happened in the previous paragraph, we set
*actualSize = _theca->totalBytes. If isCacheInitComplete() == false,
we are starting a new cache! So set _initializingNewCache = true. We
check a few flags, and toggle the extraFlags variable (just
initialized in this branch to 0) according to these settings:

1) J9VM_DEBUG_ATTRIBUTE_LINE_NUMBER_TABLE |
J9VM_DEBUG_ATTRIBUTE_SOURCE_FILE being false => *_NO_LINE_NUMBERS in
extraFlags
2) J9SHR_RUNTIMEFLAG_ENABLE_CACHERETRANSFORMED? =>
*_runtimeFlags |= J9SHR_RUNTIMEFLAG_DISABLE_BCI
3) !J9SHR_RUNTIMEFLAG_DISABLE_BCI =>
*_runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_BCI;
extraFlags |= J9SHR_EXTRA_FLAGS_BCI_ENABLED;
4) J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_PARTIAL_PAGES* =>
extraFlags |= J9SHR_EXTRA_FLAGS_BCI_ENABLED;
*_runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_BCI;
5) J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_PARTIAL_PAGES* =>
extraFlags |= J9SHR_EXTRA_FLAGS_MPROTECT_PARTIAL_PAGES
5a) if J9SHR_RUNTIMEFLAG_MPROTECT_PARTIAL_PAGES_ON_STARTUP* =>
    extraFlags |= J9SHR_EXTRA_FLAGS_MPROTECT_PARTIAL_PAGES_ON_STARTUP;
6) J9SHR_RUNTIMEFLAG_RESTRICT_CLASSPATHS* =>
extraFlags |= J9SHR_EXTRA_FLAGS_RESTRICT_CLASSPATHS;

A * at the end of the flag means the flag is checked with
J9_ARE_ALL_BITS_SET; ? corresponds to *_ANY_* and ! to *_NO_*.

Then 'setCacheHeaderExtraFlags' is called with extraFlags as an
argument, and similarly for 'setCacheAreaBoundaries'. This is because
the cache is new. These options need to be set. Finally,
_canStoreClasspaths = true.

Now, alternatively, if isCacheInitComplete() == true.. we call
'checkCacheCompatibility'. If the return value is false, set rc =
CC_STARTUP_FAILED, and goto releaseLockCheck. We compute
_canStoreClasspaths again, for this branch (the work in the previous
one was, of course, deferred! that is how conditionals work). We can
if (false == this->isRestrictClasspathsSet(currentThread)) ||
J9_ARE_ALL_BITS_SET(*_runtimeFlags,
J9SHR_RUNTIMEFLAG_ALLOW_CLASSPATHS)). We will examine these later!

If we _canStoreClasspaths, we emit some trace messages saying so, and
we toggle the *_RESTRICT_CLASSPATHS flag off in _runtimeFlags. I'll
let the comments above explain the next cache section:

/* If cache is created with partialpage protection enabled then use the cache in that mode,
 * and ignore any incompatible option like mprotect=nopartialpages or mprotect=none.
 * Similarly, if the cache is created with mprotect=nopartialpages, then use the cache in that mode,
 * and unset runtime flags for protecting partially filled pages.
 */

All of it is just making sure _runtimeFlags is consistent with respect
to potentially contradictory options being enabled at once. Thank
Christ, it would've been so tedious to read and most importantly for
me to explain.

We set _prevScan and _scan to
(ShcItemHdr*)CCFIRSTENTRY(_theca). Without reserve, without
controversy! No qualifying conditions are checked before this can
happen.

If this is the first start.. we store _theca to
_sharedClassConfig->cacheDescriptorList->cacheStartAddress, so that
external users of the VM can reach it. We also set _metadataSegmentPtr
= &(_sharedClassConfig->metadataMemorySegment).

Next, if isFirstStart is true, we increment _theca->vmCntr if the
cache isn't read only, or, we set _commonCCInfo->vmID = _theca->vmCntr
+ 1 if it is. Note that we can modify _commonCCInfo with impunity,
even if _readOnlyOSCache is true! But _theca->vmCntr must be modified
with care. If there is integer overflow from the increment, the
_commonCCInfo->vmID is incremented once more, since it cannot be
allowed to be 0! Watch for the vmID, I think it may used as a flag
that the CC hasn't been initialized.

Next, *localCrashCntr = _theca->crashCntr. Because, of
course. localCrashCntr is the VM local counter of crashes, and
_theca->crashCntr is at the centre of it all. If !_readOnlyOSCache &&
isLocked(), call setIsLocked(false). This indicates that another JVM
crashed while it had locked the cache, and being here now, with a
non-readonly cache, we need to unlock it.

Next, _readWriteAreaStart and _readWriteAreaBytes are initialized in
the most uninteresting manner possible, based on whether
READWRITEAREASIZE(_theca) is non-zero.

Then, based on whether J9SHR_MSYNC_SUPPORT is defined true (or false)
in the C preprocessor, we toggle (or untoggle) a few flags having to
do with MPROTECT settings in _runtimeFlags. Similarly, we set
_doHeaderSync, _doReadWriteSync, _doSegmentSync and _doMetaSync to
true or false based on the same compile-time setting.

Then comes all this crap, which is so similarly themed I'm deflated by
the thought of writing about it:

if (J9_ARE_ALL_BITS_SET(*_runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT)) {
_doSegmentProtect = !getContainsCachelets();
_doMetaProtect = true;
}
_doHeaderProtect = J9_ARE_ALL_BITS_SET(*_runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_ALL);
_doHeaderReadWriteProtect = J9_ARE_ALL_BITS_SET(*_runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_RW);
_doPartialPagesProtect = J9_ARE_ALL_BITS_SET(*_runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_PARTIAL_PAGES);

if (J9_ARE_ALL_BITS_SET(*_runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_ALL)) {
CC_TRACE(J9SHR_VERBOSEFLAG_ENABLE_VERBOSE, J9NLS_INFO, J9NLS_CC_PAGE_PROTECTION_ALLENABLED_INFO);
}

Yeah, booleans are being set that reflect the value of various runtime
flags, passed to us on the command line when OpenJ9 was invoked.

Then a bunch of CC_TRACE messages are emitted, based on some platform
specific flags being defined, at compile time (ie. J9ZOS390, AIXPPC,
etc). Then:

/* Calculate the page boundaries for the CC header and readWrite areas, used for page protection.
 * Note that on platforms with 1MB page boundaries, the header and readWrite areas will all be in one page */

This happens once more, if *_runtimeFlags &
J9SHR_RUNTIMEFLAG_ENABLE_ROUND_TO_PAGE_SIZE is true. We compute
_cacheHeaderPageStart and _cacheHeaderPageBytes by rounding down/up to
the nearest page boundary.. which is determined by, guess
what.. _osPageSize. Very familiar by now. If _readWriteAreaStart !=
NULL (meaning it has positive size, from what we saw a moment ago!) it
is rounded to match the page boundary sizes. _readWriteAreaPageStart
and _readWriteAreaPageBytes are set to NULL and 0 resp. if the
readwrite area and the cache header occur on the same page. Which
helps explain some of the more oblique conditionals encountered
later. The point of putting the two on separate pages, if large
enough, is to be able to protect them separately. Then there's a brief
sanity check about the rounding calculations, to make sure the new
byte size of the cache header and read/write area amount to several
whole pages.

Next, if we aren't testing (meaning _oscache isn't NULL) and if
_parent == NULL, so that we are the authority in our own household, we
try to capture the readWriteMutex if we don't have it already. This is
indicated by hasReadWriteMutex. If it's false, and if
_commonCCInfo->readWriteAreaMutexID != CC_READONLY_LOCK_VALUE, then we
call _oscache->acquireWriteLock with the readWriteAreaMutexID just
mentioned. If it succeeds, then hasReadWriteMutex and
doReleaseReadWriteMutex are set to true! Otherwise, and regardless of
whether the branch fired or _oscache->acquireWriteLock succeeded if
the branch fired, we do:

_localReadWriteCrashCntr = _theca->readWriteCrashCntr.

Y'see, claiming the readWriteAreaMutex was just a ploy to do
this. Once we have it, if doReleaseReadWriteMutex is true, we call
_oscache->releaseWriteLock.. if that call fails, we set rc =
CC_STARTUP_FAILED. If the call succeeds, we do NOT set
hasReadWriteMutex to false, strangely enough.

If it wasn't the cache that we had hasReadWriteMutex, or that the
readWriteAreaMutexID == CC_READONLY_LOCK_VALUE, we set it to
CC_READONLY_LOCK_VALUE, and _localReadWriteCrashCntr =
CC_COULD_NOT_ENTER_STRINGTABLE_ON_STARTUP. Since that is all that is
stored there! We may be able to get the readWriteAreaLock, but the
other parts of the cache should be cool to access, is what this
section is trying to convey to the VM.

Then comes this:

if (_doSegmentProtect && (SEGUPDATEPTR(_theca) != CASTART(_theca))) {
/* If the cache has ROMClass data, notify that the area exists and will be read */
   notifyPagesRead(CASTART(_theca), SEGUPDATEPTR(_theca), DIRECTION_FORWARD, true);
}

We protect the pages read from the start of the cache, to the end of
the segment area, if the region is non-empty. Then this puzzling piece
of code:

/* Update romClassProtectEnd regardless of protect being enabled. This value is
 * used by shrtest which doesn't enable protection until after startup
 */
setRomClassProtectEnd(SEGUPDATEPTR(_theca));

I was confused by this yesterday. Protect the end of the ROMClass
section? Wha? Yeah, it's just a pointer.. _romClassProtectEnd is set
to the pointer passed into it. That's a complete description of what
'setRomClassProtectEnd' does. Fin.

If _initializingNewCache was set to true earlier, *cacheHasIntegrity =
true and _theca->ccInitComplete |= CC_STARTUP_COMPLETE. So we are
doing just fine.

Also,

_maxAOT = _theca->maxAOT;
_maxJIT = _theca->maxJIT;

Which answers that.. whole series of questions. Heh.

Going way back up to the top, is isCacheCorrupt() is true, rc =
CC_STARTUP_CORRUPT, and that's it. Anticlimactic. To the other
enclosing else branch that time forgot, where _theca = 0, rc =
CC_STARTUP_FAILED. Again. If _parent == NULL, it's up to us to call
'setCorruptCache' and set rc = CC_STARTUP_CORRUPT, if
_oscache->getError() returns J9SH_OSCACHE_CORRUPT.

Otherwise, if J9SH_OSCACHE_DIFF_BUILDID is the return value of
_oscache->getError(), we set rc = CC_STARTUP_SOFT_RESET, unless the
*_DO_NOT_CREATE_CACHE flag is set inside _runtimeFlags.

Now! We're rounding the bend of 'startup'! The witch is nearly
dead. If rc == CC_STARTUP_OK, and if hasWriteMutex is true, we call
_debugData->init(..) if _parent == NULL. So that the
ClassDebugDataProvider is initialized. If it fails, we call
'setCorruptCache'.. with the unusual, overloaded option of passing the
corruption code and corruption value. rc = CC_STARTUP_CORRUPT
follows.

We're at the bottom of 'startup', and at the 'releaseLockCheck:'
label. If doReleaseWriteMutex is true, and _parent == NULL, we call
'exitWriteMutex'. If this fails, then rc = CC_STARTUP_FAILED. And we
reach a big overarching else, now that the containing branch's
positive side has run out. What is the condition of this branch? It's
hasWriteMutex being true. If it's not, rc = CC_STARTUP_FAILED.

So, that branch is ended. We check that rc == CC_STARTUP_OK. If so,
set _started = true, and call 'protectHeaderReadWriteArea'. Then do a
trace, and return rc.

'checkCacheCompatibility', which is used from 'startup', is a bit
weird. We check to see that 'getIsBCIEnabled' returns false. This
check is nothing but an add into _theca->extraFlags, and seeing that
BCI is enabled. I have no idea what BCI is. From the Holy Manual:

"-Xshareclasses:enableBCI

    This option is enabled by default.  Allows a JVMTI
    ClassFileLoadHook event to be triggered every time, for classes
    that are loaded from the cache. This mode also prevents caching of
    classes that are modified by JVMTI agents. For more information
    about this option, see Using the JVMTI ClassFileLoadHook with
    cached classes. This option is incompatible with the
    cacheRetransformed option. Using the two options together causes
    the VM to end with an error message, unless
    -Xshareclasses:nonfatal is specified. In this case, the VM
    continues without using shared classes."

There's no indication of what BCI stands for/means, which I find odd.

This enables overloading via OpenJ9's JVMTI, its tools interface. So,
I don't know if we need to worry overmuch about the specifics of this,
since, after all, we don't care about Java. All that either branch
does is toggle _runtimeFlags around, according to those sections
specified by J9SHR_RUNTIMEFLAG_ENABLE_BCI and
J9SHR_RUNTIMEFLAG_DISABLE_BCI. If the stats are enabled, but BCI is
not, the cache is not compatible, and this also holds if vice
versa. Also, something to do if -Xshareclasses:cacheRetransformed is
enabled. That can also fuck everything up, unless stats are
enabled. cacheRetransformed allows retransformed classes to be written
to the cache. From the Holy Manual:

"Retransformed classes are classes with registered retransformation
capable agents that have been called by a JVMTI agent at run
time. Unlike RedefineClasses, the RetransformClasses function allows
the class definition to be changed without reference to the original
bytecode. An example of retransformation is a profiling agent that
adds or removes profiling calls with each
retransformation. Retransformed classes are not stored in the cache by
default, but caching can be enabled using the
-Xshareclasses:cacheRetransformed option. This option will also work
with modification contexts or partitions."

Moving on to 'next'. Not 'nextEntry', but 'next'. We should hold
either the refresh mutex or the write mutex. These conditions are
checked (either will do) in an assert. free is a local variable set to
UPDATEPTR(_theca). The cusp of the cache entries area, where new items
are placed. The local variable ih is set to &_scan. The maximum length
of a composite cache entry, then is the difference between ih and
free, plus the length of a single shared cache item header (a
ShcItemHdr).

If (BlockPtr)(*ih) > free, (remember, the cache entry region grows to
the left), then we have found an item at _scan! If:

(CCITEMLEN(*ih) <= 0) || (CCITEMLEN(*ih) > maxCCItemLen)

holds, then something has gone wrong. A problem that may indicate a
corrupted cache, specifically. We call 'setCorruptCache'. ih is the
corrupted value, and ITEM_LENGTH_CORRUPT is the corruption code.

Otherwise, _prevScan = _scan, result = *ih, and *ih (an lvalue of
_scan, in other words) is set to CCITEMNEXT(*ih), which iterates to
the next item in the linked list. If _doMetaProtect is true (and yes,
this is the metadata region we are walking), we call
'notifyPagesRead', on the region _prevScan.._scan +
sizeof(ShcItemHdr), in the backward direction, where doProtect is
true.

Then we record a Trace message, and return the result. The end.

'initBlockData' initializes an ShcItem type. Which contains a type
tag, length, and Java VM ID. That's it. The ShcItem is passed in as a
ShcItem**, along with a data length, and a datatype. And a jvmID,
which is _commonCCInfo->vmID.

'checkUpdates' reads the value at _theca->updateCountPtr, and tries to
return the difference between it and _oldUpdateCount, if it's
non-negative. If negative, it returns 0. I don't like this,
really.. it's a kludge to circumvent a potential stateful
inconsistency. But there it is.

'doneReadUpdates' takes the currentThread and a value, updates. The
number of updates 'actually' read from the cache, according to the
comment preamble.. it also says the value returned 'checkUpdates'
should be used in conjunction with 'doneReadUpdates'. It reads
_theca->updateCountPtr, as before. If updates > 0 and the
_oldUpdateCount is < than _theca->updateCountPtr, it increments
_oldUpdateCount by updates. It also calls
_debugData->processUpdates... if _doSegmentProtect is true at this
stage, it calls 'notifyPagesRead' to protect the region

getRomClassProtectEnd() .. newRomClassEndAddr

where newRomClassEndAddr is a local variable set to
SEGUPDATEPTR(_theca). It then calls 'setRomClassProtectEnd' on
newRomClassEndAddr, so that the next call of the getter
'getRomClassProtectEnd' will return the current value of
newRomClassEndAddr.

'nextEntry' skips over stale items within the cache (which it counts,
if staleItems is a non-NULL pointer). The ih values (item headers) are
given by 'next'. 'nextEntry' returns the first non-stale item it can
find, if it can found one. It expects the caller to hold either the
refresh mutex or the write mutex.

'enterWriteMutex' either acquires the write lock through the owning
osCache (either our own if _ccHead or NULL, or the head's oscache,
lending further creedence to the idea that there is only *one* OSCache
for every chain of CompositeCache's, of which there is also just one),
or by using omrthread_monitor_enter. Then a bunch of other options
that might revoke possession of the mutex if toggled are
checked. That's basically it, not much more to say.

Holding the write mutex allows multiple concurrent readers of the
cache, unless the cache is locked!

If _commonCCInfo->writeMutexID == CC_READONLY_LOCK_VALUE, the TLS
value _commonCCInfo->writeMutexEntryCount is incremented by 1, and 0
is returned. That's it, if the writeMutexID is the
CC_READONLY_LOCK_VALUE!

If that's not the case, we continue. We assert, via
Trc_SHR_Assert_NotEquals, that currentHeader is not equal to any of:
_commonCCInfo->hasWriteMutexThread,
_commonCCInfo->hasReadWriteMutexThread,
_commonCCInfo->hasRefreshMutexThread.

If we're using an oscache (determined by the pointer oscacheToUse
being non-NULL, of course), call
oscacheToUse->acquireWriteLock. Otherwise, call
omrthread_monitor_enter. Either way, if rc == 0, it succeeded!! If
DENY_CACHE_UPDATES is enabled in _runtimeFlags, call
'exitWriteMutex', and set rc = -1. Otherwise, if DENY_CACHE_UPDATES
isn't enabled, see if lockCache, the local variable, is
true. lockCache was passed to 'enterWriteMutex' as an argument
parameter (a boolean). If it's true, call 'doLockCache'.

If UnitTest::unitTest !=
COMPOSITE_CACHE_TEST_SKIP_WRITE_COUNTER_UPDATE, we call
'unprotectHeaderReadWriteArea', set _commonCCInfo->oldWriteCount =
_theca->oldWriterCount to _theca->writerCount (we can safely do this
because we have the write mutex!!), and increment
_theca->writerCount. Once this is done, call
'protectHeaderReadWriteArea'.

Then emit some trace messages if rc == -1, and return rc.

'exitWriteMutex' is largely the same thing, complete with an
unprotectHeaderReadWriteArea/protectHeaderReadWriteArea wrapping a
*decrement* to _theca->writerCount (depending on whether we are
entering or exiting the mutex respectively). This time, if
_commonCCInfo->writeMutexID == CC_READONLY_LOCK_VALUE, we decrement
the TLS value _commonCCInfo->writeMutexEntryCount and return 0. Also,
it calls 'doUnlockCache' again, and sets
_commonCCInfo->hasWriteMutexThread to
NULL. oscacheToUse->releaseWriteLock is called if oscacheToUse !=
NULL, and omrthread_monitor_exit is called otherwise. Then rc is
returned. It's the mirror-mirror version of 'enterWriteMutex'.

For 'doLockCache' and 'doUnlockCache', the caller must hold the write
mutex. The comments say as much. The header and read/write are
unprotected, the cache is locked/unlocked, and then the header and
read/write area are protected again. Also, theca->crcValid is set to 0
(a C style boolean for false). 'setIsLocked' is called with true,
sandwiched by protect/unprotect calls. After
'protectHeaderReadWriteArea' has been called, the local patienceCntr
(initialized to 0 in 'doLockCache', it's a local variable) is checked
for < CACHE_LOCK_PATIENCE_COUNTER, and this is &&'ed with
_theca->readerCount > 0. The body of the while loop that's entered via
these conditions sleeps 5 milliseconds, and patienceCntr is
incremented.

Once the loop is existed, we check the conditions that caused the
exit. If patienceCntr == CACHE_LOCK_PATIENCE_COUNTER, *and*
_theca->readerCount > 0, the comments say, 'Reader has almost
certainly died. Cannot wait forever. Whack to zero and proceed'. And
it does exactly that. We call 'unprotectHeaderReadWriteArea', set
_theca->readerCount = 0, call 'protectHeaderReadWriteArea', and on we
go. We call 'unprotectMetadataArea' and return (.. nothing, it's a
void function).

'doUnlockCache' checks that the cache is not read-only. It
ShouldNeverHappen here that the cache is read-only. If not, check
_theca is not NULL, and that 'isLocked' returns true. Then we call
'protectMetadataArea', 'unprotectHeaderReadWriteArea', call
setIsLocked(false), and then call 'protectHeaderReadWriteArea'
again. That's it, easy peasy.

'peekForWriteHash' sets and returns _useWriteHash, a boolean. Here's
the comment preamble, it.. simply says more than my words ever could.

/**
 * Check whether to use writeHash when loading classes
 * 
 * This method helps answer the question: Is it worth us using
 * writeHash when loading classes?  The answer is: Yes if another VM
 * has connected since us or if a VM previous to us has detected us
 * and started writeHashing 
 *
 * Current thread should hold refresh mutex when entering this method.
 *
 * @param [in] currentThread  Points to the J9VMThread struct for the current thread
 *
 * @return true if this VM should use writeHash while loading classes, false otherwise
 */

And then:

_useWriteHash = ((_commonCCInfo->vmID < _theca->vmCntr) || _theca->writeHash);
return _useWriteHash;

after some trace messages and a ShouldNeverHappen is the cache is not
started, or read-only. That's it! _commonCCInfo->vmID < _theca->vmCntr
checks that there are other VMs active.. _theca->writeHash checks that
a writeHash has been recorded. It can't be 0, of course.

'testAndSetWriteHash', according to the preamble, tests to see if the
class (demarcated by the function parameter hashValue) is being loaded
by another JVM. If not, set the write hash to that value.

Should be called if an attempt to find a class in the cache has
failed.  If the hash field in the cache field is free (0), it is set,
indicating that the JVM is going to load the class.  If the hash field
has already been set, then this means that another JVM is loading the
class.  If it is the same class, 1 is returned which indicates that it
would be wise to wait. Otherwise, 0 is returned.

A hash value, hashValue, is passed in, that it is calculated from the
name of the class (from 'computeHashForUTF8'). The writeHash value in
the cache is called _theca->writeHash. The hash value has some bitwise
component pertaining to the write hash, which is captured by &&'ing it
with the value WRITEHASH_MASK. If _theca->writeHash is 0, we call
'setWriteHash'. Otherwise, if hashValue & WRITEHASH_MASK == cacheValue
& WRITEHASH_MASK, we shift _theca->writeHash right by WRITEHASH_SHIFT
bytes, indicating the ID of the JVM that is 'in the
cache'. _theca->writeHash is really an indicator of two things, then:
the ID of the JVM modifying the cache, and the 'true' write hash in
the bits preceding it, of which there are WRITEHASH_SHIFT.

If the VM ID doesn't match _commonCCInfo->vmID, return 1, or true,
indicating that yes, the caller VM should wait for the cache to be
released. The call of 'setWriteHash' is to indicate to other JVMs that
*this* JVM is loading the class.

'setWriteHash' is really just a compare and swap atomic operation on
_theca->writeHash, buffeted by calls to 'unprotectHeaderReadWriteArea'
and 'protectHeaderReadWriteArea'. That's all. Again, the new value is
recorded as such, which corroborates the account given above:

value = ((hashValue & WRITEHASH_MASK) | (_commonCCInfo->vmID << WRITEHASH_SHIFT));

The hash value, the 'true' hash of the write hash, is &&-masked by
WRITEHASH_MASK, and the rest is simply the VM ID shifted by the number
of bits composing WRITEHASH_MASK.

'tryResetWriteHash' has this write-up.. later within this very
writeup:

After checking the staleness of ClassPathEntryItem (and marking the
ROMClass as stale if so), if the ROM class was found, we call
_ccHead->tryResetWriteHash if are using the write hash. And we're
trying to reduce contention.. this is a runtime flag stored within the
cache, btw. If we hold the write hash, or if the write hash failed to
be set too many times, we reset it. This is all the action of
_ccHead->tryResetWriteHash.

I should specify, the write hash is set to 0 if successfully reset in
'tryResetWriteHash'.

'setWriteHash', similarly quite similar. It's a
VM_AtomicSupport::lockCompareExchange on &(_theca->writeHash), the
oldNum (the previous value that we read in), and value, a local
variable computed from the VM ID and the passed in hashValue. We do
the lock compare exchange in the midst of unprotecting/protecting the
HeaderReadWriteArea.

'incReaderCount' uses VM_AtomicSupport to do a 'lockCompareExchange'
on the reader count, which may fail! Suggesting that high-granularity
locks are being used, rather than, you know, actual atomics. Something
belied by the name. These calls to 'lockCompareExchange' are
buttressed by a call to 'protectHeaderReadWriteArea' and
'unprotectHeaderReadWriteArea', as in the previous function. We do in
a compare-test-swap loop until the new value is finally written!

'decReaderCount' does the decrement/wait on 'atomic' lock and exchange
loop again. This time to decrement _theca->readerCount. Once finished,
it calls 'protectHeaderReadWriteArea'. It checks to see if the
previous readerCount value was whacked to 0 by doLockCache, and if so,
it breaks out of the do/while. This is the only notable difference
from 'incReaderCount', apart from the decrement in place of the
increment.

'enterReadMutex' increments the reader count (by calling
'incReaderCount') and waits for the cache to be unlocked, if it's
currently locked. It will block until the cache is unlocked. Or the
wait count is exceeded. If it is locked, the reader count is
immediately decremented, and 'acquireWriteLock' is called. This waits
for the lock to be undone (I can only presume!), and for the write
mutex to become available, before incrementing the reader count again
via 'incReaderCount'. If the write lock mutex was acquired
successfully, 'incReaderCount' is called *again*.  Then the write lock
is released, by calling 'releaseWriteLock'. If we look down to
'doLockCache', we see from the comment preamble that 'doLockCache'
*expects* the caller to hold the write mutex. So everything in this
paragraph is justified, non? We can be sure the cache is not locked at
the time we increment the reader counter in 'enterReadMutex'. All the
acquiring of write locks and grabbing of monitors and so on you see in
this function have entirely to do with securing the write mutex. The
so-called "read mutex" is nothing other than the check readerCount >
0.

'exitReadMutex' calls 'decReaderCount' unless
_commonCCInfo->writeMutexID == CC_READONLY_LOCK_VALUE, in which case
_readOnlyReaderCount is decremented, and we return. That's it!

'deleteCache' calls _oscache->destroy to destroy the cache, if
_oscache is not NULL. Note that there's no mucking around with
_ccHead, or _parent, or any of that nonsense we saw before. Again, as
always, this is buttressed by
unprotectHeaderReadWriteArea/protectHeaderReadWriteArea. Of course.

'startCriticalUpdate' is perhaps best explained by appealing to the
preamble, as I so often do:

/**
 * Called when performing critical section which, if does not complete, will
 * cause the cache to be corrupted.
 * Calling this function causes the cache header to become unprotected until endCriticalUpdate is called
 *
 * @param [in] currentThread  Pointer to J9VMThread structure for the current thread
 */

It will 'cause the cache to be corrupted' by unprotect(ing) the
read/write area, as we've come to expect, and incrementing
_theca->crashCntr. That's because the critical section has things
done to it that the CompositeCache judges as corruptions if they're
not soon undone.

'endCriticalUpdate' is the mirror image of 'start'.. we decrement
_theca->crashCntr, and protect the read/write area.

Also, as a prelude, 'allocateMetadataEntry' tries to allocate a
section to store a metadata item represented by a ShcItem entry. A lot
of the trickiness once again boils down to rounding the size of the
item up or down according to a page boundary. Here,
'changePartialPageProtection' is applied so that the metadata region
becomes read/write. It writes to the metadata area of the cache using
memcpy. Yes, the system routine memcpy! I was expecting something a
little more haute couture. But there it is.

Before that, we check to see if the allocation area produced for the
metadata item abuts against the page containing
SEGUPDATEPTR(_theca). If it does, use 'changePartialPageProtection' to
protect it, too. Also update _scan to reflect the addition of the
latest item. Remember, walking the cache items in the metadata area
involves stepping *forward* through the metadata area, which allocates
new items *backwards*.

'allocate' firsts starts by checking a NeverShouldHappen condition:

!_started || _readOnlyOSCache || (itemToWrite == NULL) ||
 ((I_32)itemToWrite->dataLen < 0)

So, if we haven't started, or are read-only, or we don't have an item
to write to the cache, or if the dataLen of the item is corrupted,
yes, none of those things should happen.

Similarly, isCacheCorrupt() cannot be true, or we are in trouble. More
in the sense that we return NULL, so, less severe than NeverShouldHappen.

Then, itemToWrite is aligned to byte align (ie. as an integer, it must
be even) because the lower bit is used to indicate staleness, as the
comments say. This is if itemToWrite->dataLen > 0. The itemLen, the
'true' aligned length of the item, is represented by the local
variable itemLen. Otherwise, if itemToWrite->dataLen == 0, itemLen =
0.

There is this fun assert:

Trc_SHR_Assert_False(_storedSegmentUsedBytes | _storedReadWriteUsedBytes | _storedMetaUsedBytes | _storedAOTUsedBytes | _storedJITUsedBytes);

All these bools must be false. We cannot currently be in the process
of storing any data, to anywhere in the cache. It's by design a
single-threaded operation.

Next, we set the locations *at* the pointers segmentBuffer and
readWriteBuffer to NULL, if the pointers themselves aren't NULL, of
course. Then we consider the enum type, a parameter to 'allocate'.

If type == ALLOCATE_TYPE_BLOCK, we are allocating a generic block, in
the sense that it's distinct from a JIT or AOT block. freeBytes, the
local variable, is set to 'getFreeBlockBytes' (its return value, not
the function). And that does a few calculations based on
FREEBYTES(_theca), and subtracting away the portions reserved for JIT
and AOT code.

The local variables usedBytesInc = itemLen + addBufferSize +
_debugData->getStoredDebugDataBytes(). addBufferSize is a bit of a
stumper. If readWriteBuffer == NULL, it's separateBufferSize.
Otherwise it's 0. The readWriteBuffer does indeed -- usually --
correspond to the read/write buffer of the cache as we usually
understand it.

If type == ALLOCATE_TYPE_AOT, we start by calling
'getAvailableReservedAOTBytes'. That function answers a longstanding
question I've had about the role of minAOT and minJIT. The number
of *available* reserved AOT bytes is minAOT - aotBytes and we expect
_theca->minAOT <= _theca->aotBytes <= _theca->maxAOT.  But also
'getAOTBytes' has a comment stating that it is indeed the total number
of AOT bytes stored in the SCC. Similarly for JIT!

The available reserved AOT bytes are stored in
reservedAOT. 'getFreeAOTBytes' is slightly different! It computes the
local variable

I_32 usableFreeBytes = (I_32)getFreeBytes() - getAvailableReservedJITBytes(currentThread);

We need to know that _theca->maxAOT - _theca->aotBytes.   (1)

the maximum amount of space useable for AOT minus the number of bytes
presently used for AOT.. exceeds usableFreeBytes. In this case we
return usableFreeBytes. We also return usableFreeBytes if
_theca->maxAOT == -1.

Otherwise, if _theca->maxAOT != -1, and the difference at (1) is <
usableFreeBytes.. then we go with (_theca->maxAOT -
_theca->aotBytes). The lesser value.

Back to allocate! If the number of reserved AOT bytes is >=
_theca->aotBytes, *plus* the length of the code data (the parameter of
'allocate', codeDataLen; the code data can be such as profiling data
related info, you know), set usedBytesInc = itemLen + addBufferSize -
codeDataLen. This is because, quoth the comment,

/* Reserved AOT has already been counted as used bytes. If it
 * is not reached, codeDataLen should not be counted as used
 * bytes */

The amount of space reserved for AOT (and that is *available*) has
already been counted in the usedBytes count (yep, this is true.. see
'getFreeBlockBytes'). If it can accommodate all it contains *plus* the
codeDataLen bytes, clearly, the increment to usedBytes at the finale
of allocate should not include codeDataLen! We would double count the
bytes of codeDataLen in that case.

But that implies that while the data whose length is counted
codeDataLen goes into the AOT area (that was pre-reserved) the AOT
code itself does not. See if this holds up!

In the second case,

(reservedAOT > _theca->aotBytes) && (reservedAOT < _theca->aotBytes +
codeDataLen)

and so, usedBytesInc is computed as follows:

usedBytesInc = (U_32)_theca->aotBytes + itemLen + addBufferSize -
reservedAOT;

meaning that we deduct the last bit of reservedAOT space that remains
available, yes? So we are going to copy the used parts of the cache
into the available, reserved parts of the AOT? Or we're going to
behave like that will happen, and use only the residual part
represented by _theca->aotBytes - reservedAOT?? WHY?? Seems that we're
always trying to maintain a buffer of at least the amount of space
used to *store* AOT/JIT code in reserved space for *future* AOT/JIT
code. This is the best possible explanation I can give currently.

OK, genius, we realized weeks ago (and then promptly forgot again),
that itemLen (the calculation returned by the function
getBytesRequiredForItemWithAlign) includes codeDataLen! This is belied
by the 'allocate' function, a kitchen sink... it makes the existence
of a separate codeDataLen parameter appear like a necessity, when in
fact it's not, it's totally redundant. See the lines

_storedMetaUsedBytes = itemLen - codeDataLen; /* Don't count AOT data
as metadata */

and

_storedMetaUsedBytes = itemLen - codeDataLen; /* Don't count JIT data
as metadata */

for corroboration of this!



Finally, if neither of these conditions applies, then reservedAOT <=
_theca->aotBytes, and usedBytesInc = itemLen + addBufferLen, the
simplest case.

Regardless of what happens,

regionFullFlag |= J9SHR_AOT_SPACE_FULL.

If type == ALLOCATE_TYPE_JIT, it's the same thing, with the character
sequence 'aot' in all cases substituted by 'jit'. That is a complete
description of the difference! All numbers are infinite, there is no
difference.

If !readWriteBuffer, then we are not writing to the read/write area,
which means we are dealing either in the segment area, or the metadata
area. We want to ensure a 1KB gap between the classes and metadata at
all times. This requires that the local variable freeBytes >
J9SHR_MIN_GAP_BEFORE_METADATA. If it is, we deduct
J9SHR_MIN_GAP_BEFORE_METADATA from freeBytes, so that the gap is not
considered part of the freeBytes. Otherwise, freeBytes = 0.

Then enoughSpace is a boolean (and a local variable) calculated as:

enoughSpace = (freeBytes >= (I_32)(itemLen + separateBufferSize));

The itemLen + separateBufferSize. The separateBufferSize is not really
a separate buffer at all, it turns out. It's being allocated in the
SCC.

Otherwise! If readWriteBuffer != NULL,

enoughSpace = ((freeBytes >= (I_32)itemLen) &&
((I_32)FREEREADWRITEBYTES(_theca) >= (I_32)separateBufferSize));

This despite the read/write area being home to exclusively the shared
string intern table! Although it might not be, I dunno! Perhaps
they're planning for some future time. The separate buffer will live
inside the read/write area in this setup! Again, I'm not sure the
readWriteBuffer (a parameter to 'allocate') is ever != NULL.

So, usedBytes = getUsedBytes(), and softMaxValue =
_theca->softMaxBytes. enoughAvailableSpace is a boolean that is true
iff enoughSpace && ((usedBytes + usedBytesInc) <= softMaxValue).

If enoughAvailableSpace is true, we check that itemLen > 0 and
dispatch on item type again. The check is to increment
_stored*UsedBytes by the appropriate amount, which, of course, varies
by the type of item we're storing. This happens regardless of whether
we are allocating JIT, AOT, or BLOCK data! There is always a
descriptor item allocated in the metadata area.

if itemLen == 0, we just set _storedMetaUsedBytes = 0, and don't
bother with the metadata area.

If separateBufferSize > 0, we turn our attention to allocating within
the segmentBuffer. We check to see that segmentBuffer != NULL. If so,
record _storedSegmentUsedBytes = separateBufferSize, and set
*segmentBuffer = SEGUPDATEPTR(_theca). Use
'changePartialPageProtection' on *segmentBuffer's resident page so
that it's read-write.

Next, if readWriteBuffer != NULL, we .. mostly do nothing. The code
present in that area applied only if cachelets were enabled, and they
are now. So we don't worry about it.

Otherwise, if enoughAvailableSpace is false, but enoughSpace is
true..  we calculate ccToUse in our accustomed manner. We emit a trace
message to indicate that the limit softMaxBytes has been reached!!! If
type == ALLOCATE_TYPE_BLOCK, we assert that

(softMaxValue - usedBytes) >= CC_MIN_SPACE_BEFORE_CACHE_FULL

is true.

Then we call 'increaseUnstoredBytes' to try to buy more space, passing
usedBytesInc as an indicator of how much new space we need for the
block. Note that the other two parameters (for the AOT and JIT space
needed) as passed as 0.

As an aside, 'increaseUnstoredBytes' deals in manipulation of
_softmxUnstoredBytes, mostly! It's a volatile which requires the use
of VM_AtomicSupport::addU32 to be incremented. Based on whether we are
requesting AOT, JIT, or block bytes to be allocated through the
parameters. _maxAOTUnstoredBytes and _maxJITUnstoredBytes are likewise
volatile data that can be atomically incremented through the same
means. This depends on various runtime flags that control the policy
on making additional space available for JIT, AOT, and block code. The
policy is usually to increment _maxAOTUnstoredBytes by aotBytes, the
number of bytes requested by the allocator, if beneath
maxAOTUnstoredLimit (calculated as MAX_CC_SIZE - maxAOT), and if so,
increment it. If that's not the case, then set _maxAOTUnstoredBytes to
maxAOTUnstoredLimit.

This reveals that the maximum limit to storage space is 'soft' because
it can be incremented if space is available!! Generally not,
though. We don't want to bother with these checks all the
time.. rather, we want a regime of 'light' changes that confirm we're
in the green, without needing more extensive checking.. the more
extensive checks are reserved for when we begin to broach the limits
of available space.

Back to 'allocate'. If the allocation type isn't BLOCK, we call
ccToUse->setCacheHeaderFullFlags with the local variable
regionFullFlag.. because regionFullFlag was only a local variable up
until now, it had no effect. But now that we know there isn't enough
available space, we flag it as full quantified in response to the type
of space we requested for allocation.

Finally.. if neither enoughSpace nor enoughAvailableSpace is true..
if type == AOT, we mark the local variables 'flags' with
J9SHR_AOT_SPACE_FULL, and similarly for JIT. Otherwise, if type != JIT
or AOT, then.. we do nothing, really. We check that
_theca->cacheFullFlags reflects J9SHR_BLOCK_SPACE_FULL in its entire
bit representation. We assert this is true, in fact. And then, we call
ccToUse->setCacheHeaderFullFlags with flags again, as before, and
we're done. We return the result. Note that the result contains the
metadata item entry. That's it! The pointers segmentBuffer and
readWriteBuffer can return the addresses into the cache (usually,
SEGUPDATEPTR(_theca), etc). They are BlockPtr*, which makes them
pointers to pointers.

I think we're ready to look at 'allocateJIT' and 'allocateAOT' in a
new light. The prototype of 'allocate' is this:

allocate(J9VMThread* currentThread, U_8 type, ShcItem* itemToWrite, U_32 codeDataLen, U_32 separateBufferSize,
	 BlockPtr* segmentBuffer, BlockPtr* readWriteBuffer, U_32 align, U_32 alignOffset)

'allocateJIT' initializes it as follows:

return allocate(currentThread, ALLOCATE_TYPE_JIT, itemToWrite, dataBytes, 0, NULL, NULL, SHC_DOUBLEALIGN, 0);

dataBytes could be the size of profiling data! Substituting for
codeDataLen. separateBufferSize is 0, so we are allocating zilch
inside the segment area! The segmentBuffer and readWriteBuffer are
NULL, and the align is a double alignment! With 0 for the offset.

In other words.. JIT data is mostly profiling data, as far as this
indicates. Not code.

'allocateAOT' initializes as follows:

return allocate(currentThread, ALLOCATE_TYPE_AOT, itemToWrite, dataBytes, 0, NULL, NULL, SHC_WORDALIGN, 0);

And now we have word alignment, but things are otherwise the same.
dataBytes is now described as 'size of code data' by the comment
preamble. It looks as though both AOT code and JIT metadata are stored
in the metadata section! Seeing as how codeDataLen is part of itemLen
and all that. codeDataLen's only purpose in being passed to 'allocate'
is to get _stored*UsedBytes changes right. See lines 2776 and 2779 for
support of the thesis that itemLen >= codeDataLen.

'allocateBlock' initializes as follows:

return allocate(currentThread, ALLOCATE_TYPE_BLOCK, itemToWrite, 0, 0,
NULL, NULL, align, alignOffset);

Again, same deal! No metadata this time, and align and alignOffset are
both customized values! So the block once again is located inside the
metadata area... when do we ever use this interface to get a
bidda-bidda the segment area?

As if in response to this prurient question, 'allocateWithSegment'
comes through, and is initialized as follows:

return allocate(currentThread, ALLOCATE_TYPE_BLOCK, itemToWrite, 0,
segmentBufferSize, segmentBuffer, NULL, SHC_WORDALIGN, 0);

We allocate a block, yes, but we want a side piece in the segment
area, of segmentBufferSize, at the pointer segmentBuffer. These are
all arguments to 'allocateWithSegment', nothing more. Once more!
readWriteBuffer is passed as NULL into allocate.

There's also 'allocateWithReadWriteBlock', which allocates like this:

return allocate(currentThread, ALLOCATE_TYPE_BLOCK, itemToWrite, 0,
readWriteBufferSize, NULL, readWriteBuffer, SHC_WORDALIGN, 0);

Here, the segmentBufferSize is 0 and the segment address is NULL. A
complete reversal from 'allocateWithSegment'. Otherwise very similar,
though!

'getBytesRequiredForItemWithAlign' is the utility function we reviewed
in 'allocate'. It finds the allocPtr as UPDATEPTR(_theca), and adds
the dataLen to the size of the ShcItemHdr struct and the ShcItem
struct, since we make space for those. Then adds the alignOffset, and
modulo's out the align, and boom.. that's the padAmount. Which is
added to the itemLen, so that itemLen is properly aligned. Some space
is wasted when we do this, sure.

'getBytesRequiredForItem' is the same as
'getBytesRequiredForItemWithAlign', but with an alignment of 0.

'fillCacheIfNearlyFull' fills the cache with dummy data if the cache
is nearly full. "Nearly full" means this, per the comment preamble:

(available bytes - (AOT + JIT reserved bytes)) <
CC_MIN_SPACE_BEFORE_CACHE_FULL

Yeah. So, if this condition applies, and freeBlockBytes >=
J9SHR_MIN_DUMMY_DATA_SIZE, we allocate a ShcItem header in the
metadata area, and call allocateMetaDataEntry with an itemLen value
equal to freeBlockBytes. Then we memset the data region with the
constant J9SHR_DUMMY_DATA_BYTE, and call 'commitUpdateHelper' to
broadcast the change to all VM's. Before that, we increment
_storedMetaUsedBytes by itemLen, yes we do!

The rest has to do with updating the cache full flags with
'setCacheHeaderFullFlags'.

'rollbackUpdate'.. is used to rollback a shared classes cache update
that's found to have crashed the cache. It consists exclusively in
restoring _scan and _prevScan to their 'stored' values _storedScan and
_storedPrevScan, and also setting _stored*UsedBytes values to
0. That's it!

'updateStoredSegmentUsedBytes' is just a setter of
_storedSegmentUsedBytes. It also asserts _storedMetaUsedBytes > 0 as
true.

Bedtime story! After a new item has been added to the cache, after a
call to 'allocate', we must 'commit' the update by propagating a
record of the changes made via allocate to the various Managers that
orbit the SCC. That provide an interface to find and manipulate items
of data that have been stored within the cache. Typically via a hash
table lookup, because obvy, that is so much faster than doing a linear
search through the metadata area. Which is to the best of my knowledge
thus far, is a perfectly sufficient if unperformant way of searching
the cache.

'commitUpdate' calls 'fillCacheIfNearlyFill' after it's done, so that
the dummy data flooding is done if it needs to be done. Apart from
that, it's just a wrapper around 'commitUpdateHelper', which we turn
to next!

So, 'commitUpdateHelper'. First, _theca->crcValid = 0. Because the
cache has changed, the CRC has to be recomputed. We also call
'startCriticalUpdate'. This increments the crash counter. If
_storedSegmentUsedBytes > 0.. then the segment area was modified. We
check that _storedMetaUsedBytes > 0 is true. We increment
_theca->segmentSRP by _storedSegmentUsedBytes. If _doSegmentProtect is
true, or if _doSegmentSync is true (iff J9SHR_MSYNC_SUPPORT is
enabled), we call 'notifyPagesCommitted', with some rounding around
page sizes, if partial page protection is enabled within further
settings.

Then we call 'setRomClassProtectEnd', like this:

setRomClassProtectEnd(startAddress + _storedSegmentUsedBytes);

Which is just a setter around _romClassProtectEnd.. the end of the ROM
class section. startAddress the local variable was initialized as

BlockPtr startAddress = SEGUPDATEPTR(_theca);

earlier, before _theca->segmentSRP was incremented by
_storedSegmentUsedBytes. It's the end of the segment region after
readWriteSRP that needs to be protected.. it's the upper bound of the
segment area.

For _storedReadWriteUsedBytes, the entirety of the commit is this:

if (_storedReadWriteUsedBytes) {
   /* Don't currently notify read or commit of readWrite bytes */
   _theca->readWriteSRP += _storedReadWriteUsedBytes;
}

The comments note that if we crash at exactly this moment.. the ROM
class and read/write sections will have been updated without any
reference to those updates made elsewhere. So, we update
_theca->lastMetadataType to offer the future some chance at restoring
the state if a crash does happen. It looks like this:

oldNum = _theca->updateSRP;

/* Store the ShcItem->dataType and jvmID */
_theca->lastMetadataType = *(U_32 *)&((ShcItem *)((UDATA)_theca + oldNum - (_storedMetaUsedBytes + _storedAOTUsedBytes + _storedJITUsedBytes)))->dataType;
_theca->updateSRP -= _storedMetaUsedBytes + _storedAOTUsedBytes + _storedJITUsedBytes;

Then we check that the 'free' gap in the CompositeCache diagram is at
least J9SHR_MIN_GAP_BEFORE_METADATA, in the form of an Assert_True.

Then we update _theca->updateCountPtr, incrementing it by 1. We update
_oldUpdateCount after the increment to reflect the new amount. There
are no concurrency primitives employed in this!! From the preamble, we
see that the caller MUST hold the shared classes cache write mutex! It
must.

_theca->aotBytes and _theca->jitBytes are incremented by
_stored[AOT|JIT]UsedBytes if either one is non-zero.

Then we employ a similar protect/sync check (again, if
J9SHR_MSYNC_SUPPORT is enabled) for the metadata area, in analogy to
the check for the segment area mentioned earlier. These are indicated
by the flags _doMetaProtect and _doMetaSync. 'notifyPagesCommitted' is
called with some modifications if partial page protection is enabled,
blah blah. It's largely the exactly same thing! The only change is in
the change in the area of the cache being protected.

Then we call 'endCriticalUpdate', which re-protects the header and
read/write areas, and decrements crashCntr. We update
_totalStoredBytes to reflect the new amounts, and set the
_stored*UsedBytes fields back to 0. And we're done.

'markStale', marks blocks of memory as stale, as you might
imagine. It's the first byte at the end of a block that's marked 1 to
indicate staleness, which is why items are always aligned on at least
a word boundary. blockEnd, the parameter, is BlockPtr pointing to the
ShcItemHdr of the item to be marked as stale. If _doMetaProtect is
true and isCacheLocked true (bizarrely, isCacheLocked is passed in as
an argument) we round ih->itemLen down to the _osPageSize, and round
its length _osPageSize (the length of the metadata area), and call
'setRegionPermissions' on it so that we may write to it.

Then we call CCSETITEMSTALE(ih) to mark the last bit as 1, indicating
staleness, and we are done!! Then we restore read protections, if the
cache isn't locked, and if _doMetaProtect is true, and the _areaStart
> _prevScan.

'stale' checks a ShcItemHdr at its only parameter blockEnd for
staleness. The final bit being 0, that's it.

'findStart' initializes _scan as:

_prevScan = _scan;
_scan = (ShcItemHdr*)CCFIRSTENTRY(_theca);

Same basic thing.

CCFIRSTENTRY has this definition:

#define CCFIRSTENTRY(ca) (((BlockPtr)(ca)) + (ca)->totalBytes -
 (ca)->debugRegionSize - sizeof(ShcItemHdr))

In each case, it goes to the start of the cache entry lineup, and
skips over the header. Seems that.. the aim is to look past _scan for
the next cache entry in the sequence, while also checking conditions
that indicate the cache is corrupted.

Also, it asserts that hasWriteMutex(currentThread) is true. Because we
are writing to _scan and _prevScan, you see. I think.

'getBaseAddress' is CASTART(_theca). The very beginning of the
block, after the header. It returns that value.

'getCacheHeaderAddress' just returns _theca.

'getStringTableBase' is just READWRITEAREASTART(_theca), which it
returns.

'getCacheMemorySize' is "return _theca->totalBytes".

'getCacheEndAddress' is "return CAEND(_theca)".

'getCacheLastEffectiveAddress' is (CAEND(_theca)) - sizeof(UDATA). The
address of the last readable/writeable word the block contains, in
other words. Why is this necessary?

/**
 * Utility function for finding the last writeable/readable UDATA address in the cache.
 * This function was created b.c when the cache is mapped to the end of memory CAEND(_theca)
 * will return NULL. Which causes problems in various asserts, and could possible create problems
 * with bounds checking in a ROM class segment.
 *
 * @note This function is needed for representing the cache as a J9MemorySegment.
 *
 * @return Address of the last writeable/readable UDATA in the cache
 */

'getSegmentAllocPtr' just returns SEGMENTUPDATEPTR(_theca).

Similarly, 'getMetaAllocPtr' just returns UPDATEPTR(_theca).

'getReadWriteAllocPtr' returns RWUPDATEPTR(_theca).

'getTotalUsableCacheSize' returns (CAEND(_theca) -
READWRITEAREASTART(_theca)).

'getTotalStoredBytes' returns _totalStoredBytes.

'getUnstoredBytes' gets the unstored bytes, of the three types!
softmxUnstoredBytes (blocks), and then the max unstored bytes for AOT
and JIT allocations. There's page rounding via _osPageSize, if
_osPageSize != 0. The parameters are pointers, and they are the return
values! Each of the quantities is already known internally.

'getAOTBytes' returns _theca->aotBytes.

'getJITBytes' returns _theca->jitBytes.

'getReadWriteBytes' and 'getStringTableBytes' return
'READWRITEAREASIZE(_theca) and _theca->sharedInternTableBytes
respectively.

'getFreeBytes' returns FREEBYTES(_theca).

'getFreeAvailableBytes' is mostly getTotalSize() - getUsedBytes(),
which might be modified if _theca->softMaxBytes == -1 (and is thus
disabled). Reserved AOT and JIT memory is considered used! That's why
they're reserved.

'isAddressInCacheDebugArea' just checks to see if the address is
within bounds of the area, a contiguous area in memory! Nothing
complicated there.

'getDebugBytes' calls out to _debugData->getDebugDataSize() and
returns the result.

'getFreeDebugSpaceBytes', 'getLineNumberTableBytes' and
'getLocalVariableTableBytes' similarly call out to getter functions in
_debugData.

'getFreeReadWriteBytes' returns FREEREADWRITEBYTES(_theca).

'isInaddressInROMClassSegment' and 'isAddressInCache' do similar
contiguous region comparisons. Not a huge deal.

'runExitCode' is the first non-trivial thing in a while. It's cleanup
code that runs when the JVM exits. oscacheToUse is calculated via the
ccToUse convention of checking to see if _ccHead == NULL, and using
its oscache if it is, and our own if it isn't. Then
'unprotectHeaderReadWriteArea' is called on the current thread. Some
special considerations are made if J9ZOS390 is enabled.

Then we assert that _headerProtectCntr == 1.

Then we check _commonCCInfo->hasRWMutexThreadMprotectAll ==
currentThread. If so, it is ours to relinquish! We set

_commonCCInfo->hasReadWriteMutexThread = NULL;
_commonCCInfo->hasRWMutexThreadMprotectAll = NULL;

to let go of the mutexes that we hold. Then we call
oscacheToUse->releaseWriteLock(_commonCCInfo->readWriteAreaMutexID) so
that we no longer hold the write lock in TLS storage.

Then there's this weird ass segment:

/* If we're exiting abnormally, a thread may have the write mutex.
* If that's the case, do not attempt to update the cache CRC
* because otherwise we can hang writing the dumps */
if ((_commonCCInfo->hasWriteMutexThread == NULL) && (_commonCCInfo->writeMutexID != CC_READONLY_LOCK_VALUE)) {
   IDATA lockrc = 0;
   PORT_ACCESS_FROM_PORT(_portlib);
   if ((lockrc = oscacheToUse->acquireWriteLock(_commonCCInfo->writeMutexID)) == 0) {
      updateCacheCRC();
      /* Deny updates so the CRC is not invalidated */
      *_runtimeFlags |= J9SHR_RUNTIMEFLAG_DENY_CACHE_UPDATES;
      if ((lockrc = oscacheToUse->releaseWriteLock(_commonCCInfo->writeMutexID)) != 0) {
      	 CC_ERR_TRACE1(J9NLS_SHRC_CC_FAILED_EXIT_MUTEX, lockrc);
      }
    } else {
      CC_ERR_TRACE1(J9NLS_SHRC_CC_FAILED_RUN_EXIT_CODE_ACQUIRE_MUTEX, lockrc);
    }
}

We try to get the write mutex before updating the cache CRC! If we
call 'updateCacheCRC' without holding the write mutex ourselves, it
might hang on writing the CRC dump. I think. Then we toggle a denial
of cache updates that the CRC is not invalidated, and we're good. We
release the write mutex.

Then, finally, we call oscacheToUse->runExitCode().

'getJVMID' is a simple getter, and returns _commonCCInfo->vmID.
_commonCCInfo is cross-thread, intra-process.

'setInernCacheHeaderFields' sets the passed in ** pointers (its
arguments) to the locations of _theca->sharedStringTail,
_theca->sharedStringHead, and other fields. I don't know what their
significance is.

'enterReadWriteAreaMutex' contains several arguments instructing that
some section of the cache should be rebuilt if the possibility of
corruption was detected. We compute oscacheToUse using the standard
convention, and we confirm _readWriteAreaBytes > 0. And that
oscacheToUse != NULL. If so, we check that
_commonCCInfo->readWriteAreaMutexID != CC_READONLY_LOCK_VALUE.

We do the following asserts:

Trc_SHR_Assert_NotEquals(currentThread, _commonCCInfo->hasReadWriteMutexThread);
Trc_SHR_Assert_NotEquals(currentThread, _commonCCInfo->hasRefreshMutexThread);

and do

oscacheToUse->acquireWriteLock(_commonCCInfo->readWriteAreaMutexID);

If that returns 0, we do

oscacheToUse->hasReadWriteMutexThread = currentThread;

Then there's a bunch of overspecific crap concerning string table
resets that we may want to consult later. Suffice it to say, they can
toggle whether the cache is read-only. In "normal" circumstances, with
a non-readonly cache, we unprotect the header and read/write areas to
increment _theca->readWriteCrashCntr.

Then for the crash/corruption detection pass! If

oldReadWriteCrashCntr != _theca->readWriteRebuildCntr

we set *doRebuildCacheData = 1 in case the caller wants to handle
it. We set _theca->readWriteRebuildCntr = oldReadWriteCrashCntr so
that we don't endlessly thrash around flagging for a rebuild, I guess.

Similarly, if (_localReadWriteCrashCntr != oldReadWriteCrashCntr), we
set *doRebuildLocalData = 1, and _localReadWriteCrashCntr =
oldReadWriteCrashCntr. I don't know where _localReadWriteCrashCntr and
_theca->readWriteRebuildCntr are set.

Finally, we return rc.



'reset' calls findStart(currentThread) to set the scan pointers back
to UPDATEPTR(_theca). And _stored* statistics back to 0, besides. It
also unlocks the cache. Should the cache be locked before hand? Hard
to tell.

Back to the initialization dance.

'protectHeaderReadWriteArea' protects the header of the read/write
area? If we're protecting the header, or we're protecting the read
write area and also changing it,

_readWriteAreaPageStart is the rounded down size of the read/write
area (rounded down to a page size, of course). I think the header,
read/write area, and cache area all occupy a single page? I think??

/* Calculate the page boundaries for the CC header and readWrite areas, used for page protection.
 * Note that on platforms with 1MB page boundaries, the header and readWrite areas will all be in one page */

ok, that's pretty damn unclear. It's just rounded it *to* a multiple
of the page size, in terms of address, yes? so that the boundaries
align??

It's possible for _readWriteAreaPageStart and _cacheHeaderPageStart to
coincide as integers. This makes a bit more sense with all the
rounding, then. If not, there is this comment:

/* Header is smaller than a page, round up the start of the readWrite area to the next page
 * to ensure that it can be protected/unprotected independently */

Seems they can be on either a single page or two separate pages.

Anyway, I get the areaStart.. based on whether the caller wants to
protect the header, the read/write area, or both.. it calls
'setRegionPermissions' to set the page permissions if areaStart is
non-NULL. Then it decrements the [_readWrite|_headerProtect]Cntr
variables. And then the _commonCCInfo->hasReadWriteMutexThread is set
to NULL, away from the current thread, and similarly for
_commonCCInfo->hasRwMutexThreadMprotectAll. Presuming that
currentThread == the latter.

'setRegionPermissions' checks that length is positive, and that the
OSCache _oscache exists, before deferring to
_oscache->setRegionPermissions. If _oscache is NULL, j9mmap_protect
is called instead.. but why might _oscache be NULL? Is it known to the
head composite cache only? Why then is a new instance created at
startup? Perhaps 'startup' deters that other CompositeCache's exist,
at which point it dredges up the parent's OSCache.

'unprotectHeaderReadWriteArea': same thing. has logic to do nothing
if some other thread is changing the two (or one, where applicable).
Call 'setRegionPermissions' to unprotect.

'startupForStats' is the method to call to create a CompositeCache
for a shared cache that exists, and is attached already. An 'oscache'
parameter is passed into it. I don't think its comment has been
updated in some time, it definitely sounds.. behind. But it makes it
sound as though oscache is the 'attached shared memory region'. Or its
representative as an object, anyway.

It sets _oscache to oscache, one of its arguments, to answer our
earlier question. attachedMemory, mentioned in the now obsolete
comments above the definition of the method, is now derived from
this line:

attachedMemory = (BlockPtr)oscache->getAttachedMemory();

It configures the CompositeCache object by extracting information from
oscache.

'allocateBlock' allocates a block of memory. Its parameter itemToWrite
is a ShcItem, which serves as a header for the block.. containing its
type, length, and Java VM ID, as we saw previously.

'allocate', which 'allocateBlock' and friends call, is not static,
which is odd when you consider its parameter names. segmentBuffer,
and readWriteBuffer, especially. 'allocateBlock' passes in NULL
values for these.

The rest of the function that isn't immediately straightforward is
a dispatch on the value of type, as a series of if/else if blocks.

if allocating aot:

... it gets the available AOT bytes!! Naturally. The ones that were
reserved. This is the task of 'getAvailableReservedAOTBytes'.

'getFreeAOTBytes' returns the AOT bytes that are reserved for AOT
allocations, but that have not yet been allocated. Regardless of how
many of the reserved AOT bytes are available, we flag the
regionFullFlag bit vector, toggling J9SHR_AOT_SPACE_FULL (!)..
to indicate that other threads should back off on AOT allocations
until we're finished, I guess? What could be the reason for that???

The JIT case allocation is almost identical to the AOT one!!
Substitute 'JIT' for 'AOT' in the code and you're most of the way
there! We also mark the regionFullFlag with J9SHR_JIT_SPACE_FULL!

If readWriteBuffer hasn't been decided yet, we compute a boolean value
called enoughSpace, which is self-descriptive.

It moves onto checking that 'enoughAvailableSpace' is true, which is
so if enoughSpace is true, and usedBytes + usedBytesInc <=
softMaxValue. The soft max, not the hard max! Unsure of the
distinction.

Any allocate type that isn't AOT or JIT counts as metadata! According
to the comments within the code.

So, we call 'allocateMetadataEntry'. The past two paragraphs are
applicable if itemLen > 0. We then check to see that
separateBufferSize > 0.

If we yes, and segmentBuffer != NULL, the point the segmentBuffer
pointer at SEGMENTUPDATEPTR. The END of the segment section,
where new segments are added. We need to look
'changePartialPageProtection', which is the thing that is allocated
next.

If readWriteBuffer is allocated, we call allocateReadWrite.. which
allocates space in the read/write area, I can only guess. When was
readWriteBuffer sent to something non-NULL? Answer: when it was passed
in, by the caller. If cachelets and crap aren't enabled, we use
RWUPDATEPTR. Obviously.

If there is 'enoughSpace', but not 'enoughAvailableSpace', the cache
space is enough, but available space is not! So we defer to either the
head of the cache linked list, or the parent's cache, if either exist,
checking in that order.

If we mean to allocate a block, we call increaseUnstoredBytes, with
usedBytesInc as the amount of space needed, I presume.

Otherwise, we use the common cache info struct to set cache header
full flags, using the value of the regionFullFlag. There's our
answer.. the regionFullFlag, true to the name (the lack of an opening
underscore), is just a local variable whose value impinges on nothing
until this moment.

Otherwise! enoughSpace is false, our life is a lie! We go about
markings flags with the bits signified by
J9SPACE_[JIT|AOT]_SPACE_FULL, as before! But we don't have
regionFullFlag at our disposal anymore. Some other logic applies if we
are nested (ie. cachelets are enabled), but we're not considering it
just yet.

'allocateMetadataEntry' .. seems to allocate a cache entry, not a
segment but an actual, no shit entry, against the cache! And does the
actual work of writing stuff into the cache that we never saw directly
in 'allocate'.

It begins by carving out space, from the allocPtr, for a ShcItemPtr
(it moves backwards to do this, seeing as how it's a cache entry).
Then it invokes partial page protection at the allocPtr, using
'changePartialPageProjection' (it passes the address). Then good old
fashioned memcpy is called!! I have no idea how this is or isn't
affected by the partial page protection scheme. But I supposed I'll
find out. Oh, and the previous _scan and _prevScan values are backed
up to _storedScan and _storedPrevScan respectively, so that _prevScan
is set to scan, and _scan refers to the item after the item header.
Then the result is returned.

'changePartialPageProtection' does some rounding of the passed in
address according to the page alignment, and calls
'setRegionPermissions' on that address. If the address passed in is
already page aligned, we jump to the done label, which does nothing
but emit a trace message.

'allocateWithSegment' calls allocate, asking for a block to be
allocated as the allocation type.

'allocateJIT' calls allocate, asking for a JIT type.

'allocateAOT' calls allocate, asking for an AOT type.

--

There are many more secrets of the CompositeCache to be discovered,
and for that we have to see how it's being used in the wild,
probably!! For instance, many of CompositeCache's features -- reader
count and writer count -- are outward facing, and don't affect the
internals of the cache beyond their values being
manipulated. Similarly, there are getter/setter functions for fields
like _next.. that point to subsequent caches in a chain of caches (the
comments spread throughout the implementation suggest that there is a
chain of 'supercaches' -- the top level caches that potentially
contain nested caches). But nothing further! All manipulation of
those fields is done by users of the SH_CompositeCache class.

So, let's begin to look at CacheMap. Its member variables:

SH_CompositeCacheImpl* _cc;					/* current cache */

/* See other _writeHash fields below. Put U_64 at the top so the debug
 * extensions can more easily mirror the shape.
 */
 U_64 _writeHashStartTime;
 OMRSharedClassConfig* _sharedClassConfig;

SH_CompositeCacheImpl* _ccHead;				/* head of supercache list */
SH_CompositeCacheImpl* _cacheletHead;		/* head of all known cachelets */
SH_CompositeCacheImpl* _ccCacheletHead;		/* head of cachelet list for current cache */
SH_CompositeCacheImpl* _cacheletTail;		/* tail of all known cachelets */
SH_CompositeCacheImpl* _prevCClastCachelet;	/* Reference to the last allocated cachelet in the last supercache */
//	SH_ClasspathManager* _cpm;
//	SH_TimestampManager* _tsm;
//	SH_ROMClassManager* _rcm;
//	SH_ScopeManager* _scm;
SH_CompiledMethodManager* _cmm;
//	SH_ByteDataManager* _bdm;
SH_AttachedDataManager* _adm;
OMRPortLibrary* _portlib;
omrthread_monitor_t _refreshMutex;
bool _cacheCorruptReported;
U_64* _runtimeFlags;
const char* _cacheName;
const char* _cacheDir;
UDATA _localCrashCntr;

UDATA _writeHashAverageTimeMicros;
UDATA _writeHashMaxWaitMicros;
UDATA _writeHashSavedMaxWaitMicros;
UDATA _writeHashContendedResetHash;
/* Also see U_64 _writeHashStartTime above */

UDATA _verboseFlags;
UDATA _bytesRead;
U_32 _actualSize;
UDATA _cacheletCntr;
J9Pool* _ccPool;
uintptr_t  _minimumAccessedShrCacheMetadata;
uintptr_t _maximumAccessedShrCacheMetadata;
bool _metadataReleased;

/* True iff (*_runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_NESTED). Set in startup().
* This flag is a misnomer. It indicates the cache is growable (chained), which also
* implies it contains cachelets. However, the cache may contain cachelets even
* if this flag is not set.
* NOT equivalent to SH_Manager::_isRunningNested.
*/
bool _runningNested;

/* True iff we allow growing the cache via chained supercaches. Set in startup().
* _runningNested requests the growing capability, but _growEnabled controls the
* support for it.
* Currently always false, because cache growing is unstable.
* Internal: Requires cachelets.
*/
bool _growEnabled;

/* For growable caches, the cache can only be serialized once, because serialization "corrupts"
* the original cache and renders it unusable. e.g. We fix up offsets in AOT methods.
* This flag indicates whether the cache has already been serialized.
* Access to this is not currently synchronized.
*/
bool _isSerialized;

bool _isAssertEnabled; /* flag to turn on/off assertion before acquiring local mutex */

SH_Managers * _managers;

We see from the top of the list that there are a number of manager
classes. They appear to decide how certain items are stored within the
cache, and encapsulate information and methods describing how the
items are to be written and read. Of course, we also have a composite
cache implementation object, _cc.

Let's take a look at how 'findCompiledMethod' works. It takes a
J9ROMMethod, the VM current thread, and parameters called
dataStart, codeStart, codeSize, and forceReplace.

--

Most of the work is delegated to the SH_Managers, whichever are
appropriate for the target data. So we should probably refer to them!

The ROMClassResourceManager, once SH_CacheMap->storeCompiledMethod
gets it successfully, is passed to the cache map's
storeROMClassResource method. In storeROMClassResource, we start by
emitting some trace messages, and calling
permitAccessToResource. Which is just a getter that returns the field
_accessPermitted from localRRM, the SH_ROMClassResourceManager object
storeCompiledMethod passed to storeROMClassResource. If access is not
permitted, we return an error, emit a trace msg, etc.

Otherwise, we enter the write mutex on _ccHead, which is at the head
of the composite cache chain (making _ccHead a composite cache). If we
can't get the write mutex, once again, we return with a resource store
error.

Then we call runEntryPointChecks. According to the comments, it should
be run before any find/store operation made to the cache. With either
the read or write mutex held, if other threads are active. As an
overview.. it checks these things:

1) Is the head corrupt? If yes, exit with error.

2) Is the address out of the bounds of the cache? If yes, exit with error.

3) Is the cache running in read-only mode? If not, do we have the
write mutex? If we have the write mutex, check for a crash. If there
was a crash, fail and exit. If we don't have the write mutex.. keep going.

Next, refresh the hash tables! Do this by calling
refreshHashtables. Per the comments, it "update[s] hashtables with new
data that might have appeared in the cache." The refresh mutex is held
throughout its execution, which makes it thread safe!! We don't need
to hold the write mutex if we have the refresh mutex. I should
specify, refreshHashtables enters the refresh mutex, not its caller.

Once the refresh mutex is held, we call readCacheUpdates. From it, we
call readCache. readCache expects to hold either the read or refresh
mutex. readCache walks the cache items using the nextEntry function in
a do/while loop. It retrieves each entry as a ShcItem*. For those
non-NULL items, it finds the suitable Manager type, belonging to the
CompositeCache. It does this by calling getAndStartManagerForType.
Each manager needs to be initialized.. this is all that is meant by
'start'. They don't run on dedicated threads or anything like that.

Anyway, this returns an SH_Manager*, which in actuality points to one
of the manager subclass objects. We call storeNew on that manager
object, with the item and a SH_CompositeCacheImpl* (named cache) as
parameters. From the call site in readCacheUpdates, this is none other
than _cc, the cache map's current cache. Which actually does the
action of storing the item in the *manager's* hashtable, the field
_hashTable inside SH_Manager, the manager abstract class. A resource
can be stored inside the cache *before* it is registered in the
manager of the corresponding type.

Before we return to discussing readCache, an interlude: what does it
mean for a cache item to be stale?? We never bothered answering that
above.. shame on us! SH_CacheMap::isStale calls
SH_CompositeCacheImpl::stale, which is little more than a wrapper
around the macro CCITEMSTALE. It's defined like this:

#define CCITEMSTALE(ih) (J9SHR_READMEM((ih)->itemLen) & 0x1)

So, we're checking to see if a single bit is set! This doesn't answer
what staleness means exactly.. or at all, depending on your
definition. For now, it suffices to know that an item is stale if it's
been invalidated in some way. Looking to the implementation of
storeNew in ROMClassResourceManager, we see that stale entries found
within the manager hash table are deleted. So it's a fair assumption
that, as the adjective 'stale' implies, the items are no longer good,
and can be discarded unhesitantly.

The do/while loop continues iterating until either some read fails, or
there are no items left in the iteration, or the cache is found to be
corrupt. The iteration is over the cache, by the way.. the passed in
SH_CompositeCacheImpl* argument cache. Not the CacheMap's own
_cc. Once finished, check if cache has become corrupt, and report that
fact if it is. Then call cache->doneReadUpdates. And we are done.

doneReadUpdates receives the currentThread and updates, the number of
cache entries that were updated. If there was more than one update,
and the new count of updates exceeds _oldUpdateCount, we update
_oldUpdateCount now that we're finished. Then we call
_debugData->processUpdates(currentThread, this). If we are protecting
the cache area that contains the ROM class (ie. the segment area, which is
flagged by the boolean _doSegmentProtect), we call
this->notifyPagesRead(). And from there we're done.

Once we return from runEntryPointChecks.. we are back in
storeROMClassResource. If we force a replacement, by the way, the RRM
marks the item as stale! We then call addROMClassResourceToCache.
initBlockData is called in the _ccHead. Which sets the info in the
ShcItem* item appropriately. Then getCacheAreaForDataType is
called. It's a SH_CompositeCacheImpl*. If the cache isn't nested
in some other cache, it's just _ccHead! Then we check to see that
the address of the ROM resource is in the range of _cc's
getBaseAddress() and _cc->getCacheLastEffectiveAddress(). If not,
it's in a different superclass, and we must fail.

Otherwise, we do a switch on the resourceType. For
TYPE_COMPILED_METHOD, we call allocateAOT on the CompositeCache.
Otherwise, we call allocateJIT for TYPE_ATTACHED_DATA (which usually
pertains to JIT hints, and JIT related info in general). All other
types are allocated with allocateBlock.

These allocations fail if the pointer they return, which is always
stored in itemInCache, regardless of type, is NULL. We do the usual
error dance and return with J9SHR_RESOURCE_STORE_FULL.

If we succeed, it's the resourceDescriptor that encapsulates knowledge
of how to write the item of the specific data type to the cache.  It
does this by calling 'writeDataToCache', with the itemInCache (not
actually the item, but a pointer to where it will live) and the
romAddress. As we saw below, romAddress forms the key into the
hashtable of the RRM, which indexes all the ROMClassResource's stored
within the cache. In particular (speaking to our interests on this
project, currently), CompiledMethodManager's writeDataToCache wraps
the info into a CompiledMethodWrapper, a struct containing fields for
the codeLength, dataLength, and the romMethodOffset (the romAddress -
the value of the CompiledMethodWrapper*, an address in the cache --
this is an SRP). We call localRRM->storeNew after writeDataToCache
returns. Again, this merely updates the localRRM's hash table to
contain the location within the cache under the key, the address of
the ROMClassResource in question.

Then commitUpdate is called on the cacheAreaForAllocate (again, this
is usually just _ccHead). We have not documented 'commitUpdate'
previously. According to comments heading up 'commitUpdate's
definition, the purpose of 'commitUpdate' is to notify other JVMs of
the cache update. It does this mostly by relying on
'commitUpdateHelper'. Specifically, it updates various cache header
counters.

'commitUpdate' is quite involved, and the expose here will conclude
our discussion of storeROMClassResource, since it's the last thing to
be called!

First, 'startCriticalUpdate' is called by 'commitUpdateHelper'. This
removes memory protection from the header. It unprotects the header of
the read/write area, and increments the crash counter. Then it
returns. By 'crashing', the cache becomes corrupted. The cache will
crash if the critical update is not 'stopped' by decrementing the
crash counter again.

That's all 'startCriticalUpdate' does. We return to where we left off
in 'commitUpdateHelper'. First, the composite cache CRC is marked as
invalid because the cache is about to change. Based on whether the
read/write section or class segment sections were updated, we
increment the readWriteSRP (resp., segmentSRP) value. Or both,
if both were modified. How do we know they were modified? The values
of the uints _storedSegmentUsedBytes and _storedReadWriteUsedBytes
tell us so. If they are 0, they act as false in a boolean context
(like the condition of an if statement).

Metadata, AOT code, and JIT code can all go into the cache entry
section, so updateSRP is decremented similarly. Then we change
_oldUpdateCount to a newly calculated value stored at
_theca->updateCountPtr. Surrounding all this, on the read/write and
metadata areas, are booleans that determine whether we use memory
protection. Earlier we unprotect these regions so we could manipulate
them, yes? But now that we've finished successfully, without a crash,
we restore protections. This is what the nested calls to
'notifyPagesCommitted' do. It works much like 'notifyPagesRead', which
we documented earlier. 'notifyPagesRead' is called at the conclusion
of 'notifyPagesCommitted', in fact, but before that, once the
applicable regions are calculated according to page size roundings as
before, _oscache->syncUpdates is called. This is what actually
synchronizes the updates to disk, depending on the semantics of the
underlying OSCache. syncUpdates is a pure virtual function in OSCache
that must be overloaded by a concrete subclass, in other
words. SH_OSCachemmap::updateSync will call j9mmap_msymc, the memory
map sync primitive, to do its work, for instance.

This brings us back to where 'notifyPagesCommitted' was possibly
called within 'commitUpdateHelper'. We call 'endCriticalUpdate' next.
It calls 'protectHeaderReadWriteArea' again, and decrements the
crash counter, undoing the work of 'startCriticalUpdate'.

From 'commitUpdateHelper' we go on to call 'updateMetadataSegment'
after updating _totalStoredBytes and _storedMetadataUsedBytes. This
mostly updates _metadataSegmentPtr, if there's an address stored
in it. Otherwise the method returns.

And that's it for 'commitUpdateHelper'. It returns to 'commitUpdate',
where it does some stuff if nested caches are enabled, but otherwise
finishes.

Ok, now to findCompiledMethod (in shrinit.cpp).

It dispatches to CacheMap's findCompiledMethod. Which, in turn, calls
out to findROMClassResource. It checks that RRM (the
SH_ROMClassResourceManager* instance) permits access.. by calling
permitAccessToResource. If useReadMutex is specified, it calls
enterReadMutex, and fails if enterReadMutex does. Then it calls
runEntryPointChecks, which checks that the cache isn't locked, isn't
read-only, we hold the right mutexes, all the manager hash tables are
up to date, etc.

Then we generate a keyfrom the resourceDescriptor. resourceDescriptor
is of type SH_ROMClassResourceManager::SH_ResourceDescriptor*.
generateKey is defined as a pure virtual function there! So it's
expected to be covered by some inheriting class. The answer to this is
that several manager classes derive from SH_ROMClassResourceManager,
and these subclasses have internal classes subclassing
SH_ResourceDescriptor. SH_CompiledMethodResourceDescriptor in
SH_CompiledMethodManager is one example. If you look to its
generateKey method, it returns the address of the method as the key,
and does nothing else.

Still, it's weird that the ROMClassResourceDescriptor and
ROMClassResourceManager are passed as two separate arguments to
findROMClassResource! Very bizarre indeed. This is just a wrapper
around rrmTableLookup.

'findROMClass' is also pretty illustrative, enough though we are not
looking to load classes of any kind just yet. We started by checking
that we have ROMClassManager, and that the head of _ccHead isn't
running read only. Assuming all it good, we get the read mutex of
_ccHead, and call 'runEntryPointChecks'.

This brings us to another detour into SH_CompositeCacheImpl, this
time, into the 'testAndSetWriteHash' method. We wondered previously
about what the 'write hash' was for. See the method description of
'testAndSetWriteHash'.

Back to 'findROMClass'! If 'testAndSetWriteHash' tells us we should
wait, whatever waiting means (we will find out shortly!), we do the
following. We calculate the amount of time we should wait in
milliseconds. We use some internal stats (_writeHashAverageTimeMicros
and _writeHashMaxWaitMicros) to determine the value of waitMillis.
Then we get endTime and startTime, initializing them to
j9time_usec_clock().

If _writeHashMaxWaitMicros != 0, then while
_ccHead->checkUpdates(currentThread) returns false (indicating that
the cache was not updated since it was last read and synchronized), we
update endTime, and see if endTime - startTime >=
_writeHashMaxWaitMicros. If so, we break from the loop we've entered!
(the while(!_ccHead->checkUpdates(currentThread)) loop, not the
enclosing do loop).

If not, we modify waitMillis accordingly and wait waitMillis
milliseconds by calling omrthread_sleep(waitMillis). There are some
rules governing how the waitMillis is increased until the max waiting
time is reached. I have no idea what inspired their design. See the
source for details.

Once we've escaped the while loop, we check again that
_ccHead->checkUpdates(currentThread) returns a positive amount. If so,
we capture the read mutex. If that doesn't succeed, we fail and
return. Then we call 'refreshHashtables', which we've already
covered. Like _ccHead->checkUpdates, 'refreshHashtables' returns the
number of items read (and written into hashtables in the process).

If that succeeds (ie. rv != -1), we call localRCM->locateROMClass.
From within the Manager's hash, which is why the calls to update were
necessary. Well, not. 'refreshHashtables' was necessary, which we know
from _ccHead->checkUpdates returning a positive value. If nothing had
been updated, 'refreshHashtables' wouldn't have been necessary.

Anyway, localRCM->locateROMClass returns an error code containing
LOCATE_ROMCLASS_RETURN_DO_TRY_WAIT (which can happen), we continue
with the enclosing do if the actualTimeMicros (the time waited) hasn't
exceeded the maximum wait time. Otherwise we set updates, the count
returned from _ccHead->checkUpdates(), to 0. If the return code wasn't
LOCATE_ROMCLASS_RETURN_DO_TRY_WAIT, and counter of wait periods is >
0, we call 'updateAverageWriteHashTime', so that the average of write
hash wait times so far is updated to reflect the last witnessed length
of time the write hash was waited on.

If updates == 0, it could be that the class being searched for doesn't
exist, at least, not to the cache.. If that's the case, set
_writeHashMaxWaitMicros to 0. Also record the startTime, and some
other stuff. At this point, retry is false, and so we leave the
do/while loop (which continues only if retry is true, naturally).

After checking the staleness of ClassPathEntryItem (and marking the
ROMClass as stale if so), if the ROM class was found, we call
_ccHead->tryResetWriteHash if are using the write hash. And we're
trying to reduce contention.. this is a runtime flag stored within the
cache, btw. If we hold the write hash, or if the write hash failed to
be set too many times, we reset it. This is all the action of
_ccHead->tryResetWriteHash.

Once finished, we 'updateAccessedShrCacheMetadataBounds', and
'updateBytesRead'. That's about it!

My question, currently: when do we call 'rollbackUpdate'? A: not from
anywhere within CacheMap, it would appear. So we won't document it
just yet.

'updateROMSegmentList' is mostly a wrapper around
'updateROMSegmentListForCache'. We iterate through the linked list of
caches (that are started!), calling 'updateROMSegmentListForCache' on
each.

'updateROMSegmentListForCache' does the following. It gets the current
ROM Segment. How you ask? By calling getCurrentROMSegment() on the
target cache. It returns _currentROMSegment. If it's NULL, it's
initialized via 'addNewROMImageSegment'. Mostly, it calls
'createNewSegment', and adds the resulting romSegment as a
J9AVLTreeNode to vm->classMemorySegments->avlTreeData, which is an
index of class memory segments, it looks like.

'createNewSegment' calls
vm->internalVMFunctions->allocateMemorySegmentListEntry to retrieve
the address of romSegment, a J9MemorySegment*, and its fields are
initialized. So, it does appear as ROM class segments are contained
*within* the shared cache! Although.. no. The ROM segment (called
romSegment) appears to simply be a descriptor record, that stores the
type, the size of the ROM class, the base address, its class loader,
etc. The base address it records belongs to the
cache. forCache->getBaseAddress(), if we're being specific. This is
none other CASTART(_theca). The beginning of the segment entry free
area.

'updateROMSegmentListForCache' then calls setCurrentROMSegment on the
cache. And it proceeds to walk the ROM class list within the cache,
using resident info from the ROM segment. Namely, the
currentSegment. If the ROM class size found is too great for what the
current ROM segment has recorded, create a new segment that reflects
the present size. This is the essence of the update.. the VM's view on
which ROM classes are contained with the cache can be out of step with
the state of the cache itself. As we've seen. Hence the need for
updates.

ROM classes are stored via 'commitROMClass'. That's what *adds* a ROM
class to the cache. Space for ROM classes is allocated via
'allocateROMClass'. Which is part of CacheMap, not CompositeCache,
somewhat confusingly. Starting with 'allocateROMClass' first.

'allocateROMClass' tries to allocate memory in the class debug
segment. Debug info pertaining to the class, I think. Then we call
'allocateROMClassOnly', and that's presumably where the interesting
stuff begins. It's assigned the returned address to pieces->romClass.
And there's a lot more logic dealing with the ClasspathManager,
marking previously stored versions of the class as stale if
found. There's plenty of trace messages recording what's going on
there. Either way though, we wind up calling 'allocateFromCache'.
We allocate an item of TYPE_ORPHAN, an orphan ROM class.

'allocateFromCache' checks some settings, emits some trace messages,
and calls initBlockData and allocateWithSegment on the
localCacheAreaForAllocate, which is returned from
'getCacheAreaForDataType'. localCacheAreaForAllocate is indeed a
SH_CompositeCacheImpl*. We call
allocateCacheAreaForAllocate->allocateWithSegment.

allocateCacheAreaForAllocate->allocateWithSegment just wraps a call
onto SH_CompositeCacheImpl::allocate, with the allocate type being a
block. The segmentBuffer parameter passed into it is a BlockPtr*, so a
double pointer. allocate winds up writing the address of the region to
be written, to it, starting at line 2788 of CompositeCache.cpp in the
OpenJ9 source.

Back to commitROMClass. Now that the ROM class has been written into
the cache, we want to store it in one of two wrapper types:
ROMClassWrapper or ScopedROMClassWrapper. This is based on whether the
boolean useScope is true. useScope's value is true if neither
partitionInCache nor modContextInCache, both parameters to
'commitROMClass', are NULL values.

Even if useScope is false, srcw, the ScopedROMClassWrapper object
created in the body of 'commitROM', is initialized in several
parts. Its ClassPathEntryIndex, cpeIndex, is recorded, and timestamp
is set to 0. I have no clue how this ClassPathEntry business works,
currently. I'm now weighing to what degree it shapes the design of the
SCC, and whether I should investigate it further. Until I reach a
conclusion on that, I'm going to ignore it for the rest of this
miniature writeup of 'commitROMClass'.

I have some idea of what a modification context is, but not a
partition. It would be lovely if the writers of the SCC were sat down
and encouraged to use consistent language. I guess the onus for that
is now on us.

We call _rcm->storeNew to store the itemInCache. itemInCache is cast
to a ScopedROMClassManager*, regardless of whether useScope is
true. Then we call cacheAreaForAllocate->commitUpdate,
'updateROMSegmentList', we do some more stuff for the write
hash.. yeah.

TODO: maybe answer this whole allocate JIT vs. allocate AOT thing??
Yes? What the limitations of the JIT and AOT sections really mean,
amid the structure of the composite cache? Also, getReaderCount!
Where does _metadataSegmentPtr point to????

Minor thing here, that will become important in the study of the
CacheMap source.

'notifyRefreshMutexEntered' updates
_commonCCInfo->hasRefreshMutexThread to currentThread. Similarly,
'notifyRefreshMutexExited' sets _commonCCInfo->hasRefreshMutexThread
to NULL.

--

MUTEX NOTES:

A comment points out that multiple readers can read concurrently!!
Readers can also read at the same time a writer is writing! Of course,
this is sort of the entire point of having distinct read and write
mutexes. Locking prevents the write mutex from being claimed. Also,
here's a blurb above enterWriteMutex:

 * Allows only single-threaded writing to the cache.
 * Write mutex allows multiple concurrent readers, unless lockCache

Yeah, locking stops readers. Stops readers cold! But what if the cache
is locked when 'enterWriteMutex' is called? No, 'enterWriteMutex' does
not check to see that the cache is locked. Rather, it has the
parameter lockCache, a bool, that indicates whether it should lock the
cache also, to prevent readers from reading anything.

Yeah, 'enterReadMutex' pussyfoots around the cache being locked. To
lock the cache, we need the write mutex.. ergo, it suffices to wait
for the thread that holds the write mutex (which therefore locked the
cache!!) to relinquish the write mutex. Then the write mutex is
released, and the reader count is decremented, and all that crap.

_theca->readerCount, the atomic quantity incremented/decremented here,
is something that we get through 'getReaderCount', and also something
that 'doLockCache' cares about. While _theca->readerCount > 0, we wait
out the patienceCntr in 'doLockCache'. If _theca->readerCount > 0
after we've exceeded the patienceCntr, we set _theca->readerCount =
0. Since the 'reader has almost certainly died.' We already called
setIsLocked(true) ages ago, but we wait for the reader count to return
to 0. Did you know the caller of 'doLockCache' must hold the write
mutex! It's true. Notice that 'enterReadMutex' tries to sleep until
the cache is unlocked, and the write mutex is released. Increasing the
reader count is meant to prevent a lock from occurring (within
reason), which is why 'enterReadMutex' increments the reader count
before calling 'isLocked'. This is all in the comments! Note that
multiple attempts to 'claim' the read mutex are not in fact mutually
excluding.

Any number of concurrent readers can proceed at once! They don't need
the write mutex to read, either! If we want to prevent reading, we
must lock the cache, which means waiting for the reader count to
dwindle to 0. And for that, we must effectively be a writer, since we
need to hold the write mutex, which is a write mutex in the true sense
of the word, since it allows only single-threaded writing of the
cache.

Where do we check to see if the cache is locked? Why, through
'isLocked()', of course.. uhhh, nowhere I can tell, really. It's just
a means to coordinate the read mutex, it looks like. Like, if we call
'enterReadMutex' and find that the cache is locked, we're forced to
wait until it's no longer locked. But then when we 'claim' the read
mutex by the end of 'enterReadMutex', do we lock the cache? No, not
exactly.. we don't wait for it to become unlocked, either. We wait
until we claim the write mutex, we decrement the reader count, and
then we relinquish the write mutex! Which is to say the cache is no
longer locked at that point. It is only locked when the write mutex is
held, as a necessary but insufficient condition. Uhhh... no, actually,
it leaves the reader count incremented, and then returns.

Finally, 'enterReadWriteAreaMutex'. We wrote it up earlier. The main
thing to know is that it's a separate mutex acquired via
oscacheToUse->acquireWriteLock(_commonCCInfo->readWriteAreaMutexID). That's
about all! There's a bunch of other checks. See the earlier writeup of
'enterReadWriteAreaMutex' if you need to know.

When is 'doLockCache' called? And 'enterReadMutex' and
'enterWriteMutex'? And 'enterReadWriteAreaMutex'? From nowhere in
CompositeCache.cpp, except 'enterWriteMutex'.

Let's look to CacheMap for these answers:

'enterReadMutex' is used from these places:

findROMClass, lines 2464, 2539
findROMClassResource, line 2954
findAttachedData, line 3469
findSharedData, line 3979
getCachedUTFString, line 5325

'enterWriteMutex' is used from these places (the cache is not locked
by the calls except where indicated):

storeROMClassResource, line 2778
updateROMClassResource, line 2868 (we lock the cache as well here!)
storeSharedData, line 3825 (locks the cache if performing an overwrite
of previous data)
acquirePrivateSharedData, line 4033
markStale, line 4288 (locks the cache)
markItemStaleCheckMutex, line 4378
destroy, 4395 (locks the cache)
printAllCacheStats, line 4474
getCachedUTFString, line 5349
serializeSharedCache, line 6075
startClassTransaction, line 6485
aotMethodOperationHelper, line 6882 (locked if not simply finding
methods)
protectPartiallyFilledPages, line 7236

'enterReadWriteAreaMutex' is used from these areas:

enterStringTableMutex, line 5255
createNewCachelet, line 5591 (obsolete, as cachelets are obsolete!)

'doLockCache' is used from these areas:

markStale, line 4283 (yes, this is in CacheMap)

And that's all she wrote!!

NOW CACHEMAP:

CACHEMAP.HPP MEMBER VARIABLES:

 	SH_CompositeCacheImpl* _cc;					/* current cache */

	/* See other _writeHash fields below. Put U_64 at the top so the debug
	 * extensions can more easily mirror the shape.
	 */
	U_64 _writeHashStartTime; // when was the write hash initialized?
	OMRSharedClassConfig* _sharedClassConfig;   /* the shared
	class conf! of course.  */

	SH_CompositeCacheImpl* _ccHead;				/* head of supercache list */
	SH_CompositeCacheImpl* _cacheletHead;		/* head of all known cachelets */
	SH_CompositeCacheImpl* _ccCacheletHead;		/* head of cachelet list for current cache */
	SH_CompositeCacheImpl* _cacheletTail;		/* tail of all known cachelets */
	SH_CompositeCacheImpl* _prevCClastCachelet;	/* Reference to the last allocated cachelet in the last supercache */
	SH_ClasspathManager* _cpm;           /* self explanatory. all managers are! */
	SH_TimestampManager* _tsm;
	SH_ROMClassManager* _rcm;
	SH_ScopeManager* _scm;
	SH_CompiledMethodManager* _cmm;
  	SH_ByteDataManager* _bdm;
	SH_AttachedDataManager* _adm;
	OMRPortLibrary* _portlib;  // the portlib, ofcourse.
	omrthread_monitor_t _refreshMutex;

        /* Q: does the CompositeCache have a refresh mutex? A: Nope!

	Although it does have the functions
	'notifyRefreshMutexEntered' and 'notifyRefreshMutexExited'.
	*/
	bool _cacheCorruptReported;
	U_64* _runtimeFlags;
	const char* _cacheName;
	const char* _cacheDir;
	UDATA _localCrashCntr;

	UDATA _writeHashAverageTimeMicros;
	UDATA _writeHashMaxWaitMicros;
	UDATA _writeHashSavedMaxWaitMicros;
	UDATA _writeHashContendedResetHash;
	/* Also see U_64 _writeHashStartTime above */

	UDATA _verboseFlags;
	UDATA _bytesRead;
	U_32 _actualSize;
	UDATA _cacheletCntr;
	J9Pool* _ccPool;
	uintptr_t  _minimumAccessedShrCacheMetadata;
	uintptr_t _maximumAccessedShrCacheMetadata;
	bool _metadataReleased;

	/* True iff (*_runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_NESTED). Set in startup().
	 * This flag is a misnomer. It indicates the cache is growable (chained), which also
	 * implies it contains cachelets. However, the cache may contain cachelets even
	 * if this flag is not set.
	 * NOT equivalent to SH_Manager::_isRunningNested.
	 */
	bool _runningNested;

	/* True iff we allow growing the cache via chained supercaches. Set in startup().
	 * _runningNested requests the growing capability, but _growEnabled controls the
	 * support for it.
	 * Currently always false, because cache growing is unstable.
	 * Internal: Requires cachelets.
	 */
	bool _growEnabled; /* we grow the cache through supercaches! finally. */

	/* For growable caches, the cache can only be serialized once, because serialization "corrupts"
	 * the original cache and renders it unusable. e.g. We fix up offsets in AOT methods.
	 * This flag indicates whether the cache has already been serialized.
	 * Access to this is not currently synchronized.
	 */
	bool _isSerialized;

	bool _isAssertEnabled; /* flag to turn on/off assertion before acquiring local mutex */

	SH_Managers * _managers;

CACHEMAP.CPP

'enterLocalMutex' calls 'enterReentrantLocalMutex' immediately in its
return clause. If _isAssertEnabled is true, it asserts that we do not
possess the local mutex. The comment says the mutex can't be entered
recursively, so there you go.

'exitLocalMutex'.. much the same thing, right down to the assert if
_isAssertEnabled is true. 'exitReentrantLocalMutex' is called in the
return clause.

'enterRefreshMutex' calls 'enterReentrantLocalMutex' and examines the
rc. If rc == 0, and _refreshMutex->count == 1, it calls
_ccHead->notifyRefreshMutexEntered.

'exitRefreshMutex' asserts that we have the local mutex. Regardless of
whether _isAssertEnabled is true, oddly. It checks to see if 1 ==
_refreshMutex->count, and if so, calls
_ccHead->notifyRefreshMutexExited. Unlike 'enterRefreshMutex', it
doesn't end there. It calls 'exitReentrantLocalMutex' and returns the
rc.

'newInstance' is a a static method. Which is only ever
single-threaded. It calls the function initialize on a newCacheMap
CacheMap object, which it returns. Apart from bracketing trace calls,
there's nothing else to document here.

'dontNeedMetadata'.. the comments read thus:

/**
 * Advise the OS to release resources associated with
 * the metadata which have been accessed to date.
 */

I don't know what 'advising' means in this context. After computing
the min max access bounds of the metadata area, we call
_ccHead->dontNeedMetadata.. which passes the same call onto the
OsCache. The OsCache passes it to j9mmap_dont_need (if an OsCachemmap
instance). sysv doesn't seem to override it. The root OsCache dontNeedMetadata
just returns without doing a thing. There's a comment saying the
function should be overridden if the cache is persistent, and
OsCacheSysv is not. Makes sense, I suppose. Why would you want to
alert the OS of this, though? Perhaps because you don't need
metadata?? Like the name suggests?

'newInstanceForStats' is again a static function that does the
initialization does just as 'newInstance' does, but instead
'initialize' is toggled to initialize with stats.

'initialize' is only ever single-threaded! That's all the comments
say. It's very simple. It initializes all its *Manager pointers by
calling those Manager classes' static newInstance method.

'getRequiredConstrBytes' computes the required bytes needed to
construct the CompositeCache and each of the manager classes, and the
Managers class, which manages the managers! And the size of the
CacheMap. The total is returned.

'cleanup' cleans up resources, by using the Managers instance to walk
the instantiated managers we have, and call cleanup(currentThread) on
each. Then it walks the chain of composite caches and calls
theCC->cleanup on each of those. Then the cache descriptor list
(cacheDescriptorList) within _sharedClassConfig is reset by calling
this->resetCacheDescriptorList(currentThread, _sharedClassConfig).
Then the refresh mutex is destroyed, and then we're effectively
over. The _ccPool is "killed" via pool_kill(_ccPool).

'sanityWalkROMClassSegment' has this leading comment:

/* Walks the ROMClasses in the ROMClass segment performing a quick check to make
 * sure that the walk produces sensible results. Any failure in the walk should result
 * in a corrupted cache behaviour. */

Does a demo walk to check that the ROMClass segment is 'sane', which
is to say uncorrupted. We walk the segment list by reading the romSize
attribute from each ROMClass object, and check to see if the walk
wraps around the previous valid walk pointer somehow, or if suddenly
goes beyond the right bound of the segment list. If so, corruption is
flagged through _ccHead->setCorruptCache. That's it, easy-peasy.

'startup' starts by setting up some basic member variables
(_actualSize, _runtimeFlags, _verboseFlags), then initializes
_refreshMutex. tryCntr, the try counter probably, is incremented. This
is just after entering a do/while. We call _ccHead->startup. If it
returns CC_STARTUP_CORRUPT, we call 'reportCorruptCache'.

Now, if stats aren't enabled and the _ccHead->isRunningReadOnly() ==
false, and the rc is one of CC_STARTUP_CORRUPT, CC_STARTUP_RESET, or
CC_STARTUP_SOFT_RESET, we call _ccHead->deleteCache and
_ccHead->cleanup. If the deleteRc (from the deleteCache call we just
made, OBVIOUSLY) is 0, and rc == CC_STARTUP_CORRUPT, we call
'resetCorruptState'. Then, if cacheFileSize > 0, we install it back
into the config struct as piconfig->sharedClassCacheSize =
cacheFileSize.

If the restore check is not enabled (checked with J9_ARE_NO_BITS_SET)
we see if the delete succeeded, or failing that, if
CC_STARTUP_SOFT_RESET was returned. If so, we set doRetry to true!
Then we reach the end of the do loop. The loop conditional is this:

doRetry && (tryCntr < 2)

We retry at most twice, then we're done. We can see from the above
that we don't want to delete a corrupted cache and retry in the event
that we're gathering stats, the restore check is not enabled, etc.

After escaping the do/while, we check that rc != CC_STARTUP_OK. If so,
we return -2 if rc == CC_STARTUP_NO_CACHE and -1 otherwise. If rc ==
CC_STARTUP_OK, and  check _ccHead->isRunningReadOnly(). If so, we set

*_runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_READONLY;

and

/* If running read-only, treat the cache as full */
_ccHead->markReadOnlyCacheFull();

So we treat the cache as full if it's read-only! Which is effectively
same thing if 'treating the cache as full' means what I think it
means. Then we call 'initializeROMSegmentList' and return -1 if it
fails, after some trace messages. Then we return 0.

'addNewROMImageSegment' is just this:

/* Assume cc is intialized OK */
/* THREADING: Only ever single threaded */
/* Creates a new ROMClass memory segment and adds it to the avl tree */
J9MemorySegment*
SH_CacheMap::addNewROMImageSegment(J9VMThread* currentThread, U_8* segmentBase, U_8* segmentEnd)
{
	J9MemorySegment* romSegment = NULL;
	J9JavaVM* vm = currentThread->javaVM;
	UDATA type = MEMORY_TYPE_ROM_CLASS | MEMORY_TYPE_ROM | MEMORY_TYPE_FIXEDSIZE;

	Trc_SHR_CM_addNewROMImageSegment_Entry(currentThread, segmentBase, segmentEnd);

	if ((romSegment = createNewSegment(currentThread, type,
	   		  		   vm->classMemorySegments,
					   segmentBase, segmentBase,
					   segmentEnd, segmentBase))
	   		  		   != NULL)
        {
		avl_insert(&vm->classMemorySegments->avlTreeData, (J9AVLTreeNode *) romSegment);
	}

	Trc_SHR_CM_addNewROMImageSegment_Exit(currentThread, romSegment);

	return romSegment;
}

So it calls 'createNewSegment' and indexes the resulting romSegment
into the AVL tree that tracks the locations of class
MemorySegments. There you go! That's it.

'createNewSegment' looks like this:

J9MemorySegment*
SH_CacheMap::createNewSegment(J9VMThread* currentThread, UDATA type, J9MemorySegmentList* segmentList,
		U_8* baseAddress, U_8* heapBase, U_8* heapTop, U_8* heapAlloc)
{
	J9MemorySegment* romSegment = NULL;
	J9JavaVM* vm = currentThread->javaVM;

	Trc_SHR_CM_createNewSegment_Entry(currentThread, type, segmentList, baseAddress, heapBase, heapTop, heapAlloc);

	if ((romSegment = vm->internalVMFunctions->allocateMemorySegmentListEntry(segmentList)) != NULL) {
		romSegment->type = type;
		romSegment->size = (heapTop - baseAddress);
		romSegment->baseAddress = baseAddress;
		romSegment->heapBase = heapBase;
		romSegment->heapTop = heapTop;
		romSegment->heapAlloc = heapAlloc;
		romSegment->classLoader = vm->systemClassLoader;
	}

	Trc_SHR_CM_createNewSegment_Exit(currentThread, romSegment);

	return romSegment;
}

'allocateMemorySegmentListEntry' is called, as we can see, and the
romSegment is initialized. It's a C struct, and its members are
exactly what you see.

'updateROMSegmentList' tries to get the local mutex if preemptive
threading is enabled, if it doesn't have the class segment mutex.
Then we iterate through the cache chain and call
'updateROMSegmentListForCache' on each one.

Again, if preemption is enabled, and we don't have the class segment
mutex, and the class segment mutex is initialized, we call
'exitLocalMutex'. This is to be called after a ROMClass has been added
to the cache.

In 'updateROMSegmentListForCache', we need to hold the class segment
mutex. Going back to the code for 'updateROMSegmentList', there is an
assert for ShouldHaveLocalMutex if hasClassSegmentMutex is true. If
it's not true, we call enterLocalMutex.. that is the same thing
apparently? It would seem so.

We try to get the currentSegment by calling
forCache->getCurrentROMSegment() (yes, this is the same forCache in
the method name). If the currentSegment is NULL, we call
'addNewROMImageSegment' using the base addresses of forCache's ROM
segment list. If that doesn't exist, return. Otherwise, call
forCache->setCurrentROMSegment to set it to currentSegment.

If currentSegAlloc < cacheAlloc, then there was a cache update not
reflected in the *current* ROMClass segment. So, there's a while loop
contained inside.. its purpose is to walk up to the point of
cacheAlloc, each step being a ROMClass. Once we make it to the end
without leaving the ROMClass segment, we set the heapAlloc pointer
inside the currentSegment struct to cacheAlloc.

Of course, if we don't make it, then skip the segment! Allocate a new
one, and make that the current segment. Once that's all finished,
write cacheAlloc to currentSegment->heapAlloc. That's it.

Now 'initializeROMSegmentList'. We have these mutexes:

omrthread_monitor_t classSegmentMutex  = vm->classMemorySegments->segmentMutex;
omrthread_monitor_t memorySegmentMutex = vm->memorySegments->segmentMutex;

Conjured up from nothing! Or the VM, if you like.

Although classSegmentMutex is fed into an assert:

Trc_SHR_Assert_ShouldNotHaveLocalMutex(classSegmentMutex);

This mutex needs to be distinct from the local mutex!

Ohh, no shit.. this refers to locally initialized mutexes! Like in all
the previous cases we've seen.

Here's the type of config->cacheDescriptorList:

typedef struct J9SharedClassCacheDescriptor {
	struct J9SharedCacheHeader* cacheStartAddress;
	void* romclassStartAddress;
	void* metadataStartAddress;
	UDATA cacheSizeBytes;
	void* deployedROMClassStartAddress;
	struct J9SharedClassCacheDescriptor* next;
} J9SharedClassCacheDescriptor;

Ok, let's try this again. We claim the classSegmentMutex and
memorySegmentMutex from vm->classMemorySegments->segmentMutex and
vm->memorySegments->segmentMutex.  These are VM-wide mutexes!  We
shouldn't have the classSegmentMutex, which is checked through an
assert. Then we get the cacheBase and firstROMClassAddress, which
are.. the base address of the cache, and the earliest part of the
ROMClass segment list. cacheDebugAreaStart, same thing.

Then we claim the config->configMonitor mutex if it's initialized. If
the cacheStartAddress is initialized *within the descriptor list*, we
assert that it's equal to _cc->getCacheHeaderAddress(). An important
invariant. Otherwise, if it's not initialized, we set it to that
value. Then we assert it's non-NULL, after the conditional is
concluded.

Then we do this:

config->cacheDescriptorList->romclassStartAddress = firstROMClassAddress;
config->cacheDescriptorList->metadataStartAddress = cacheDebugAreaStart;
config->cacheDescriptorList->cacheSizeBytes = _cc->getCacheMemorySize();

We are loading the cacheDescriptorList with.. descriptor data. Then we
try to claim the memorySegmentMutex defined locally, earlier in the
method body, with 'enterLocalMutex' if preemption is enabled
(J9VM_THR_PREEMPTIVE). We create a new memory segment of type
MEMORY_TYPE_SHARED_DATA, through 'createNewSegment', and store it to
config->metdataMemorySegment. It's another descriptor of the metadata
area, in effect, but communicated to the VM. Then we call
'exitLocalMutex' on memorySegmentMutex if preemption is enabled. We
call 'exitLocalMutex' on config->configMonitor, signaling that we are
done.

We return the result, which is a UDATA initialized to 1. It's set to 0
when 'createNewSegment' is successfully called.

'updateBytesRead' takes a single argument, numBytes, reads the value
of the atomic _bytesRead, and tries to do an atomic compare exchange
(CAS, to the rest of us) on it, and will continue attempting to do it
in a do/while loop until finally it takes. That's it.

'startManager' takes the currentThread and SH_Manager*. If manager !=
NULL, and manager->getState() != MANAGER_STATE_STARTED, then we do
some stuff! Otherwise we return 1. Assuming we do stuff, we check that
manager->getState() == MANAGER_STATE_SHUTDOWN, we assert is should
never have happened (we go full Trump) and return 0. Failing that, we
check that _refreshMutex is not owned by this thread. We don't want
another thread to shut the manager down while this function is using
it. So we call 'enterRefreshMutex', and switch the local
doExistRefreshMutex (a bool) to true. Then we call
manager->startup(..). That expression != 0 is assigned to rc, which
means rc is 0 if the expression was false. Then, we enter a while
loop.. while rc != -1 and the manager state isn't
MANAGER_STATE_STARTED, we sleep 10 micros and call manager->startup
again.

If rc == -1, we return -1 ! After that, if doExitRefreshMutex is true,
we call 'exitRefreshMutex'. Notice how we continue to hold the
_refreshMutex if startup fails. Finally, return 1.

'getAndStartManagerForType' calls
managers()->getManagerForDataType(dataType), where dataType is a
parameter. Once the manager is retrieved, we call
startManager(currentThread, manager) and check that the result is
1. If so, result is set to dataType. Then we set

*startedManager = manager;

and we return the result.

'readCacheUpdates' sets the cache to _cc, and while cache is not NULL,
we call 'readCache' on it, provided that cache->isStarted() and the
number of availableCacheUpdates > 0 (we call
cache->checkUpdates(currentThread)). Once 'readCache' returns
cacheResult (an IDATA), we check that

(CM_READ_CACHE_FAILED != cacheResult) && (CM_CACHE_CORRUPT !=
cacheResult)

we set itemsRead += cacheResult. If cache = _cc, we set cache =
_cacheletHead, and if not, we set cache = cache->getNext() (we are
walking the cache list!).

Once we're finished, we return itemsRead.

'readCache' expects to have either the write mutex
(_ccHead->hasWriteMutex(currentThread) should be true) and if not,
there's an assert for ShouldHaveLocalMutex(_refreshMutex). Then we
enter a do/while. We call cache->nextEntry(..). This starts at the
beginning of the metadata area.. I checked the underlying
CompositeCache calls to confirm this. If it's a valid ShcItem, we
check that the itemType read from it is valid. If not, and
startupForStats is false (a parameter of 'readCache'), we call
cache->setCorruptCache, and set result = CM_CACHE_CORRUPT.

Otherwise, we call 'getAndStartManagerForType'. If the manager fails
to start (ie. rc == -1) we increment result for some reason, and
ignore the manager. Otherwise, rc > 0, we call manager->storeNew(..)
on it, and cache. The manager will store the item if it doesn't have
it already. All the redundancy checking logic is contained within
storeNew. We decrement expectedCntr if expectedCntr != -1. Otherwise,
there's a trace error, and the result becomes CM_READ_CACHE_FAILED.

If !((rc > 0) && ((UDATA)rc == itemType)), result =
CM_READ_CACHE_FAILED, again.

Then go to the while conditional. We break if

!((it != NULL) && (result != CM_READ_CACHE_FAILED) && (result !=
  CM_CACHE_CORRUPT) && (expectedCntr==-1 || expectedCntr>0))

expectedCntr is set to expectedUpdates, in other words. Once it runs
done to 0, that's the termination condition we need in the absence of
the cache failing, being corrupt, or it becoming null.

Once we exit the loop, if (false == startupForStats) &&
(cache->isCacheCorrupt()), call 'reportCorruptCache'; internal to that
if, if NULL == it, we set result = CM_CACHE_CORRUPT.

If expectedUpdates != -1 && result != expectedUpdates, (result charts
the number of expected updates if it's not negative and therefore an
error code!) we emit a trace message.

Then, regardless of everything that just happened, we call
cache->doneReadUpdates(..), and return the result.

'checkForCrash' calls _ccHead->crashDetected(&_localCrashCntr). If
it's true, we call resetAllManagers(currentThread), and return -1 if
it fails. If it succeeds, we call _cc->reset(currentThread), and set
rc = refreshHashTables(currentThread, hasClassSegmentMutex).
Then we return rc.

'refreshHashtables' setes the local itemsReads to 0, then calls
'enterRefreshMutex'. If it succeeds, it calls 'readCacheUpdates'. If
itemsRead > 0, if checks that hasClassSegmentMutex holds. If so, it
calls 'updateROMSegmentList'. That's the if. Next, we call
_cc->updateMetadataSegment. if _ccHead->isCacheCorrupt(), we call
'exitRefreshMutex' and return -1.

If that didn't happen, we call 'exitRefreshMutex'. Then we return
itemsRead.

'isStale' checks if item != NULL, and then checks that
!_ccHead->stale(..) on the item. We return 0, else, 1.

'resetAllManagers' is just this:

IDATA
SH_CacheMap::resetAllManagers(J9VMThread* currentThread)
{
	SH_Manager* walkManager;
	SH_Managers::ManagerWalkState state;

	walkManager = managers()->startDo(currentThread, 0, &state);
	while (walkManager) {
		if (walkManager->reset(currentThread)) {
			return -1;
		}
		walkManager = managers()->nextDo(&state);
	}
	return 0;
}

Walks the managers and resets them all! Completely straightforward,
that.

'getCacheAreaForDataType' expects to hold the cache write mutex.. its
preamble comment says so. Also, there's an assert checking
_ccHead->hasWriteMutex(..) is true. It asserts the same thing is true
twice!! But at the end of the day it returns cacheletForAllocate,
which is NULL, owing to the deciding code being hidden beneath

#if defined(J9SHR_CACHELET_SUPPORT)
..
#endif

and cachelets are obsolete now.

'updateAverageWriteHashTime' takes actualTimeMicros, which is capped
from above by the constant WRITE_HASH_WAIT_MAX_MICROS. If
actualTimeMicros > _writeHashMaxWaitMicros, we set
_writeHashMaxWaitMicros = actualTimeMicros.

If _writeHashAverageTimeMicros != 0,

_writeHashAverageTimeMicros = ((_writeHashAverageTimeMicros * 10) +
actualTimeMicros) / 11;

It's a weighted average, obviously.

Otherwise,

_writeHashAverageTimeMicros = actualTimeMicros;

And we're done.

'updateClasspathInfo' checks that we hold
currentThread->javaVM->classMemorySegments->segmentMutex. We call
'getClasspathManager' to retrieve the ClasspathManager, and store it
to localCPM. If haveWriteMutex (a parameter) is false, we have the line

enteredWriteMutex = _ccHead->enterWriteMutex(currentThread, false,
fnName);

Then if enteredWriteMutex == 0,

if (haveWriteMutex==false && (runEntryPointChecks(currentThread, NULL, NULL) == -1)) {
      Trc_SHR_CM_updateClasspathInfo_ExitNull1(currentThread);
      goto _exitNULLWithMutex;
}
if (localCPM->update(currentThread, cp, cpeIndex, &answer)) {
      Trc_SHR_CM_updateClasspathInfo_ExitNull2(currentThread);
      goto _exitNULLWithMutex;
}
if (!answer) {
      answer = addClasspathToCache(currentThread, cp);
}

So we call 'runEntryPointChecks' and localCPM->update(..). If answer
is NULL from the call to localCPM->update(..), we invoke the line

      answer = addClasspathToCache(currentThread, cp);

where we add the class path to the class. If the answer wasn't present
in the ClasspathManager, localCPM->update(..) apparently did nothing
with it. The rest of the function deals with whether the cache is
partitioned or has a modification context. This is checked in the
expression

partition || modContext

which are both arguments to 'updateClasspathInfo'. In that case, we go
on using the ScopeManager to find the scopes that apply to the
partition and modContext codes. What that means, I don't yet
know. Apparently, partition constitutes a scope. The next segment of
code tries to retrieve the cachedPartition and cachedModContext from
the ScopeManager using 'findScopeForUTF', and adds them to the scope
with 'addScopeToCache' if not.

Then we try to call _ccHead->exitWriteMutex(..), and blah blah.
We return answer if we got one, and if the 'addScopeToCache' logic
failed, we return NULL.

'addScopeToCache' is up next, which we just covered, if you
recall. Surely you do. Anyway. It needs to have the CC's write mutex,
which the comments mention and which is checked with the adjoining
assert. It uses 'getScopeManager' to write to localSCM. If localSCM is
still NULL, return NULL. If RUNTIME_FLAGS_PREVENT_BLOCK_DATA_UPDATE is
set in _runtimeFlags, call 'increaseUnstoredFlags' and return
NULL. Otherwise, call _ccHead->initBlockData(..) is called on itemPtr,
a local pointer to another local ShcItem, item.

Then call 'getCacheAreaForDataType'. It writes to cacheForAllocate. If
it's NULL, return NULL. Otherwise, use
cacheForAllocate->allocateBlock(..) to return a value to
itemInCache. If itemInCache == NULL, return NULL. Then we copy the
scope argument..

memcpy(ITEMDATA(itemInCache), scope, totalSizeNeeded);

into the itemInCache. We call localSCM->storeNew(..) to write
itemInCache which is now in cacheForAllocate. we copy the result using

result = (const J9UTF8*)ITEMDATA(itemInCache);

and call cacheForAllocate->commitUpdate(..). Then we return result.

'addClasspathToCache' does much the same thing.

1. Check for write mutex, assert it's there
2. increaseUnstoredBytes & return NULL if
RUNTIME_FLAGS_PREVENT_BLOCK_DATA_UPDATE is enabled
3. Check to that _ccHead->canStoreClasspaths() is true, if not return
NULL
4. Same song and dance with cacheAreaForAllocate->allocateBlock as
before

Also there's some stuff with setting timestamps on the classpath
wrapper. Probably so we know when the classpath was received. Which
might be important for debugging purposes I guess.

Then we call 'commitUpdate' and we are done once more!

'runEntryPointChecks' states it should be done before any find/store
operation on the cache. It needs either the read or mutex to be held.
It returns the number of items it reads! Why you may ask? What's the
point of checking the entry points, whatever that might mean?

We get the class segment mutex and check that the cache isn't
corrupt.. if it is, we return -1. Then:

1. Check _ccHead->isAddressInCache(isAddressInCache) (?). If not,
return -1.
2. If we have the write mutex, call 'checkForCrash'. If rc < 0, return
rc.
3. a. Call 'refreshHashtables'. If it returns -1, return -1.
   b. Else, if itemsAdded > 0 (this was returned by
   'refreshHashtables'), then if we have the write mutex, set
   hasMutex = true. Else, if J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_ONFIND,
   we try to enter the write mutex, and return the result of that call
   to hasMutex. If hasMutex is then true, set doExitMutex = true.

   If hasMutex is true, and the _ccHead isn't lock, call
   _ccHead->protectPartiallyFilledPages(..). Otherwise, call

   _ccHead->protectPartiallyFilledPages(currentThread, true, false,
   true);

   explained by this comment:

   /* Do not protect last partially filled metadata page when cache is locked.
    * During lock state, whole of metadata in the cache is unprotected.
    * As such, protecting only the last partially filled page is not of much use.
    */

   Uhhh.. ok? I don't remember enough about the function to make sense
   of this.

   The declaration in CompositeCache.cpp looks like this:

   SH_CompositeCacheImpl::protectPartiallyFilledPages(J9VMThread
   *currentThread, bool protectSegmentPage, bool protectMetadataPage,
   bool protectDebugDataPages, bool phaseCheck)

   which are true (protect the segment area), false (don't protect the
   metadata area), true (do a phase check). Okay.

   Then if doExitMutex is true, we call
   _ccHead->exitWriteMutex(..). And we're done.

'allocateROMClass'.. is due for a rewrite. And it's not that even that
big or difficult to understand a function! pieces is a pointer of type
J9SharedRomClassPieces* that will contain the addresses pointing to
the various components of the ROM class. So let's see how they're
allocated!!

sizes is in tandem with J9SharedRomClassPieces; its type is
J9RomClassRequirements*. It tells us how big the pieces must be. Then
some debug stuff I don't really need or care about at this
moment. Then down to line 1661.

pieces->romClass = (void *) allocateROMClassOnly(currentThread,
romclassSizeToUse, classnameLength, classnameData, cpw,
partitionInCache, modContextInCache, callerHelperID,
modifiedNoContext, newItemInCache, cacheAreaForAllocate);

Yeahh, so we do that. What of the rest of the pieces? I don't
know. It's also passed to 'allocateClassDebugData', and some flags are
toggled, indicating whether we've used the full size, and whether
class debug data was allocated. We call 'rollbackClassDebugData' if
pieces->romClass == NULL && debug memory was allocated.

Anyway, if pieces->romClass == NULL, retval = false, otherwise it's
true. Return retval.

'allocateROMClassOnly' needs the segment mutex, string table lock, and
write area lock. This call is to allocate from the cache if either cpw
== NULL (the classpath wrapper) or, modifiedNoContex == true, meaning
it will contain modified bytecode.

result = allocateFromCache(currentThread, sizeToAlloc,
sizeof(OrphanWrapper), TYPE_ORPHAN, newItemInCache,
cacheAreaForAllocate);

If neither of those things is true, get summon the classpath manager
using the usual means, and bind it to localCPM. Now, we need to check
if we're storing using what they call a Token. I have no clue what a
Token is. Here's the connected comment:

/* If we are storing using a Token and there is already a class of the
same name stored under that token, mark the original one stale */

Then we call 'tokenStoreStaleCheckAndMark'. More on that later of
course. We check to see if the classpath wrapper is stale, using
localCPM->isStale(..). If so, we goto _exit. Otherwise, if !useScope,
we set wrapperSize and wrapperType locals accordingly, and the same if
useScope is true.

Then we call allocateFromCache again:

result = allocateFromCache(currentThread, sizeToAlloc, wrapperSize,
wrapperType, newItemInCache, cacheAreaForAllocate);

It's identical to the previous allocateFromCache call, except it's
not.. we use wrapperSize and wrapperType in place of
sizeof(OrphanWrapper) and TYPE_ORPHAN respectively. So, if we have no
classpath or are dealing in a modifiable context, the ROMClass is an
orphan, apparently!! It is without an origin.

Then we return result. Which is exactly what the _exit label wraps,
along with a few trace messages.

'tokenStoreStaleCheckAndMark' is the one we are now curious
about. Here's the comment preamble behind it:

/**
 * If a new ROMClass is being stored with a token, then older ROMClasses
 * with the same name stored against the same token should be marked stale.
 *
 * @param [in] currentThread the thread calling this function
 * @param [in] classnameLength length of the rom class name we are storing
 * @param [in] classnameData the class name data
 * @param [in] cpw classpath info for this class
 * @param [in] partitionInCache partition info for this class
 * @param [in] modContextInCache mod context info for this class
 * @param [in] callerHelperID id of the classloader
 *
 * @return void
 *
 * THREADING: Called during a write transaction
 */

I guuuesss.. a token can be attached to a classpath wrapper. It's
read like this:

((ClasspathItem*) CPWDATA(cpw))->getType() == CP_TYPE_TOKEN

If so, we do this:

LocateROMClassResult existingTokenResult;
UDATA tokenRC = 0;

tokenRC = _rcm->locateROMClass(currentThread, classnameData,
classnameLength, ((ClasspathItem*) CPWDATA(cpw)), 0, -1,
callerHelperID, NULL, partitionInCache, modContextInCache,
&existingTokenResult);

if (tokenRC & LOCATE_ROMCLASS_RETURN_FOUND) {
  markItemStale(currentThread, existingTokenResult.knownItem, false);
}

If we find the ROMClass in the RCM, we mark the item stale. A token
can only correspond to one given ROMClass. So if an older ROMClass
with the same name as classnameData exists already, we mark
it.. staaaale!!! You see. Otherwise nothing happens.

'allocateFromCache' is here! A vile force of darkness has arrived.
Again, we need the Segment Mutex, String Table Lock, and Write Area
Lock. We do the ShcItem item, itemPtr convention again. If
RUNTIME_FLAGS_PREVENT_BLOCK_DATA_UPDATE is set in _runtimeFlags, we
jump to the end. Otherwise, we call 'getCacheAreaForDataType', which
is meaningless now that cachelets are dead and gone. We go jump to the
done label again if the pointer it returned, localCacheAreaForAllocate
is NULL. Otherwise, we call _ccHead->initBlockData(..) on the itemPtr,
and then there's this line:

itemInCache = (ShcItem*) localCacheAreaForAllocate->allocateWithSegment(currentThread,
					 itemPtr, sizeToAllocPadded,
					 &romClassBuffer);

If itemInCache is NULL.. you guessed it.. we jump to done. Otherwise,
set result = romClassBuffer. Which was returned from
allocateWithSegment, by the way.

The name 'allocateFromCache' isn't very descriptive but the preamble
states explicitly it's meant to allocate "Orphan ROMClass memory from
the cache." So this makes total, abject, unvariegated sense.

The epilogue of the function following the done label:

done:
  if (result == NULL) {
	newItemInCache = NULL;
	cacheAreaForAllocate = NULL;
  } else {
	newItemInCache = (void*) itemInCache;
	cacheAreaForAllocate = (void*) localCacheAreaForAllocate;
  }
  Trc_SHR_CM_allocateFromCache_Retval_Event(currentThread, result);
  Trc_SHR_CM_allocateFromCache_Exit(currentThread);
  return result;
}

It's weird how the result not being NULL is used as an indicator of a
successful write. Sure is odd! The reasons for that aren't clear.

'allocateClassDebugData' calls _ccHead->allocateClassDebugData(..) and
returns the result.

'rollbackClassDebugData' does the same, but with
_ccHead->rollbackClassDebugData.

'commitClassDebugData' is this:

void
SH_CacheMap::commitClassDebugData(J9VMThread* currentThread, U_16 classnameLength, const char* classnameData)
{
	this->_ccHead->commitClassDebugData(currentThread, classnameLength, classnameData);
}

Blah! boring.

void
SH_CacheMap::commitClassDebugData(J9VMThread* currentThread, U_16 classnameLength, const char* classnameData)
{
	this->_ccHead->commitClassDebugData(currentThread, classnameLength, classnameData);
}

'updateLineNumberContentInfo' is just more debugging related crap. It
enables the storage of line number content to the cache.

'commitROMClass' commits the ROM class! It expects:

THREADING: We assume the Segment Mutex, String Table Lock, and Write
Area Lock is held by the transaction.

That's in the comment preamble of course. We start with the parameter
commitOutOfLineData. It's a bool! If it's true, 'commitClassDebugData'
is called.

If we are using scoped ROMClass wrappers (ie. if partition and
modContext is true), we determine the wrapper size accordingly. Here's
a writeup about modification contexts and how they cause the cache to
be partitioned.

`Used when a JVMTI agent is installed that might modify bytecode at
run time. If you do not specify this suboption and a bytecode
modification agent is installed, classes are safely shared with an
extra performance cost. The <modified context> is a descriptor
that is chosen by the user; for example, myModification1. This
option partitions the cache so that only VMs that are using
context myModification1 can share the same classes. So if, for
example, you run an application with a modification context and
then run it again with a different modification context, all
classes are stored twice in the cache.`

Even if useScope is false,

srcw.cpeIndex = cpeIndex;
srcw.timestamp = 0;
if (cpeiInCache->protocol == PROTO_DIR) {
	srcw.timestamp = _tsm->checkROMClassTimeStamp(currentThread, (const char*) J9UTF8_DATA(romClassName), (UDATA) J9UTF8_LENGTH(romClassName), cpeiInCache, ((ROMClassWrapper*) &srcw));
}

We check the ROMClass timestamp.. for whaaaat? The preamble is this:

/*
 * Checks the timestamp of an individual ROMClass.
 * This function is only used for ROMClasses loaded from filesystem directories.
 *
 * If the timestamp of the ROMClass has changed, a new timestamp is returned
 * and it is the responsibility of the caller to take appropriate action (mark stale).
 * If the romclass doesn't exist, -1 is always returned.
 * Otherwise, if there is no change, 0 is returned.
 *
 * Parameters:
 *   className		Fully-qualified name of class to timestamp check
 *   cpei			Classpath entry that the class was found in
 *   rcWrapper		The ROMClass wrapper of the ROMClass to check
 * 					(Contains the current timestamp)
 */

Soo.. I assume if the timestamp has changed between the addition of
the ROMClass to the cache and the time we want to commit it to the
cache? I don't see how that's possible. I think it's more.. if the ROM
class was in the cache from a previous run, and we're committing a new
one (indicated by the difference in timestamp) then the previous
commited ROM class needs to be marked stale by the caller. This is the
interpretation I'm following.

Then we compute this crap:

srcwInCache = (ScopedROMClassWrapper*) ITEMDATA(itemInCache); /* must be after name is written */
srcw.theCpOffset = (J9SRP)((BlockPtr) cpw - (BlockPtr) srcwInCache);
/*Calc the J9SRP*/
srcw.romClassOffset = (J9SRP)((BlockPtr) romClassBuffer - (BlockPtr) srcwInCache);

if (useScope) {
   const J9UTF8* mcToUse = modContextInCache;
   const J9UTF8* ptToUse = partitionInCache;

   srcw.modContextOffset = (J9SRP)((modContextInCache) ? ((BlockPtr) mcToUse - (BlockPtr) srcwInCache) : 0);
   srcw.partitionOffset = (J9SRP)((partitionInCache) ? ((BlockPtr) ptToUse - (BlockPtr) srcwInCache) : 0);
}
memcpy(srcwInCache, &srcw, wrapperSize);

So we compute some modContext and partition offset stuff, and copper
srcw into the cache location for it.

Next, if we are using the write hash, we compute a hash from the class
name, and store it to classNameHash. We see if the hash matches the
_writeHashContendedResetHash. If the reduce store contention option is
enabled, I mean, on top of useWriteHash being true. It does this:

/* When storage contention is enabled, and the max wait is zero, restore the saved max time
 * if the hash was contended.
 */
_writeHashMaxWaitMicros = _writeHashSavedMaxWaitMicros;

Then we exit that conditional and call _rcm->storeNew(..), and record
the return value as storeResult. storeResult is a bool which toggles
retval as 0 or 1 accordingly.

Then we call cacheAreaForAllocate->commitUpdate(..), and then
'updateROMSegmentList'. Now that is is done, we try to reset the write
hash.

/* Try to reset the writeHash field in the cache. We have loaded a class from disk have now stored it.
 CMVC 93940 z/OS PERFORMANCE: Only reset the writeHash field on non-orphan store */
if ((true == useWriteHash) && (cpw != NULL) && (*_runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_REDUCE_STORE_CONTENTION)) {
	if (classNameHash == 0) {
		classNameHash = currentThread->javaVM->internalVMFunctions->computeHashForUTF8(J9UTF8_DATA(romClassName), J9UTF8_LENGTH(romClassName));
	}
	_ccHead->tryResetWriteHash(currentThread, classNameHash); /* don't care about the return value */
}

cpw != NULL is what proves the class was loaded from disk, I
think. Then we return retval.

'commitOrphanROMClass' is pretty similar to the 'commitROMClass'
member function. It's an orphan, and there has no modification context
or partition info, and no classpath wrapper.

'commitMetaDataROMClassIfRequired' creates and commits brand new
metadata to commit to the cache. Despite what the comment preamble
says, there is a romclass parameter, which is of type J9ROMClass*.

Some 'typical things' happen as committing ROM classes go up to this
point.. then we call _rcm->locateROMClass, to see if metadata for this
class was added by some other JVM, since adding the metadata is
potentially our responsibility within this function. Then mark the
class stale if we need to.. if it exists under the same Token or
whatever the hell.

/* If we are storing using a Token and there is already a class of the same name stored under that token, mark the original one stale
 * Note also that the locateROMClass call above will not necessarily find what we want. If another class is being added under the same token,
 * and the orphan has already been added, the above call will return the exact orphan match which is useful, but not what we need to do the stale mark
 */
this->tokenStoreStaleCheckAndMark(currentThread,
J9UTF8_LENGTH(romClassName), (const char*)J9UTF8_DATA(romClassName), cpw, partitionInCache, modContextInCache, helperID);

And then this, confusingly:

/* If locateROMClass found a stale ClasspathEntryItem */
if (rc & LOCATE_ROMCLASS_RETURN_DO_MARK_CPEI_STALE) {
	markStale(currentThread, locateResult.staleCPEI, true);
}

In general if the ROMClass was found, we launch into a large body of
code. The comments explain, "we only get here if another VM has stored
the same item underneath us." What do we do then?!? If
REDUCE_STORE_CONTENTION and useWriteHash is true, we try to reset the
writeHash field in the cache. There's some manipulation of write wait
times going on as well.. if the class wasn't found in the cache, the
policy is to bump the wait time down, to 0, potentially, as there's
nothing to wait on!

Otherwise, if the class was not found, we get the ClasspathManager,
and check if the classpath wrapper is stale. If so we jump to the done
label. Otherwise we return to the toplevel of indentation (still in
the function, of course). Similarly, there is this check:

/* If result is set, this means that we should not store, as we already have the result */
if (locateJ9ROMClass != NULL) {
   /*Our class and meta data was already added so we can exit*/;
   updateBytesRead(locateJ9ROMClass->romSize);

   Trc_SHR_CM_commitMetaDataROMClassIfRequired_Existing_Event(currentThread,
(UDATA)J9UTF8_LENGTH(romClassName), J9UTF8_DATA(romClassName),
(UDATA)romclass);

   goto done;
}

By this point, the comments note, we are using an existing class, but
the 'metadata does not match what we need', whatever that means. We
need to create new metadata, then. This is self-explanatory at least:

/* If the cache is marked full, we cannot add any new metadata as the last page would have been mprotected */
if (*_runtimeFlags & RUNTIME_FLAGS_PREVENT_BLOCK_DATA_UPDATE) {
   /* Don't update the cache */
   increaseUnstoredBytes(wrapperSize);
   Trc_SHR_CM_commitMetaDataROMClassIfRequired_Flags_Event(currentThread);
   retval = -1;
   goto done;
}

This next part might force the allocation of a supercache, if not for
the fact that cachelets have been removed.

/*Ensure enough supercache space*/
bytesToReserve = sizeof(ShcItem) + sizeof(ShcItemHdr) + wrapperSize + 16;

/* This forces allocation of a supercache, if necessary.
 * THIS IS HACKISH. Currently, all cachelets are shared between all managers,
 * so data type is irrelevant when attempting to reserve space.
 */
cacheAreaForAllocate = getCacheAreaForDataType(currentThread, wrapperType, bytesToReserve);

if (cacheAreaForAllocate == NULL) {
	/* This may indicate size required is bigger than the cachelet size.
	 * In this case we simply indicate that we are storing nothing, and return 0.
	 */
	Trc_SHR_CM_commitMetaDataROMClassIfRequired_Area_Event(currentThread, (UDATA)wrapperType, (UDATA)bytesToReserve);
	retval = 0;
	goto done;
}

Then we actually allocate space for the metadata:

/*Allocate the meta data*/
_ccHead->initBlockData(&itemPtr, wrapperSize, wrapperType);
itemInCache = (ShcItem*) cacheAreaForAllocate->allocateBlock(currentThread, itemPtr, SHC_WORDALIGN, wrapperSize);

if (itemInCache == NULL) {
      /* Not enough space in cache to accomodate this item. */
      Trc_SHR_CM_commitMetaDataROMClassIfRequired_Full_Event(currentThread, (UDATA)J9UTF8_LENGTH(romClassName), J9UTF8_DATA(romClassName), (UDATA)romclass);
      retval = -1;
      goto done;
}

Then call 'commitROMClass' with the newly allocated metadata! Which
does the task of specifying the item for us. If the data is created
and written to the cache in this way, we skip over the usual write
hash business hiding behind the 'done' label, which recomputes and
resets the write hash from the classNameHash.

Then we return the retval, and are finished.

'findNextRomClass' calls _rcm->findNextExisting(..).. which finds the
next ROM class over from findNextIterator. I'm not sure why firstFound
matters.. perhaps so we don't wrap around? Yes, looking at the source,
that's exactly what happens. OK.

'getStringTableBytes'.. get a simple getter that calls out to the
_ccHead method of the same name.

'getStringTableBase', same thing, swap names.

'findROMClass' starts by calling 'enterReadMutex' on the _ccHead. Once
it gets it, it calls 'runEntryPointChecks', which refreshes the
manager hashtables and toggles page protections and so on. Once that
succeeds, we call localRCM->locateROMClass(..). The first thing to do
is check if REDUCE_STORE_CONTENTION is enabled. If so, and rc has
LOCATE_ROMCLASS_RETURN_DO_TRY_WAIT, we check to see if another JVM is
trying to load the same class.. at this exact moment.

As always, we compute the hash, and call
_ccHead->testAndSetWriteHash(..). If result == 1, what do we do??  We
compute the locals startTime and endTime, according to
_writeHashMaxWaitMicros and _writeHashAverageTimeMacros. It tries to
change that according to its current value.

Then we enter a do/while loop. If the maximum wait time for write hash
is not 0, we loop for as long as there are no updates, as long as the
maximum wait time will allow us. Once we surpass the limit, we break
out of the loop.

Once we break out, if there is an update waiting (a new update is
alerted to us via _ccHead->checkUpdates(..)), we call
_ccHead->enterReadMutex(..). Then we call 'refreshHashtables'. If that
succeeds, call locaRCM->locateROMClass(..) again. If the returned item
is marked stale, we call _ccHead->exitReadMutex(..). If the result of
checkUpdates is still LOCATE_ROMCLASS_RETURN_DO_TRY_WAIT, and the
actualTimeMicros (the time we've waited) is not greater than the max
wait time (_writeHashMaxWaitMicros), set retry = TRUE and go to the
top of the do/while. updates is set to FALSE in this case, because we
haven't detected any yet.

Otherwise! If the rc is not LOCATE_ROMCLASS_RETURN_DO_TRY_WAIT.. and
cntr > 0, meaning we have waited at least once.. we call
'updateAverageWriteHashTime' with actualTimeMicros as an argument, so
that the average write hash time is updated, obviously.

Finally, at the foot of the do/while, if !updates is true, so that
there were no updates detected, and _writeHashMaxWaitMicros != 0, set
_writeHashContendedResetHash = hash, the hash of the className. We
have reached this point because there were no updates for this class,
even though we waited the maximum time. We set _writeHashMaxWaitMicros
= 0, and already, to have reached this point, we must have retry =
FALSE.

Back to the top of the conditional that led us into the do/while, if
writeHash == false, we call 'enterRefreshMutex'. If it succeeds, we
call _ccHead->peekForWriteHash(..), writing the result to
useWriteHash.

Then there's this, as we've seen:

/* If ClasspathEntryItem is stale, become a writer, lock the cache and do stale mark */
if (rc & LOCATE_ROMCLASS_RETURN_DO_MARK_CPEI_STALE) {
	markStale(currentThread, locateResult.staleCPEI, false);
}

If rc & LOCATE_ROMCLASS_RETURN_FOUND, we try to reset the write hash
to hash again. Why?? This comment explains:

/* It is quite possible for another JVM to set the writeHash field, load a class and set it back to zero
 * while we are pootling around in locateROMClass above. If so, we will incorrectly set the writeHash field,
 * unaware that the class has already been loaded. This clause ensures that the writeHash field will
 * *definitely* be reset in all circumstances */

There you go.

A note about foundAtIndex:

foundAtIndex Set to the index in the classpath from which the class
would have been loaded from disk

So.. if we found the ROM class in the cache, but want to know the
index the class would have in the classpath *if* the class was loaded
from disk? Sounds about right. Anyway, if we've found the ROMclass in
the cache, and foundAtIndex is not NULL, we record
locateResult.foundAtIndex in it. Then we set returnVal to the
ROMClassWrapper of the ROMClass. The rest is mostly trace messages and
the usual 'updateAccessedShrCacheMetadataBounds' call made if we're on
Linux, and not on certain processor architectures.

Lastly, if returnVal is not NULL, we call 'updateBytesRead' with
returnVal->romSize as the argument.

'addROMClassResourceToCache' must be protected by the write mutex
(!). First we switch on resourceType, a local variable we get from the
resourceDescriptor, an argument. If it's a compiled method or attached
data, and the runtime flags specify we don't have permission to update
those types, we immediately return NULL. Otherwise, press forward.

We call _ccHead->initBlockData(..). Of course. Then
'getCacheAreaForDataType', which is so very obsolete. Skipping that
check, we come to line 2711. We check to see that the romAddress (an
argument to 'addROMClassResourceToCache', specifying the location of
the ROMClass *within* the cache) is indeed within the address range of
the cache. If not, emit a trace message and return
J9SHR_RESOURCE_STORE_ERROR.

Continuing on. We switch on resourceType once more. If it's a
COMPILED_METHOD we're storing, call
cacheAreaForAllocate->allocateAOT(..)..

If it's attached data, call
cacheAreaForAllocate->allocateAOT(..)..

For all other cases, call cacheAreaForAllocate->allocateBlock(..).

In all three events, the return value is bound to itemInCache.

If itemInCache == NULL, return J9SHR_RESOURCE_STORE_FULL !

If not, continue on. Call
resourceDescriptor->writeDataToCache(..). It's the resource descriptor
that determines how the raw ROM class *resource* (*not* a ROM class!)
is actually written to the cache.. this function just determines the
proper allocation mode before deferring to the resourceDescriptor,
which determines how the data is actually to be written.

We call localRRM->storeNew(..) to do the work of storing the item in a
Manager. If that succeeds, resultWrapper becomes
ITEMDATA(itemInCache).

Then we call cacheAreaForAllocate->commitUpdate, of course, and then
we return the resultWrapper. We're done.

'storeROMClassResourceToCache' is protected by the cache write mutex!
It takes these boi's as arguments:

J9VMThread* currentThread,
const void* romAddress,
SH_ROMClassResourceManager* localRRM,
SH_ROMClassResourceManager::SH_ResourceDescriptor* resourceDescriptor,
const char** p_subcstr

The address of the ROM class to which the resource belongs. The
resource is described by the.. wait for it.. resourceDescriptor.

As usual, we check _runtimeFlags to see that we're not contravening
any user settings by storing this thing, and if not, it's off to the
races.

Then we call ccHead->initBlockData(..). This is all looking terribly
familiar thus far!

We get the cacheAreaForAllocate from 'getCacheAreaForDataType',
obvy. If that doesn't work, we return J9SHR_RESOURCE_STORE_ERROR, of
course. Then we check to see that the romAddress is within the cache's
address range. Then we dispatch once more on the resourceType:


	switch (resourceType) {
	case TYPE_COMPILED_METHOD :
		itemInCache = (ShcItem*)(cacheAreaForAllocate->allocateAOT(currentThread, itemPtr, dataLength));
		break;
	case TYPE_ATTACHED_DATA :
		if ((J9SHR_ATTACHED_DATA_TYPE_JITPROFILE == resourceSubType) ||
			(J9SHR_ATTACHED_DATA_TYPE_JITHINT == resourceSubType)
		){
			itemInCache = (ShcItem*)(cacheAreaForAllocate->allocateJIT(currentThread, itemPtr, dataLength));
		}
		break;
	default :
		itemInCache = (ShcItem*)(cacheAreaForAllocate->allocateBlock(currentThread, itemPtr, align, wrapperLength));
		break;
	}

I don't even care about indentation anymore. This produces an
itemInCache as you can see! The resourceDescriptor knows how to write
to it via resourceDescriptor->writeDataToCache(..). And then we write
it the localRRM->storeNew(..), and call
cacheAreaForAllocate->commitUpdate(..). And we are done! Return the
resultWrapper.

'storeROMClassResource' is now the thing we are on. Apparently
localRRM, the argument is a ROMClassResourceManager, and we need to
call its permitAccessToResource member function on the
currentThread.. which returns a bool called _accessPermitted.  Then we
try to claim the composite cache's write mutex, through
_ccHead->enterWriteMutex(..). And that's that, I'm afraid.

Then we call 'runEntryPointChecks', followed by
resourceDescriptor->generateKey(romAddress). Then
localRRM->findResource(..).. if it doesn't return a resource wrapper,
then it's not already in the cache! If it does return a resource
wrapper, well.. we exit the write mutex, and return with a message
indicating whether the store is invalidated or not (if the item type
is TYPE_INVALIDATED_COMPILED_METHOD, for instance), or we return
J9SHR_RESOURCE_STORE_EXISTS.

Otherwise, no such resource exists. We call
'addROMClassResourceToCache', as planned. We check to see that the
store is not full, and that there was not an error. If
_ccHead->isNewCache() is true, that's another condition that piles
onto the previous ones. If so! .. and the persistent cache is
enabled.. we call 'updateAccessedShrCacheMetadataBounds'. Then we call
_ccHead->exitWriteMutex(..), and boom. We are finished.

'updateROMClassResource' does much the same thing:

1) _ccHead->enterWriteMutex(..) is called.
2) 'runEntryPointChecks' is called.
3) resourceDescriptor->generateKey(..) is called.
4) localRRM->findResource(key) is called.
4i) If the resource is found, check for errors in store
representation! Like byte lengths not matching up. Otherwise, call
resourceDescriptor->updateDataInCache and the like (sometimes
resourceDescriptor->updateUDATAInCache(..)).
4ii) If the resouces is not found, result becomes
J9SHR_RESOURCE_STORE_ERROR.

In any event we call _ccHead->exitWriteMutex(..), and are done.  We
return the result.

'findROMClassResource' also does super boring, typical things, such
as:

1) localRMM->permitAccessToResource(..) is called. If false, we're
gone. Return NULL.

2) if useReadMutex the bool parameter is true, call
_ccHead->enterReadMutex(..). If that fails, return NULL.

3) 'runEntryPointChecks' is called. If failed return NULL. Blah.

4) generateKey and findResource are called on localRRM. If the
resource isn't found, check to see if we've found an invalidated AOT
method. Toggle the flags parameter accordingly.

5) Release the read mutex and call 'updateBytesRead'.

6) Return the result.

'storeCompiledMethod' is mercifully just a wrapper around
'storeROMClassResource', which creates a
CompiledMethodResourceDescriptor object around the data and code
passed to 'storeCompiledMethod'. It passes that shit along, you see.

Here are.. some rad comments.

/*
 * This method adds the fixed data associated with a compiled method to the cache.
 * The data defined by dataStart and dataSize and the data defined by codeStart and
 * and codeSize are copied to the cache as a single contiguous block. The stored
 * data is indexed by the romMethod's address. The return value is a pointer to the
 * stored data or null in case of an error.
 */

'findCompiledMethod' finds the fixed data associated with the method!
A J9ROMMethod* to be exact. As before, we initialized a
CompiledMethodResourceDescriptor and get the CompiledMethodManager
from the CacheMap. We use 'findROMClassResource' to get the thing!
Oddly we don't feel the need to load the descriptor with any
information whatsoever -- it's the J9ROMMethod* that's passed.

If the result != NULL, we call
vmFunctions->findROMClassFromPC(..). This a function internal to the
VM, from currentThread->javaVM->internalVMFunctions. You know, to find
the containing ROMClass from the program counter, I think, which the
J9ROMMethod* effectively is. If we find it, we get the class name,
method name, and method signature.. and use them to emit a trace
message, nothing more, to indicate a successful metadata access.
This is if the persistent cache is enabled. Seems to be purely for
debugging purposes. We don't actually do anything further with the
ROMClass that was retrieved.

Turning back to the internals of 'getROMClassResource', though, we see
that the romMethod pointer is interpreted as a key by the
resourceDescriptor, which is then passed to the
ROMClassResourceManager. It knows how to handle all that.

Finally, we return the result.

'updateAccessedShrCacheMetadataBounds'.. hoo man. Here's the comment
preamble:

/**
 * Record the minimum and maximum addresses accessed in the shared classes cache.
 * @param [in] metadataAddress address accessed in metadata
 * @note an argument of 0 will reset the minimum and maximum
 */

This entire thing hinges on manipulating

uintptr_t * updateAddress = (uintptr_t *)&_minimumAccessedShrCacheMetadata;

as an atomic value. It reads the current value (just
_minimumAccessedShrCacheMetadata)

and sets newValue (a local) to equal the passed in value,
metdataAddress (as a uintptr_t).

If the currentValue is 0, as the preamble says, do:

compareAndSwapUDATA(updateAddress,
		    currentValue,
		    newValue);

Then currentValue is read in again. We enter a while loop when we
check that newValue < currentValue as the loop condition. Clearly, it
should be greater!! This is because currentValue is updated in the
loop body, from _minimumAccessedShrCacheMetadata. Before that, we try
to update _minimumAccessedShrCacheMetadata through another call to

compareAndSwapUDATA(updateAddress,
		    currentValue,
		    newValue);

We break once it finally succeeds. Then we do the same with
_maximumAccessedShrCacheMetadata. Same thing, right down to
updateAddress and currentValue, except this time, there is no check
that 0 == currentValue.

'storeAttachedData' takes a parameter called addressInCache,
indicating that this data is attached to a method or class already in
the cache. To attach it, we must know where that data resides in the
cache. Other parameters: the data to store (a J9SharedDataDescriptor*,
obviously); forceReplace, a bool that *forces* attached data to
replace itself in the cache, regardless of whether it already exists
there, marking the old data stale; aaaand, that's it. One of the more
well-documented functions inside CacheMap.

Here are the steps:

1) get AttachedDataManager
2) if we've enabled VERBOSE_JITDATA in the runtime flags:
2i) call 'updateROMClassResource' with the
addressInCache. updateAtOffset is a function argument.. the area
within the addressAtCache we are updating. The descriptor is populated
with the data length, address and type.

Next, if the address is in the cache, call
vmFunctions->findROMClassFromPC(..) again, and extract method names
and data for debugging purposes only! This is the verbosity part.
2ii) Otherwise, just call 'updateROMClassResource' as previously
described without the massive amount of ceremony.

Return the result. Fin.

'updateAttachedUDATA' is a mirror copy of 'updateAttachedData', except
the data argument is replaced by a UDATA parameter called value. We
construct our own local J9SharedDataDescriptor called data, which
value is used to populate (using its address, size, and the type
argument).

Then the action again boils down to using 'updateROMClassResource'
again, with or without the verbosity cruft.

And, return the result.

'findAttachedDataAPI' has this purpose-explaining preamble written in
it:

/**
* Find the data for the given shared cache address. If *corruptOffset is not -1,
* a vm exit occurred while a call to j9shr_updateAttachedData() was in progress.
* In such case, data->address is still filled with the corrupt data.
* Corrupt data can be overwritten by a subsequent update.
* If data->address was NULL on entry, then on return caller must free
* a non-NULL data->address.

This.. is somewhat confusing. The documentation on this thing sucks,
of course, in general but especially for this function. I take it to
mean that the corruptOffset records the offset of where data starts to
be corrupted within the addressInCache, yes? At least the
documentation is somewhat helpful in that corruptOffset is marked as a
return value (an "out" parameter).

And the function body is.. drum roll.. a big convoluted mess anchored
by ENABLE_VERBOSE_JITDATA being set in _runtimeFlags, again. The core
of the action is 'findAttachedData', which takes as parameters
currentThread, addressInCache, data, corruptOffset, and a char** for a
debug message.

On to 'findAttachedData' then! Hopefully for some answers. It's much,
much longer.

First, we have

*corruptOffset = -1;

to mean that no such offset exists, yet. NULL has its own
interpretation apart from that of -1. We call 'getAttachedDataManager'
again, and then 'enterReadMutex'. If either fail, return NULL. Nothing
new so far.

Then we populate an AttachedDataResourceDescriptor with data->type,
with the length and address fields being 0 and NULL respectively. We
pass the descriptor to 'findROMClassResource'. So far, corruptOffset
is untouched. If the result of the call to 'findROMClassResource' is
!= NULL, we get an AttachedDataWrapper out of the result. If
data->address != NULL, we do this:

if (data->length < dataLength) {
				result = (U_8 *)J9SHR_RESOURCE_STORE_ERROR;
				if (NULL != p_subcstr) {
					const char *tmpcstr = j9nls_lookup_message((J9NLS_INFO | J9NLS_DO_NOT_PRINT_MESSAGE_TAG), J9NLS_SHRC_CM_DATA_SIZE_LARGER, "data %d larger than available %d");
					j9str_printf(PORTLIB, (char *)*p_subcstr, VERBOSE_BUFFER_SIZE, tmpcstr, dataLength, data->length);
				}
				goto _exitWithError;
}

Clearly, this is error checking code that modifies result accordingly.

Otherwise, if data->address == NULL, we allocate a buffer at
data->address using j9mem_allocate_memory. If it's still NULL, do the
error dance again, jumping to _exit this time.

Moving on, we check to see if the _ccHead->isRunningReadOnly() is
true. If not, we copy the result to data->address, which is non-NULL
now in any event, sugar. We set the local variable corrupt to

corrupt = ADWCORRUPT(wrapper);

I don't know what this wrapper does. It's this macro:

#define ADWCORRUPT(adw) J9SHR_READMEM((adw)->corrupt)

If corruptOffset != NULL, do

*corruptOffset = corrupt;

Uhh, when was corruptOffset touched in the intervening code? Never, as
far as I can tell! It was dereferenced without so much as a nullity
check.

If on the other hand corrupt != -1, result = NULL and we goto _exit.

Otherwise, _ccHead is running read only. We read the update count of
the wrapper using ADWUPDATECOUNT on
wrapper. VM_AtomicSupport::readBarrier() is used to establish a read
barrier, to everyone's great shock. Then the data stuff is copied over
from result once more:

memcpy(data->address, result, dataLength);
data->length = dataLength;
result = data->address;

VM_AtomicSupport::readBarrier();

and notice how we follow without another readBarrier(). The
readBarrier() is toggled off. Did I mention we are now in a do loop??
It has to do with the managing the updateCountTryCount.. we get a
limited number of retries. Why might the loop go round in another
retry? Because the initialUpdateCount and the finalUpdateCount, before
and after data is read from result, might be different. These update
counts both come from ADWUPDATECOUNT, BTW. Once we've exceed our
allotted number of retries, we goto _exitWithError, after setting
result to NULL. The while condition is just true, BTW. It's an
unconditional infinity loop until we break out.

The rest of the function just looks like this:

_exitWithError:
	if (true == bufferAllocated) {
		j9mem_free_memory(data->address);
		data->address = NULL;
	}
_exit:
	_ccHead->exitReadMutex(currentThread, fnName);
	Trc_SHR_CM_findAttachedData_Exit3(currentThread, result);
return result;

And that is that confusing function! We really gained no insight at
all on the function of corruptOffset. Perhaps later it will become
clearer??

'addByteDataToCache' does what it claims to do, boy howdy! I'm now
sure how byte data differs from Attached data. I suppose we'll find
out. These are its parameters:

J9VMThread* currentThread, SH_Manager* localBDM, const J9UTF8* tokenKeyInCache,
const J9SharedDataDescriptor* data, SH_CompositeCacheImpl* forceCache,
bool writeWithoutMetadata

We have a manager localBDM, a tokenKeyInCache, a
J9SharedDataDescriptor*, a CompositeCacheImpl for some reason, and a
boolean flag indicating whether we write with metadata.

First is that we expect to hold the write mutex. A given at this
point. The data has certain flags attached to it:

1) whether it is read/write
2) whether it is not indexed (whatever that might mean)
3) whether it is private

cacheForAllocate is either forceCache or _cc, based on whether
forceCache is NULL.

Then a few features of the wrapper are set up, namely its type and
length, represented by the locals wrapperType and wrapperLength. The
type pivots on dataNotIndexed: if true, the type is
TYPE_UNINDEXED_BYTE_DATA; if false, TYPE_BYTE_DATA. wrapperLength is 0
unless dataNotIndexed is false, in which case it's
sizeof(ByteDataWrapper).

Then this bit of mystifying code:

if (J9_ARE_ANY_BITS_SET(*_runtimeFlags, RUNTIME_FLAGS_PREVENT_BLOCK_DATA_UPDATE)) {
        if (J9_ARE_ALL_BITS_SET(data->flags, J9SHRDATA_USE_READWRITE)) {
	   increaseUnstoredBytes(wrapperLength);
        } else {
           increaseUnstoredBytes(wrapperLength + (U_32)data->length);
        }
        Trc_SHR_CM_addByteDataToCache_Exit1(currentThread);
	return NULL;
}

If we're interested in preventing *updates* to block data, and the
data to be read/written, then we'd better increment the number of
unstored bytes by the length of the wrapper, if we need to!

If use read/write isn't flagged in data->flags (<-> !dataReadWrite),
then check to ensure data->type != J9SHR_DATA_TYPE_CACHELET (it always
is true, cachelets are gone!). We call _ccHead->initBlockData(..), and
then

cacheForAllocate = getCacheAreaForDataType(currentThread, wrapperType,
_ccHead->getBytesRequiredForItemWithAlign(itemPtr, SHC_WORDALIGN,
sizeof(ByteDataWrapper)));

true to form. This is if !forceCache is true. In any event, we set
itemInCache using this:

if ((itemInCache = (ShcItem*)(cacheForAllocate->allocateBlock(currentThread, itemPtr, SHC_WORDALIGN, sizeof(ByteDataWrapper)))) == NULL) {
   /* Not enough space in cache to accomodate this item. */
   return NULL;
}

Else, if dataReadWrite is true, we do this (snipping the obsolete
parts):

_ccHead->initBlockData(&itemPtr, wrapperLength, wrapperType);
itemInCache = (ShcItem*)(cacheForAllocate->allocateWithReadWriteBlock(currentThread, itemPtr, (U_32)data->length, &externalBlock));
/* Expect readWrite to become full before the cache does - so don't
report it */

externalBlock is an internal BlockPtr that we are hoping to allocate,
see. It will be allocated in the read/write area of the cache,
following the documentation of allocateWithReadWriteBlock in
CompositeCache.cpp. That is what dataReadWrite actually indicates!

If the data is indexed (by a token key, it turns out) and the value of
_cc changes out from under us (somehow? preCC certainly can't!) then
we do this:

if ((preCC != _cc) && (tokenKeyInCache != NULL) && !dataNotIndexed) {
	/* Our token key is in a different supercache - we need to reallocate it */
	tokenKeyToUse = addScopeToCache(currentThread, tokenKeyInCache);
}

It needs to be re-indexed, clearly! Or reallocated or something.

If we are writing without metadata, and we got an externalBlock,
memToSet = externalBlock. That's the thing to write to. Otherwise,
memSet = (BlockPtr)itemInCache, the metadata item we allocated.

Otherwise, if data isn't indexed (dataNotIndexed is true), memToSet
becomes ITEMDATA(itemInCache). Else! If metadata is not being written
and data is indexed, we do all this:

if (itemInCache == NULL) {
	Trc_SHR_CM_addByteDataToCache_Exit_Null(currentThread);
	return NULL;
}

bdwInCache = (ByteDataWrapper*)ITEMDATA(itemInCache);
bdwInCache->dataLength = (U_32)data->length;
bdwInCache->tokenOffset = (J9SRP)((BlockPtr)tokenKeyToUse - (BlockPtr)bdwInCache);

if (externalBlock) {
	bdwInCache->externalBlockOffset = (J9SRP)((BlockPtr)externalBlock - (BlockPtr)bdwInCache);
} else {
	bdwInCache->externalBlockOffset = 0;
}

bdwInCache->dataType = (U_8)data->type;
/* Only set privateOwnerID if the data is private - when JVM shuts down, all of its privateOwnerIDs are set to 0 */
bdwInCache->privateOwnerID = (bdwInCache->inPrivateUse = (U_8)dataIsPrivate) ? _ccHead->getJVMID() : 0;
memToSet = (BlockPtr)BDWDATA(bdwInCache);

Then this crap:

if (memToSet == NULL) {
   Trc_SHR_CM_addByteDataToCache_Exit_Null(currentThread);
   return NULL;
}

if (data->flags & J9SHRDATA_ALLOCATE_ZEROD_MEMORY) {
   memset(memToSet, 0, data->length);
} else {
   memcpy(memToSet, data->address, data->length);
}

We set memToSet using data, which is the entire point of this
function, in case you've forgotten. Then all of this:

	/* storeNew is effectively a no-op for data marked as J9SHRDATA_NOT_INDEXED */
	if (localWriteWithoutMetadata) {
		result = memToSet;
	} else if (localBDM->storeNew(currentThread, itemInCache, cacheForAllocate)) {
		if (dataNotIndexed) {
			result = (BlockPtr)ITEMDATA(itemInCache);
		} else {
			result = (BlockPtr)BDWDATA((ByteDataWrapper*)ITEMDATA(itemInCache));
		}
	}
	cacheForAllocate->commitUpdate(currentThread, itemPtr->dataType == TYPE_CACHELET);

	if ((NULL != bdwInCache) && (J9SHR_DATA_TYPE_AOTHEADER == bdwInCache->dataType)) {
		this->_cc->setAOTHeaderPresent(currentThread);
	}

	Trc_SHR_Assert_True(_ccHead->hasWriteMutex(currentThread));
	Trc_SHR_CM_addByteDataToCache_Exit(currentThread, result);
	return result;

Writing metadata if we have to, and so forth.

Ok, 'storeSharedData' is a go now. Another monster of a function. This
fucker of a function is easy to understand but has some complex
behaviour, which might, y'know, account for its size:

/**
 * Stores data in the cache which against "key" which is a UTF8 string.
 * If data of a different dataType uses the same key, this is added without affecting the other data stored under that key.
 * If J9SHRDATA_SINGLE_STORE_FOR_KEY_TYPE is set, one store for that key/dataType combination is allowed. Subsequent stores will simply return the existing data.
 * If J9SHRDATA_SINGLE_STORE_FOR_KEY_TYPE is not set, the following is true:
 *   If data of the same dataType already exists for that key, the original data is marked "stale" and the new data is added.
 *   If the exact same data already exists in the cache under the same key and dataType, the data is not duplicated and the cached version is returned.
 *   If null is passed as the data argument, all existing data against that key is marked "stale".
 * The function returns null if the cache is full, otherwise it returns a pointer to the shared location of the data.
 *
 * data->flags can be any of the following:
 *   J9SHRDATA_IS_PRIVATE - the data is private to this JVM
 *   J9SHRDATA_ALLOCATE_ZEROD_MEMORY - allocate zero'd space in the cache to be written into later
 *      bear in mind that this should be either private memory which doesn't require locking, or read/write memory
 *   J9SHRDATA_USE_READWRITE - allocate into the cache read/write area
 *   J9SHRDATA_NOT_INDEXED - add the data, but don't index it (saves cache space)
 *      data must therefore be referenced by other data as it can never be retrieved by findSharedData
 *   J9SHRDATA_SINGLE_STORE_FOR_KEY_TYPE - only allow one store for a given key/type combination
 *      subsequent stores return the existing data regardless of whether it matches the input data
 *   J9SHRDATA_SINGLE_STORE_FOR_KEY_TYPE_OVERWRITE - Similar to J9SHRDATA_SINGLE_STORE_FOR_KEY_TYPE, only one record of key/dataType combination is allowed in the shared cache.
 *   	subsequent stores overwite the existing data. This flag is ignored if J9SHRDATA_NOT_INDEXED, J9SHRDATA_ALLOCATE_ZEROD_MEMORY or J9SHRDATA_USE_READWRITE presents
 */

The function takes a simple const char* key, a keylen, and a
J9SharedDataDescriptor*. Again, data might be indexed, or not. We once
again have a dataNotIndexed flag, which pivots around data != NULL and
data->flags & J9SHRDATA_NOT_INDEXED being true.

Then key can't be NULL or of zero length either, or we return NULL.

We call 'getByteDataManager' as you'd expect. If
J9SHRDATA_SINGLE_STORE_FOR_KEY_TYPE_OVERWRITE is enabled in
data->flags and the data is non NULL, then guess whaaat.. the local
boolean overwrite is set to true.

Then we call _ccHead->enterWriteMutex(..) and
'runEntryPointChecks'. If that succeeds, we keep the write mutex, and
on we go.

if !dataNotIndexed, hoo, watch out. We have a long road of exposition
ahead of us. If additionally data != NULL, we call
localBDM->findSingleEntry(..). This returns bdwInCache. If data->type
== J9SHR_DATA_TYPE_AOTHEADER, it's the header of an AOT datum?? And
AOT headers are present in the _cc, whatever that means?? If so, we
assert that bdwInCache != NULL.

Then, if indeed bdwInCache != NULL, we read the result from the
bdwInCache, as

result = (const U_8*)BDWDATA(bdwInCache);

if (data->address == NULL) {
   /* We're being asked to allocate memory that has already been allocated */
   if (data->flags & J9SHRDATA_ALLOCATE_ZEROD_MEMORY) {
      goto _done;
   }
}

which is as weird as it is interesting! The bulk of code is trapped in
the else clause of the shown if. For we're doing a single store for a
key of this type.. or an overwrite for a key of this type.. if
data->type == J9SHR_DATA_TYPE_STARTUP_HINTS, we call
'updateLocalHintsData'. Apparently these startup hints are folded away
in _sharedClassConfig.. there are asserts verifying that the address
of those hints match data->address. Seems rather specialized and
important!

If overwrite (the local bool) is true, we check that the data->length
== foundDatalen. If so, copy result to data->address. If that
fails, copy data->address to result instead.

Otherwise, if neither SINGLE_STORE_FOR_KEY_TYPE nor
SINGLE_STORE_FOR_TYPE_OVERWRITE is set, and data->length ==
foundDatalen, we copy result to data->address, and if we do so
successfully, we goto _done.

If we did not goto _done in this branch, we mark the found bdw item as
stale.

Otherwise! If data == NULL, we call localBDM->markAllStaleForKey(..).

Then we call 'getScopeManager'. If that fails, return NULL.

Now, if

(data != NULL) && (data->length > 0) && ((data->address != NULL) ||
(data->flags & J9SHRDATA_ALLOCATE_ZEROD_MEMORY))

we set the local (just declared) J9UTF8* tokenKey to NULL. If
!dataNotIndexed, we copy the key into J9UTF* struct. Then we try to
findScope for that UTF key struct:

if (!(tokenKey = localSCM->findScopeForUTF(currentThread, utfKeyStruct))) {
	if (!(tokenKey = addScopeToCache(currentThread, utfKeyStruct))) {
		Trc_SHR_CM_storeSharedData_CannotAddScope(currentThread);
		result = NULL;
		goto _done;
	}
}

We try to add the scope indicated by the computed key to the
cache. Then, Once the if(!dataNotIndexed) { ... } branch is exited, we
call

result = (const U_8*)addByteDataToCache(currentThread, localBDM,
tokenKey, data, NULL, false);

Followed by this:

_done:
	if (utfKeyPtr && (utfKeyPtr != (char*)&utfKey)) {
		j9mem_free_memory(utfKeyPtr);
	}

	_ccHead->exitWriteMutex(currentThread, fnName);

	Trc_SHR_CM_storeSharedData_Exit3(currentThread, result);
	return result;

Onto 'findSharedData'. Again, we have a key, a keylen, a limitDataType
(used only if what?? "If used, only data of the type constant
specified is returned. If 0, all data stored under that key is
returned"), includePrivateData( another UDATA, also mystifying), a
J9SharedDataDescriptor* called firstItem, and a J9Pool* called
descriptorPool.

We start by calling 'getByteDataManager'. Again. Then
_ccHead->enterReadMutex(..), then 'runEntryPointChecks'. The
parameters passed to 'findSharedData' are fed into
localBDM->find(..), even! So there meaning is not really expounded
upon here, and because we're nearing closing time, I am grateful.
The full bad boi looks like this:

result = localBDM->find(currentThread, key, keylen, limitDataType, includePrivateData, firstItem, descriptorPool);

Then we call _ccHead->exitReadMutex(..).

Where does the pool come in?!? Here:

if (result > 0) {
	if (descriptorPool != NULL) {
		pool_state state;
		J9SharedDataDescriptor* anElement;

		anElement = (J9SharedDataDescriptor*)pool_startDo((J9Pool*)descriptorPool, &state);
		while (anElement) {
			updateBytesRead(anElement->length);
			anElement = (J9SharedDataDescriptor*)pool_nextDo(&state);
		}
	} else if (firstItem != NULL) {
		updateBytesRead(firstItem->length);
	}
}

So, if the result > 0, and the descriptorPool isn't NULL, we iterate
through all elements of the pool, and call 'updateBytesRead' on each
element in it. Otherwise, if the pool is NULL, we call
'updateBytesRead' only on the firstItem retrieved by
localBDM->find(..). The descriptorPool is populated by all the results
found under that key, BTW, so of course we need to alert the cache of
their being read.

We should take a moment to examine the ByteDataManager and
ScopeManager classes.

Starting with ByteDataManager. In the abstract interface
SH_ByteDataManager, we see a distinction between public and private
members. Members are private in this sense if they are exclusive to a
single JVM. By 'releasing' private members, they become public, which
is to say, accessible to other JVMs. And then, of course, there's find
and findSingleEntry. find fills the descriptorPool with the entries it
finds.. findSingleEntry takes a jvmID in addition to key, keylen,
dataType, and dataLen.. the datum found must uniquely match the key,
dataType and jvmID.

SH_ByteDataManagerImpl implements virtual overrides of all
SH_ByteDataManager's pure virtual functions, but none of the Impl
classes' prototypes are pure.

Looking at storeNew, we see some first swirlings of indexed
bytes. That whole notion. We're really just adding the length of the
items to an array, _indexedBytesByType, which is indexed by the types
denoted by the constants J9SHR_DATA_TYPE_*.

releasePrivateEntry is called automatically on each private entry when
a JVM shuts down.. is publicizes its private data.

acquirePrivateEntry takes a public entry and makes it private,
according to the JVM's ID.

Ok, back to CacheMap. The next entry is
'acquirePrivateSharedData'. This tries to transfer private shared data
from another JVM to this one. 'getByteDataManager',
_ccHead->enterWriteMutex(..), and localBDM->acquirePrivateEntry(..)
are all there, operating on the lone argument, a
J9SharedDataDescriptor* called data. That's it. We exit the write
mutex when finished.

'releasePrivateSharedData' calls releasePrivateEntry on the localBDM,
and that's quite literally it. There's no need to claim the write
mutex because we don't care about race conditions involved in making
it private. The outcome is completely predictable with or without a
race condition.

'getJavacoreData' dumps many different cache stats to the struct
J9SharedClassJavacoreDataDescriptor. This (the function
'getJavacoreData') contains a useful index of byte data types. Many of
the descriptor fields describe the number of certain kinds of entries
and so on are initialized to 0 if the ByteDataManager hasn't been
started yet. But the rest is just stats gathering with the help of the
relevant managers. Nothing very relevatory or interesting.

'markStale' needs to have the write mutex, as it will check via
asserts. It will also lock the cache once it has the write mutex. The
key to the thing being marked stale is a ClasspathEntryItem* called
cpei. Also, the caller must have the classSegmentMutex belonging to
the VM. Seems a little extreme, but ok.

 We update the VM state to indicate that something in the shared class
 cache is being marked stale. It's a VM wide event. While retryCount <
 MARK_STALE_RETRY_TIMES (and it always is! retryCount is incremented
 nowhere), we call 'runEntryPointChecks', _cc->startCriticalUpdate(..)
 and _cc->findStart(..). Then we call
 localCPM->markClasspathsStale(currentThread, cpei). Notice cpei being
 passed in, there.

Once that's done, we watch the composite cache using
_cc->nextEntry(..). For each item that is a ROMClassWrapper, we get
the ROMClass path with the macro RCWCLASSPATH(rcw). That is cast to a
ClassPathWrapper*. The ClasspathWrapper is simply this:

typedef struct ClasspathWrapper {
	I_16 staleFromIndex;
	U_32 classpathItemSize;	/* ClasspathItem follows directly after */
} ClasspathWrapper;

staleFromIndex is what? "All classpaths after this index are stale",
perhaps? I have no clue how to interpret that. In this context, we
have the check:

if (((ClasspathWrapper*)RCWCLASSPATH(rcw))->staleFromIndex <= rcw->cpeIndex) {
	markItemStale(currentThread, it, true);
	++numMarked;
}

If the staleFromIndex is less than cpeIndex, ah! We mark it
stale. Here's commentary from ClasspathManagerImpl2.cpp :

 * The "staleFromIndex" of each ClasspathItem is set to the index of cpei in that classpath.
 * After this function is called, the caller should test all ROMClasses in the cache to see if they now
 * point to a stale classpath entry.

The classpath is implemented as an array, meaning every entry
in it has an index. 'markStale' is concerned precisely with testing
all ROMClasses in the cache, to see if they are 'stale from that
index.' That is, if they come after that index, they must be
stale. This was my first interpretation of the thing, and we were
correct it seems.. I still don't understand the logic of it. If the
individual ClassPathEntryItem* cpei is marked as stale.. then so is
everything after?? Why?

Ok, a ClasspathItem is an individual sequence of paths making up part
of the classpath, which can consist of many ClasspathEntryItem's. A
ClasspathEntryItem is an individual path, and a pathLen, and a
hashValue.. all that. A ClasspathWrapper is really just a header for a
ClasspathItem, as the comments say. Each cpei has an index in the
classpath as a 0-indexed sequence of ClasspathEntryItems, of course.

SH_ClasspathManagerImpl2::markClasspathsStale(..) takes a classpath
entry item, finds the classpath is belongs to, and walks the
ClasspathItems making up that classpath. Specifically, it walks their
wrappers (really, their headers.. it should have a more suitable
name). It returns the index of the ClassPathItem *within* the
classpath (a linked list, a CpLinkedList to be precise), and records
*that* to cpw->staleFromIndex (cpw is the ClasspathWrapper,
clearly). This is what it means to mark a classpath as stale,
apparently! If you look back to CacheMap::addClasspathToCache, the
classpath wrapper created there is set to CPW_NOT_STALE. It is defined
as:

#define CPW_NOT_STALE 0x7FFF

which is 16 bits, reserving the top bit for 0. Probably a stale
marker! But yeah, that's the greatest possible bound you can have, as
far as the lengths of classpaths are concerned. If staleFromIndex to
set to the cpeIndex, as it is in 'markClasspathsStale', that's a hint
to 'markStale' in CacheMap, where we check that the Classpaths of the
cache's ROMClasses have gone stale by comparing their wrapper's
staleFromIndex attributes to their ROMClass's cpeIndex. If the
classpath of the ROMClass is stale, guess what?? The ROMClass is stale!

Then we end the critical update, exit from the write mutex.. all
that. Restore the old VM state and return numMarked.

Ok, 'markItemStale'. So minimal as to be completely boring! It asserts
that the currentThread holds the write mutex. Then it calls
_ccHead->markStale(..). It is passed a ShcItem* item and a bool
isCacheLocked, and that's all.

'markItemStaleCheckMutex' tries to _ccHead->markStale(..) if the write
mutex is held. If not, it exits the read mutex,
_ccHead->enterWriteMutex(..), then does _ccHead->markStale(..), then
exits the write mutex. The only difference between this function and
the previous one is that there's some extra bureaucracy around
checking for the write mutex being held, and attempting to claim it if
it isn't. A bit safer than markItemStale, obviously.

'destroy' tries to destroy the entire cache! Just burn the entire
thing down, is the whole idea. It does _ccHead->enterWriteMutex(..),
'resetAllManagers', and then _ccHead->deleteCache(..), and that's it.

'reportCorruptCache' is next. It checks whether currentThread owns the
refresh mutex. If not, it tries to claim it. If it has the refresh
mutex, it calls _ccHead->getCorruptionContext(..), and sets the write
hash to 0 if REDUCE_STORE_CONTENTION is enabled. Then
_cacheCorruptReported = true, and the _runtimeFlags are toggled so
that we DENY_CACHE_ACCESS and DENY_CACHE_UPDATES, since, y'know, the
cache is corrupt. Then we do 'exitRefreshMutex'.

'resetCorruptState' toggles those same flags and settings off. It also
makes sure to have the refresh mutex before attempting anything. Then
'setCorruptionContext' is called to set the context to
NO_CORRUPTION. Bah! Then we are done.

'printAllCacheStats' is a beast I don't want to get into, ever. It is
only every single threaded, it tries to claim the write mutex, aaaand,
the rest appears to be logic to walk the cache,, using
cache->findStart(..) (cache is a SH_CompositeCacheImpl* argument to
the function, BTW). For each ShcItem* it claims in the walk, it
dispatches on its ITEMTYPE in a big switch statement.

Lots of uses of CACHEMAP_PRINT* here. Many, I would say! The clauses
keep repeating the same syntactic pattern.. only the macros and
constants being passed to the macros (which decide the text that they
print) change.

Oh, types of attached data, BTW: mainly they are 'attached' to
compiled methods. They are ATTACHED_DATA_TYPE_JITPROFILE (JIT
profiling info!) and ATTACHED_DATA_TYPE_JITHINT.

Then call _ccHead->exitWriteMutex(..). Fini!

'printCacheStats' prints the stats for *this* cache, rather than a
cache specified by argument parameter. If fact, it calls
'printAllCacheStats' for all cache chained to _cc, the 'head'
cache. Then it calls 'getJavacoreData' and begins to print information
from that. Java specific info! So there's some welcome segregation of
Java material from the cache there, that we don't see often enough.

Then there's some such about whether the cache is accessible and what
kind of access is allowed. Here's the switch statement controlling it:

switch (this->_cc->isCacheAccessible()) {
case J9SH_CACHE_ACCESS_ALLOWED:
	accessString = "true";
	break;
case J9SH_CACHE_ACCESS_ALLOWED_WITH_GROUPACCESS:
	accessString = "only with 'groupAccess' option";
	break;
case J9SH_CACHE_ACCESS_ALLOWED_WITH_GROUPACCESS_READONLY:
	accessString = "only with 'groupAccess' and 'readonly' option";
	break;
case J9SH_CACHE_ACCESS_NOT_ALLOWED:
	accessString = "false";
	break;
default:
	accessString = "false";
	break;
}

Following by a CACHEMAP_PRINT1(...) in there, naturally.

'isBytecodeAgentInstalled' just checks some bits in _runtimeFlags.

'printShutdownStats' calls 'getUnstoredBytes' to report on the unused
AOT, JIT and block storage.

'runExitCode' calls 'printShutdownStats', calls
walkManager->runExitCode() on each Manager instance it owns, and then
calls cache->runExitCode() on each cache in the cache chain.

'createPathString' takes a cpei, and a className and its len, as well
as a buffer to contain a path. It's a static function, and its
purpose seems to be creating a path string to a .class file within the
filesystem (or at least, "classpath system", a Java-centric
generalization of same).

How does it doing? Using ugly C string manipulation, of course!! First
it finds the address of the final '/' in the string, if there is
one. It records it as lastSlashPos, which starts off as a NULL
value. Ok. Next, we calculate the size we'll need to record the full
path as a string. This is given in this equation:

/* 2 = pathsep + \0 */
sizeNeeded = cpeiPathLen + cNameLen + SHARE_CLASS_FILE_EXT_STRLEN + 2;

The 2 is accounted by the pathsep and the null terminator, as the
comment says.

Yeah, the rest seems to be about copying the cpeiPath, and then the
class name, in step with the calculation of sizeNeeded above. That's
all. We return 0 to flag success.

'getRomClassAreaBounds' is the next thing. Where does the
romClassAreaStart, and where does romClassAreaEnd? these are void**
parameters to 'getRomClassAreaBounds'. They end up being dereferenced,
and _ccHead->getBaseAddress() and _ccHead->getSegmentAllocPtr(),
usually.

'enterStringTableMutex' gets the J9SharedInvariantInternTable* that is
currentThread->javaVM->sharedInvariantInternTable. Call
_ccHead->enterReadWriteAreaMutex(..), and off we go! If table isn't
NULL.. we do some internal stuff involved in the table that I don't
understand. I haven't studied it, it's an incredibly marginal part of
the cache really, and yet.. it could be useful for us in our study of
stuff, and things. Looks like it tries to initialize the 'head node'
of the table if it's NULL, and likewise for the 'tail node' if it's
NULL.

'exitStringTableMutex' stores the table->headNode and table->tailNode
pointers back into table->sharedHeadNodePtr and
table->sharedTailNodePtr resp., if they changed. Then it calls
_ccHead->exitReadWriteAreaMutex(..). Then return the result.

'getCachedUTFString' has this comment preamble:

/* Simple utility function which uses the scope manager to find/store UTF strings in the cache
 * Searches for a matching string in the cache. If one is not found, it is added.
 * Returns NULL if error or if the cache is full
 * THREADING: Caller should not have either the read mutex or write mutex
 */

It takes a string, and tries to find the cached version of it. For
some reason this is the responsibility of the ScopeManager. It checks
to see that it has the write mutex before calling
'getScopeManager'. Then _ccHead->enterReadMutex(..), and
'runEntryPointChecks'. If PREVENT_BLOCK_DATA_UPDATE is enabled in
_runtimeFlags, we set allowUpdate (a local variable) to be false.

After this is all done, we copy local to tempstr using strncpy. Then
we call

pathUTF = localSCM->findScopeForUTF(currentThread, temputf);

temputf is a pointer to temp, a stack allocated array of
U_8's. tempstr in turn points to temputf (its data). Then we call

_ccHead->exitReadMutex(currentThread, fnName);

If pathUTF is NULL.. and allowUpdate is true.. we try to claim the
write mutex by, how else, calling _ccHead->writeMutex(..). We try to
detect that the string carried by local was not written to the cache
by some other VM or thread in the intervening time. This involves the
usual cocktail 'runEntryPointChecks', and if nothing new was read
since claiming the write mutex (as told to us by
'runEntryPointChecks') and pathUTF still wasn't initialized by a
second call to localSCM->findScopeForUTF(..), we call
'addScopeToCache' and write that result to pathUTF, once more.

Then we call _ccHead->exitWriteMutex(..).

If allowUpdate is false, but pathUTF is NULL, we call
'increaseUnstoredBytes', adding the length of temputf + sizeof(struct
J9UTF8).

Then we return pathUTF.

Now, 'notifyClasspathEntryStateChange'. We 'getClasspathManager'. Then
we 'getCachedUTFString' on the path, a const char* passed to
'notifyClasspathEntryStateChange'. The comment preamble says this, in
case any of what I'm writing here sounds odd:

/**
 * Called when zip/jar files are opened or closed.
 * Unlikely that we have the VM class segment mutex here.
 */

We cache the literal path of the classpath entry. Then we do this:

   localCPM->notifyClasspathEntryStateChange(currentThread,
	pathUTF, newState);

'getCompositeCacheAPI' returns _ccHead as a SH_CompositeCache*
pointer. When OpenJ9 terms something an 'API', it really refers to the
practice of instantiating an object to the type of an abstract
interface, by upcasting it.

The 'getBlahManager' functions all follow the same template.. there is
an attempt at calling 'startManager', which upon succeeding, results
in that *Manager instance being returned.

'startAllManagers' hides behind a J9SHR_CACHELET_SUPPORT #ifdef, which
is somewhat shocking. That's really strange! I'm skipping it.

Similarly, lines 5481 - 6439 are also hidden behind a
J9SHR_CACHELET_SUPPORT #ifdef.

'resetCacheDescriptorList' "frees an existing list and reinitializes
it." Why you'd want to do that, I have no idea. It walks the
descriptor list and calls j9mem_free_memory on each node as it is
found. Also, we call 'enterLocalMutex' earlier than that if
sharedClassConfig->configMonitor is initialized. I honestly don't see
the reinitialization, but oh well.

Then finally 'exitLocalMutex' is called.

'startClassTransaction' .. starts a class transaction? It starts off
with _ccHead->enterWriteMutex(..), and then 'runEntryPointChecks', and
if that last one succeeds, it calls 'exitClassTranaction'. I guess the
write mutex is relinquished inside 'exitClassTranaction', because it
isn't here.

That's precisely correct, actually. 'exitClassTransaction' consists
entirely of _ccHead->exitWriteMutex(..).

'isAddressInROMClassSegment' just delegates the address parameter out
to _cc->isAddressInROMClassSegment. That's it.

Same is true of 'setStringTableInitialized',
'isStringTableInitialized', 'isAddressInCacheDebugArea',
'getDebugBytes', and 'managers', which barely merit comment.

'shutdownForStats' shutdowns the managers, destroys the _refreshMutex,
and calls pool_kill on _ccPool. It also calls
_ccHead->shutdownForStats(..) at some point along the way.

'getSharedClassConfig' and 'getReadWriteBytes' are just a getter and a
delegator resp.

'attachedTypeString' return strings describing
ATTACHED_DATA_TYPE's.. why the UDATA interpretations themselves
shouldn't suffice, I have no clue.

'isCacheCorruptReported' is a getter, nothing special or noteworthy.

'formatAttachedDataString' formats an attachedData datum into a
string, as primitively as you can in C.

'aotMethodOperation' takes some action, described here in the comment
preamble, weird replicated spelling mistakes and all:

 * @param[in] action SHR_FIND_AOT_METHOTHODS when listing the specified methods
 * 		     SHR_INVALIDATE_AOT_METHOTHODS when invalidating the specified methods
 * 		     SHR_REVALIDATE_AOT_METHOTHODS when revalidating the specified methods

So, find, invalidate, revalidate.

How does the function start? It initializes a MethodSpecTable.. called
specTable. We initialize specTable to contain 0 everywhere, using
memset. Then we call 'fillMethodSpecTable' with arguments specTable
and optionStartPos. optionStartPos is the beginning char* to the char*
methodSpecs, which was passed to us from the command line (I think).

'fillMethodSpecTable' has this comment preamble:

/**
 * This function fills the method specification table with specifications passed in by "invalidateAotMethods/revalidateAotMethods/findAotMethods=" option
 *
 * @param[in] specTable The method specification table
 * @param[in] inputOption Pointer to the method specification string
 *
 * @return the number of method specifications passed in or -1 on failure.
 */

That's uncharacteristically clear, I totally, totally get that.

The function fails if numSpecs > SHR_METHOD_SPEC_TABLE_MAX_SIZE.

If it does fail that check, it calls 'parseWildcardMethodSpecTable',
using specTable, and numSpecs. 'parseWildcard' takes a wildcard
pattern, and matches a substring against it for as long as the
wildcard applies, according to the pattern string.

'parseWildcardMethodSpecTable' matches up the entries of the spec
table to match any wildcard patterns that occur in the class names. It
does the same with method names and method signatures. Then it returns
the result. If the call to 'parseWildcardMethodSpecTable' returns
false, 'aotMethodOperation' fails with -1.

If it succeeds, it calls 'aotMethodOperationHelper', then returns
numMethods (the return value of 'aotMethodOperationHelper').

As to 'aotMethodOperationHelper', by this point the specTable has been
correctly parsed and populated, all that shit! We claim the write
mutex by .. how else .. calling _ccHead->enterWriteMutex(..) with
lockCache a bool determined by whether SHR_FIND_AOT_METHOTHODS !=
action (!!). That is, finding an AOT method.. does not cause the cache
to be locked, of course.. invalidating or revalidating one, does.

Then we go with _ccHead->findStart(currentThread). We begin calling
_ccHead->nextEntry(..) to iterate over ShcItem*'s in the metadata
area. We have entered a do/while loop at this point. If the ITEMTYPE
of the item is COMPILED_METHOD or INVALIDATED_COMPILED_METHOD, we get
the ROMMethod object, the romClassName, the class loader, the ROM
Class, and the name and signature of the ROM method.

Then we call 'matchAotMethod' on specTable, numSpecs, romClassName,
romMethodName, and romMethodSig. It purpose, according to its
preamble, is just to see whether the method matches any of the
specifications.

If it returns true.. we first check to verify that romMethodName and
romMethodSig aren't NULL. We check that the item is stale by called
_ccHead->stale((BlockPtr)ITEMEND(it)).

We check to see if the action was a FIND, and if the type of the item
is an INVALIDATED_COMPILED_METHOD. If so, issue some trace messages.
Moving along, if SHR_INVALIDATE_AOT_METHOTHODS == action, we set the
item type to TYPE_INVALIDATED_COMPILED_METHOD. Otherwise, if it's
SHR_REVALIDATE_AOT_METHOTHODS, ITEMTYPE(it) =
TYPE_COMPILED_METHOD. THIS IS THE EASIEST, MOST COGENT CODE I HAVE YET
SEEN IN THIS CODEBASE.

Continue walking the cache until we're done! No use of hash tables or
anything.

_ccHead->exitMutex(..) is called. What else might you expect at this
stage? And we return rc.

'matchAotMethod' has already been described by me, why, it's
elementary!

Same thing with 'fillMethodSpecTable' and 'parseWildcardMethodSpecTable'.

'protectPartiallyFilled' pages checks
_ccHead->isMemProtectPartialPartialPagesEnabled() for the go ahead to
do anything at all. If it is true, call _ccHead->enterWriteMutex(..),
then _ccHead->protectPartiallyFilledPages(..), then
_ccHead->exitWriteMutex(..). Then we return.

'tryAdjustMinMaxSizes' and 'updateRuntimeFullFlags' are just wrappers
around the equivalent CompositeCache functions.

'increaseUnstoredBytes' takes blockBytes, aotBytes and jitBytes as
arguments, and does some delegation out to
_ccHead->increaseUnstoredBytes(..). It's a pretty uninteresting story
that doesn't even involve the capture of any mutexes (read or write).

'getUnstoredBytes' is just a bare, 1-1 delegator to CompositeCache.

'updateLocalHintsData' .. what does it do??? According to the
preamble, it updates the local startup hints, contained in
_sharedClassConfig->localStartupHints, with the one in the shared
cache. For some reason, we need to overwrite recorded heap sizes?? I
have no clue why. This is if the flags

J9SHR_LOCAL_STARTUPHINTS_FLAG_WRITE_HINTS

or

J9SHR_LOCAL_STARTUPHINTS_FLAG_OVERWRITE_HEAPSIZES

and

J9SHR_LOCAL_STARTUPHINTS_FLAG_STORE_HEAPSIZES

are enabled. We want to store the heap sizes of the hints data, and we
may want to overwrite them. We'll return to this some other time! I
don't think it's important.

SHRINIT.CPP
===========

Looking at 'j9shr_init' now. 

The runtime flags, verbose flags, and print stat options are stored in
the struct vm->sharedCacheAPI, which is an J9JavaVM*. The cacheName,
modContext, expireTime and ctrlDirName all originate from there as
well. Then there's this:


if (FALSE == vm->sharedCacheAPI->xShareClassesPresent) {
   Trc_SHR_Assert_True(vm->sharedCacheAPI->sharedCacheEnabled);
   Trc_SHR_Assert_True(J9_ARE_ALL_BITS_SET(runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_NONFATAL));
   Trc_SHR_Assert_True(J9_ARE_ALL_BITS_SET(runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_CACHEBOOTCLASSES));
   Trc_SHR_Assert_True(J9_ARE_NO_BITS_SET(runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_CACHE_NON_BOOT_CLASSES));
   Trc_SHR_Assert_True(0 == vm->sharedCacheAPI->verboseFlags);
		Trc_SHR_INIT_j9shr_init_BootClassSharingEnabledByDefault(currentThread);
}

Shared classes have to be enabled, and we are caching boot classes,
and also caching non boot classes! This is all supposed to be true if
we attempt to initialize the cache. Then there's this crap to do with
string tables:

if (((0 != (runtimeFlags & J9SHR_RUNTIMEFLAG_CHECK_STRINGTABLE_RESET_READONLY)) ||
     (0 != (runtimeFlags & J9SHR_RUNTIMEFLAG_CHECK_STRINGTABLE_RESET_READWRITE))) &&
     (0 == (runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_ROUND_TO_PAGE_SIZE)))
{
	/* CMVC 176498 : When testing string table reset,
	 * ensure J9SHR_RUNTIMEFLAG_ENABLE_ROUND_TO_PAGE_SIZE is set.
	 */
	SHRINIT_ERR_TRACE(verboseFlags, J9NLS_SHRC_SHRINIT_CHECK_STRINGTABLE_RESET_MISSING_FLAG);
	goto _error;
}

And there's some memory protection logic:

if (((runtimeFlags & J9SHR_RUNTIMEFLAG_VERIFY_TREE_AND_TREE_ACCESS) == J9SHR_RUNTIMEFLAG_VERIFY_TREE_AND_TREE_ACCESS) ||
	(parseResult == RESULT_DO_TEST_INTERNAVL)
) {
	if ( runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_ALL ) {
		runtimeFlags &= ~(J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_ALL | J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_RW);
		runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT;
	} else if ( runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_RW ) {
		runtimeFlags &= ~(J9SHR_RUNTIMEFLAG_ENABLE_MPROTECT_RW);
	}
}

Yeah. Let's.. disable the ALL and RW flags and enable the more general
ENABLE_MPROTECT flag.

Then 'ensureCorrectCacheSizes' is called in light of the runtimeFlags,
and verboseFlags. Similarly, the cacheType is determined by
'getCacheTypeFromRuntimeFlags'. It discriminates between persistent
and nonpersistent cache types.

'modifyCacheName' add user name and group info to the naming of the
cache. Nothing remarkable about it, particularly..

This next block toggles a few options off if statistics are being
gathered at all.

if (parseResult==RESULT_DO_PRINTSTATS || 
    parseResult==RESULT_DO_PRINTALLSTATS || 
    parseResult==RESULT_DO_PRINTORPHANSTATS ||
    parseResult==RESULT_DO_PRINTALLSTATS_EQUALS ||
    parseResult==RESULT_DO_PRINTSTATS_EQUALS) {
      doPrintStats = true;
      
      /* Do not try to kill a cache if we just want to get stats on it */
      runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_STATS;
      runtimeFlags &= ~J9SHR_RUNTIMEFLAG_ENABLE_REDUCE_STORE_CONTENTION;
      runtimeFlags &= ~J9SHR_RUNTIMEFLAG_ENABLE_TEST_BAD_BUILDID;
      runtimeFlags &= ~J9SHR_RUNTIMEFLAG_AUTOKILL_DIFF_BUILDID;
     
      /* Ignore incompatible options as we just want to get stats on it */
      runtimeFlags &= ~(J9SHR_RUNTIMEFLAG_ENABLE_CACHERETRANSFORMED | J9SHR_RUNTIMEFLAG_ENABLE_BCI);
}

The next option tells us to ignore a readonly config being toggled if
we are invalidate or revalidate AOT methods:

if ((RESULT_DO_INVALIDATE_AOT_METHODS_EQUALS == parseResult)
	|| (RESULT_DO_REVALIDATE_AOT_METHODS_EQUALS == parseResult)
) {
	/* ignore 'readOnly' when invalidate/revalidate AOT methods */
	if (J9_ARE_ALL_BITS_SET(runtimeFlags, J9SHR_RUNTIMEFLAG_ENABLE_READONLY)) {
		const char* option = (RESULT_DO_INVALIDATE_AOT_METHODS_EQUALS == parseResult) ? OPTION_INVALIDATE_AOT_METHODS_EQUALS : OPTION_REVALIDATE_AOT_METHODS_EQUALS;
		runtimeFlags &= ~J9SHR_RUNTIMEFLAG_ENABLE_READONLY;
		SHRINIT_WARNING_TRACE3(verboseFlags, J9NLS_SHRC_SHRINIT_OPTION_IGNORED_WARNING, OPTION_READONLY, option, OPTION_READONLY);
		if (verboseFlags > 0) {
			j9tty_printf(PORTLIB, "\n");
		}
	}
}

Then we check to see if we're resetting an existing cache for some
reason, and if so, we jump to _error. But beyond that, we're finally
done with the tedious checking of settings and shit, and on to
allocating the actual cache. Behold this code:


cmBytes = SH_CacheMap::getRequiredConstrBytes(false);
nameBytes = (strlen(modifiedCacheNamePtr)+1) * sizeof(char);
modContextBytes = modContext ? ((strlen(modContext) * sizeof(char)) + sizeof(J9UTF8)) : 0;
memBytesNeeded = sizeof(J9SharedClassConfig) + sizeof(J9SharedClassCacheDescriptor) + cmBytes + nameBytes + modContextBytes;

tempConfig = (J9SharedClassConfig*)j9mem_allocate_memory(memBytesNeeded, J9MEM_CATEGORY_CLASSES);
if (!tempConfig) {
	SHRINIT_ERR_TRACE(verboseFlags, J9NLS_SHRC_SHRINIT_FAILURE_ALLOCATING_CONFIG);
	goto _error;
}
memset(tempConfig, 0, memBytesNeeded);

tempConfig->ctrlDirName = ctrlDirName;


cmBytes reflects the total size of the cache map we'll allocate.. then
we compute the number of bytes needed for the name, the name of the
modification context, and then factoring in the size of the
J9SharedClassConfig, *CacheDescriptor, all of that.

We allocate memBytesNeeded, and store *that* as J9SharedCacheConfig,
although it includes memory for all the other aforementioned
things. NOTE THAT WE HAVE NOT INTIALIZED ANYTHING YET *huff huff*.

'performSharedClassesCommandLineAction' takes the SCC config, the vm,
the cacheName, verboseFlags, and a command, and dispatches to other
functions on the basis of that command through (how else?) a switch
statement. Some of these flags are:

RESULT_DO_HELP
RESULT_DO_MORE_HELP
RESULT_DO_DESTROY
RESULT_DO_DESTROYALL
RESULT_DO_DESTROYSNAPSHOT
RESULT_DO_DESTROYALLSNAPSHOTS
RESULT_DO_RESTORE_FROM_SNAPSHOT
RESULT_DO_SNAPSHOTCACHE
RESULT_DO_LISTALLCACHES
RESULT_DO_EXPIRE
RESULT_DO_PRINTSTATS
RESULT_DO_PRINTALLSTATS
RESULT_DO_PRINTORPHANSTATS
RESULT_DO_PRINTALLSTATS_EQUALS
RESULT_DO_PRINTSTATS_EQUALS
RESULT_DO_PRINT_CACHENAME

And others! Long list of dispatch that we don't need to get into right
now.

Back to j9shr_init. We have another incompatible options check
following this.

/* check for incompatible options */
if ((0 != (runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_CACHERETRANSFORMED))
	&& (0 != (runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_BCI))
) {
	SHRINIT_ERR_TRACE2(1, J9NLS_SHRC_SHRINIT_INCOMPATIBLE_OPTION, OPTION_ENABLE_BCI, OPTION_CACHERETRANSFORMED);
	goto _error;
}

To actually initialize the cache, we bump the tempConfig pointer
forward repeatedly by however much space we need:

/* Initialize the cache */

tempConfig->cacheDescriptorList = (J9SharedClassCacheDescriptor*)((UDATA)tempConfig + sizeof(J9SharedClassConfig));
cmPtr = (SH_CacheMap*)((UDATA)tempConfig->cacheDescriptorList + sizeof(J9SharedClassCacheDescriptor));
mcPtr = (J9UTF8*)((UDATA)cmPtr + cmBytes);
copiedCacheName = (char*)((UDATA)mcPtr + modContextBytes);

/* make this list circular */
tempConfig->cacheDescriptorList->next = tempConfig->cacheDescriptorList;

/* Copy the cache name */
strcpy(copiedCacheName, modifiedCacheNamePtr);
cacheName = copiedCacheName;


We do this for everything. Then there's this:

tempConfig->runtimeFlags = runtimeFlags;
tempConfig->verboseFlags = verboseFlags;
tempConfig->softMaxBytes = vm->sharedCacheAPI->softMaxBytes;
tempConfig->minAOT = vm->sharedCacheAPI->minAOT;
tempConfig->maxAOT = vm->sharedCacheAPI->maxAOT;
tempConfig->minJIT = vm->sharedCacheAPI->minJIT;
tempConfig->maxJIT = vm->sharedCacheAPI->maxJIT;

Yeah. The next significant thing is that we try to claim the
configMinotir and jclCacheMutex mutexes using
'omrhtread_monitor_init', as we saw many times in CacheMap and
CompositeCache. Over and over again, really.

Finally, we call newInstance on the nascent cachemap:

/*Add the cachemap before calling startup to enable debug extensions in jextract etc*/
cm = SH_CacheMap::newInstance(vm, vm->sharedClassConfig, cmPtr, cacheName, cacheType);
vm->sharedClassConfig->sharedClassCache = (void*)cm;

If the parseResult (from the command line, natch) is
RESULT_DO_RESTORE_FROM_SNAPSHOT, we call j9shr_restoreFromSnapshot!
And do some routine error handling stuff. If not, we do this:

rcStartup = cm->startup(currentThread, piconfig, cacheName,
ctrlDirName, vm->sharedCacheAPI->cacheDirPerm, NULL,
&cacheHasIntegrity);

The startup! .. guy. If that fails, we go to _error.. if not, we carry
on. Mostly this involves populating vm->sharedClassConfig with
different pools ("caches" for the Java class library classpaths, and
tokens, and URLs, and UTF8 strings) and a whole long ass procession of
function pointers, pointing to functions that live inside
j9shr_init. It is indeed a big list:

config->getCacheSizeBytes = j9shr_getCacheSizeBytes;
config->getTotalUsableCacheBytes = j9shr_getTotalUsableCacheBytes;
config->getMinMaxBytes = j9shr_getMinMaxBytes;
config->setMinMaxBytes = j9shr_setMinMaxBytes;
config->increaseUnstoredBytes = j9shr_increaseUnstoredBytes;
config->getUnstoredBytes = j9shr_getUnstoredBytes;
config->getFreeSpaceBytes = j9shr_getFreeAvailableSpaceBytes;
config->findSharedData = j9shr_findSharedData;
config->storeSharedData = j9shr_storeSharedData;
config->findCompiledMethodEx1 = j9shr_findCompiledMethodEx1;
config->storeCompiledMethod = j9shr_storeCompiledMethod;
config->storeAttachedData = j9shr_storeAttachedData;
config->findAttachedData = j9shr_findAttachedData;
config->updateAttachedData = j9shr_updateAttachedData;
config->updateAttachedUDATA = j9shr_updateAttachedUDATA;
config->freeAttachedDataDescriptor = j9shr_freeAttachedDataDescriptor;
config->existsCachedCodeForROMMethod = j9shr_existsCachedCodeForROMMethod;
config->acquirePrivateSharedData = j9shr_acquirePrivateSharedData;
config->releasePrivateSharedData = j9shr_releasePrivateSharedData;
config->isBCIEnabled = j9shr_isBCIEnabled;
config->freeClasspathData = j9shr_freeClasspathData;
config->jvmPhaseChange = j9shr_jvmPhaseChange;
config->findGCHints = j9shr_findGCHints;
config->storeGCHints = j9shr_storeGCHints;

Well, it's not so big, perhaps. All these functions issue calls
through the CacheMap class, which is hidden elsewhere in the
J9SharedClassConfig C struct. Then there's this:

config->sharedAPIObject = initializeSharedAPI(vm);
if (config->sharedAPIObject == NULL) {
	SHRINIT_ERR_TRACE(verboseFlags, J9NLS_SHRC_SHRINIT_API_CREATE_FAILURE);
	goto _error;
}

I don't understand enough about string and class transactions. Truth
be told, I've mostly ignored them up to this time. That will soon need
to change. 

'startClassTransaction' is seldom used anywhere in J9. Here are the
places:

1) the line of code in shrinit.cpp we are about to consider,
2) in 'j9shr_stringTransaction_start'

All it does is claim the SCC write mutex and call
'runEntryPointChecks'. It is that simple.

Anyway.. we enter the string table mutex after calling
startClassTranaction on cm, the CacheMap object.

Then there's a long, long-ass conditional toggling the string table
off if print stats is on. In the body of that (which we enter
*because* ENABLE_STATS is off), it goes on to allocate the shared
string intern table. Then it's initialized with
'initializeSharedStringTable'. Then before long it exits, and we are
finished.

Then it checks that parseResult == RESULT_DO_INVALIDATE_AOT_METHODS_EQUALS.
This it delegates to j9shr_aotMethodOperation.. the thing we have sort
of seen already.

Similar with RESULT_DO_REVALIDATE_AOT_METHODS_EQUALS, and
RESULT_DO_FIND_AOT_METHODS_EQUALS. For an example, see this (!) :

if (RESULT_DO_SNAPSHOTCACHE == parseResult) {
   *nonfatal = 0;
   if (0 == j9shr_createCacheSnapshot(vm, cacheName)) {
      SHRINIT_TRACE1(verboseFlags, J9NLS_SHRC_SHRINIT_SUCCESS_CREATE_SNAPSHOT, cacheName);
   } else {
      SHRINIT_ERR_TRACE1(verboseFlags, J9NLS_SHRC_SHRINIT_FAILURE_CREATE_SNAPSHOT, cacheName);
   }
   returnVal = J9VMDLLMAIN_SILENT_EXIT_VM;
}

and then this:

if ((RESULT_DO_ADJUST_SOFTMX_EQUALS == parseResult)
	|| (RESULT_DO_ADJUST_MINAOT_EQUALS == parseResult)
	|| (RESULT_DO_ADJUST_MAXAOT_EQUALS == parseResult)
	|| (RESULT_DO_ADJUST_MINJITDATA_EQUALS == parseResult)
	|| (RESULT_DO_ADJUST_MAXJITDATA_EQUALS == parseResult)
) {
	/* There is no need to check the return value of tryAdjustMinMaxSizes(). JVM will always exit and the corresponding NLS message
	 * will be printed out inside tryAdjustMinMaxSizes() no matter whether the softmx/minAOT/maxAOT/minJIT/maxJIT has been adjusted as requested */
	cm->tryAdjustMinMaxSizes(currentThread);
	returnVal = J9VMDLLMAIN_SILENT_EXIT_VM;
}

If we jump to _error, we try to free the allocated memory. 
